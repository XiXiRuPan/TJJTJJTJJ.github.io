<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>田佳杰</title>
  <icon>https://www.gravatar.com/avatar/cbd320e406f4c9571bb798e8810c4d18</icon>
  <subtitle>记录一些学习到的东西和论文记录</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-10-04T07:58:45.171Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jiajie Tian</name>
    <email>18810906582@163.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>pytorch-chapter10-ImageCaption</title>
    <link href="http://yoursite.com/2018/09/30/pytorch-chapter10-ImageCaption/"/>
    <id>http://yoursite.com/2018/09/30/pytorch-chapter10-ImageCaption/</id>
    <published>2018-09-30T03:00:50.000Z</published>
    <updated>2018-10-04T07:58:45.171Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文主要是针对陈云的PyTorch入门与实践的第八章的内容进行复现，准确地说，是看着他写的代码，自己再实现一遍，所以更多地是在讲解实现过程中遇到的问题或者看到的好的方法，而不是针对论文的原理的进行讲解。对于原理，也只是会一笔带过。原理篇暂时不准备留坑，因为原理是个玄学。<br><a id="more"></a><br>这是我的<a href="https://github.com/TJJTJJTJJ/pytorch__learn" target="_blank" rel="noopener">代码</a><br>大神链接：<a href="https://github.com/anishathalye/neural-style" target="_blank" rel="noopener">https://github.com/anishathalye/neural-style</a><br>这是论文作者写的</p><h1 id="问题以及思考"><a href="#问题以及思考" class="headerlink" title="问题以及思考"></a>问题以及思考</h1><p>这一次感觉写起来很顺利，数据的处理+基本模型的走读基本只用了两天，剩下的两天主要是耗在了beam_searching上，原理的解析和代码的思考。<br>现在记录一下这次走读的过程中学习到的东西，如果是和之前的记录有联系，那么则尽量记在一起。</p><hr><h2 id="局部反向传播管理"><a href="#局部反向传播管理" class="headerlink" title="局部反向传播管理"></a>局部反向传播管理</h2><p>部分参考第八章，基本来自官网文档<br>一共是四种</p><ul><li>@torch.no_grad()</li><li>with torch.no_grad():</li><li>torch.set_grad_enabled(bool)</li><li>with torch.set_grad_enabled(False):</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种：固定上下文管理器，torch.no_grad()和torch.enable_grad()</span></span><br><span class="line">又分为@torch.no_grad()和<span class="keyword">with</span> torch.no_grad()</span><br><span class="line">x = torch.tensor([<span class="number">1</span>], requires_grad=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    print(x.requires_grad)</span><br><span class="line">    y = x*<span class="number">2</span></span><br><span class="line">    print(y.requires_grad)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">y.requires_grad</span><br><span class="line"></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"><span class="comment"># 以上说明了上下文管理器内和外是一致的</span></span><br><span class="line"><span class="comment"># 下面说明上下文管理器的作用域只在局部有效</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    print(x.requires_grad)</span><br><span class="line">    z = x*<span class="number">2</span></span><br><span class="line">    print(z.requires_grad)</span><br><span class="line">    <span class="keyword">with</span> torch.enable_grad():</span><br><span class="line">        print(x.requires_grad)</span><br><span class="line">        y = x*<span class="number">2</span></span><br><span class="line">        print(y.requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.enable_grad():</span><br><span class="line">    print(x.requires_grad)</span><br><span class="line">    z = x*<span class="number">2</span></span><br><span class="line">    print(z.requires_grad)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        print(x.requires_grad)</span><br><span class="line">        y = x*<span class="number">2</span></span><br><span class="line">        print(y.requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>@torch.no_grad()</span><br><span class="line"><span class="meta">... </span><span class="function"><span class="keyword">def</span> <span class="title">dddd</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    x = torch.tensor([<span class="number">2.2</span>],requires_grad=<span class="keyword">True</span>)</span><br><span class="line"><span class="meta">... </span>    y = <span class="number">2</span>*x</span><br><span class="line"><span class="meta">... </span>    print(y.requires_grad)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dddd()</span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种：条件的上下文管理器 torch.set_grad_enabled(bool)</span></span><br><span class="line">又分为<span class="keyword">with</span>  torch.set_grad_enabled(bool)和 torch.set_grad_enabled(bool)</span><br><span class="line"><span class="keyword">with</span> torch.set_grad_enabled(<span class="keyword">False</span>):</span><br><span class="line">    print(x.requires_grad)</span><br><span class="line">    y = x*<span class="number">2</span></span><br><span class="line">    print(y.requires_grad)</span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.set_grad_enabled(<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x * <span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.requires_grad</span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试@torch.enable_grad()的时候没有成功，问题应该是版本问题，0.4.0的版本就不行，但是0.4.1的版本就可以了</span></span><br></pre></td></tr></table></figure><hr><h2 id="预训练模型的修改"><a href="#预训练模型的修改" class="headerlink" title="预训练模型的修改"></a>预训练模型的修改</h2><p>备注：感觉这一块应该是很条理才对，但是没有找到类似的说明<br>只能等以后见得多了，再做补充，网上有一些对特定模型的修改，但是都不全面，也没有具体说明各个方法的优劣。<br>应该是这样的，层必须和forward对应，参数的加载可以放在模型定义时，也可以放在模型定义之后。</p><h3 id="不修改原模型的forward流程"><a href="#不修改原模型的forward流程" class="headerlink" title="不修改原模型的forward流程"></a>不修改原模型的forward流程</h3><p>常用于对特定层的修改<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">model = models.resnet50(pretrained=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 只修改最后一层</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一种</span></span><br><span class="line">fc_features = model.fc.in_features</span><br><span class="line">model.fc = nn.Linear(fc, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种</span></span><br><span class="line">resnet50 = tv.models.resnet50(pretrained=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">del</span> resnet50.fc</span><br><span class="line">resnet50.fc = <span class="keyword">lambda</span> x: x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果直接修改out_features是没有用的</span></span><br><span class="line">model.fc.out_features = <span class="number">9</span></span><br><span class="line">resnet50.fc.weight.shape</span><br><span class="line">torch.Size([<span class="number">1000</span>, <span class="number">2048</span>])</span><br><span class="line">即如果修改某一层，要重新定义这一层</span><br></pre></td></tr></table></figure></p><h3 id="在模型内修改forward流程"><a href="#在模型内修改forward流程" class="headerlink" title="在模型内修改forward流程"></a>在模型内修改forward流程</h3><p>常用于中间层的增加<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要自己先定义类似的网络，注意定义的名字必须一致和方式需要一致，利用state_dict来更新参数</span></span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">resnet50 = models.resnet50(pretrained=<span class="keyword">True</span>)</span><br><span class="line">cnn = CNN(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line">pretrained_dict = resnet50.state_dict()</span><br><span class="line">model_dict = cnn.state_dict()</span><br><span class="line"><span class="comment"># 选取相同名字参数</span></span><br><span class="line">pretrained_dict =  &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_dict&#125;</span><br><span class="line">model_dict.update(pretrained_dict)</span><br><span class="line">cnn.load_state_dict(model_dict)</span><br><span class="line">print(cnn)</span><br></pre></td></tr></table></figure></p><h3 id="在模型外增加forward流程"><a href="#在模型外增加forward流程" class="headerlink" title="在模型外增加forward流程"></a>在模型外增加forward流程</h3><p>常用与开头或者末尾层的增加<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.add_module(<span class="string">'layer_name'</span>,layer)</span><br><span class="line">可以理解成</span><br><span class="line">self.layer_name = layer</span><br><span class="line">x = model.layer_name(x)</span><br></pre></td></tr></table></figure></p><h3 id="取特定模块，利用children-和nn-Sequential-也可以实现特定层的修改"><a href="#取特定模块，利用children-和nn-Sequential-也可以实现特定层的修改" class="headerlink" title="取特定模块，利用children()和nn.Sequential()也可以实现特定层的修改"></a>取特定模块，利用children()和nn.Sequential()也可以实现特定层的修改</h3><p>这个方法比较啰嗦，不是很推荐，或者不如第一种方法，或者不如最后一种方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">model = models.vgg16(pretrained=<span class="keyword">True</span>)</span><br><span class="line">removed = list(model.classifier.children())[:<span class="number">-1</span>]</span><br><span class="line">model.classifier = torch.nn.Sequential(*removed)</span><br><span class="line">model.add_module(<span class="string">'fc'</span>, torch.nn.Linear(<span class="number">4096</span>, out_num)) <span class="comment"># out_num是你希望输出的数量 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接list(model)是不行的，但是list(model.children())就可以</span></span><br><span class="line">list(ResNet34.children())</span><br><span class="line">In [<span class="number">23</span>]: <span class="keyword">for</span> i <span class="keyword">in</span> ResNet34.children():</span><br><span class="line">    ...:     print(type(i))</span><br><span class="line">    ...:     </span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">container</span>.<span class="title">Sequential</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">container</span>.<span class="title">Sequential</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">container</span>.<span class="title">Sequential</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">container</span>.<span class="title">Sequential</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">container</span>.<span class="title">Sequential</span>'&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">torch</span>.<span class="title">nn</span>.<span class="title">modules</span>.<span class="title">linear</span>.<span class="title">Linear</span>'&gt;</span></span><br></pre></td></tr></table></figure></p><h3 id="取特定模块"><a href="#取特定模块" class="headerlink" title="取特定模块"></a>取特定模块</h3><p>利用list和modulelist，可用于对于特定模块的特定操作，可修改forward流程<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第八章的方法 定义新模型， 在模型定义时，加载原模型参数， 修改forward 对于单向的还好，对于有分支的还没有尝试 用了list和modulelist 直接在定义模型的地方取</span></span><br><span class="line">features = list(vgg16(pretrained=<span class="keyword">True</span>).features)[:<span class="number">23</span>]</span><br><span class="line">self.features = nn.ModuleList(features).eval()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ii, model <span class="keyword">in</span> enumerate(self.features):</span><br><span class="line">    x = model(x)</span><br><span class="line">    <span class="keyword">if</span> ii <span class="keyword">in</span> &#123;<span class="number">3</span>,<span class="number">8</span>,<span class="number">15</span>,<span class="number">22</span>&#125;:</span><br><span class="line">        results.append(x)</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> resnet34.named_children():</span><br><span class="line">    print(k,v)</span><br><span class="line"></span><br><span class="line">conv1 Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">bn1 BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">relu ReLU(inplace)</span><br><span class="line">maxpool MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">layer1 Sequential(</span><br><span class="line">  (<span class="number">0</span>): BasicBlock(</span><br><span class="line">    (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">    (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">    (relu): ReLU(inplace)</span><br><span class="line">    (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="keyword">False</span>)</span><br><span class="line">    (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="keyword">True</span>, track_running_stats=<span class="keyword">True</span>)</span><br><span class="line">  )</span><br><span class="line">...</span><br></pre></td></tr></table></figure><hr><h2 id="tensor-new和fill-和copy"><a href="#tensor-new和fill-和copy" class="headerlink" title="tensor.new和fill_和copy_"></a>tensor.new和fill_和copy_</h2><h3 id="在第九章，创建同类型的tensor用new-保证类型和cuda一致，不保证requires-grad，保证了和源类型一致，不共享内存"><a href="#在第九章，创建同类型的tensor用new-保证类型和cuda一致，不保证requires-grad，保证了和源类型一致，不共享内存" class="headerlink" title="在第九章，创建同类型的tensor用new,保证类型和cuda一致，不保证requires_grad，保证了和源类型一致，不共享内存"></a>在第九章，创建同类型的tensor用new,保证类型和cuda一致，不保证requires_grad，保证了和源类型一致，不共享内存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.Tensor([<span class="number">2.2</span>],requires_grad=<span class="keyword">True</span>).cuda()</span><br><span class="line">x</span><br><span class="line">tensor([ <span class="number">3.2000</span>], device=<span class="string">'cuda:0'</span>)</span><br><span class="line">y = x.new([<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">y</span><br><span class="line">y.requires_grad</span><br><span class="line"><span class="keyword">False</span></span><br><span class="line">tensor([ <span class="number">4.</span>,  <span class="number">5.</span>], device=<span class="string">'cuda:0'</span>)</span><br><span class="line">z = x.data.new([<span class="number">6</span>,<span class="number">7</span>])</span><br><span class="line">z.requires_grad</span><br><span class="line"><span class="keyword">False</span></span><br><span class="line">z</span><br><span class="line">tensor([ <span class="number">6.</span>,  <span class="number">7.</span>], device=<span class="string">'cuda:0'</span>)</span><br></pre></td></tr></table></figure><h3 id="在第十章，创建同类型同样大小同cuda的tensor，用fill-，fill-也保证了类型和cuda一致，保证了和目标类型一致"><a href="#在第十章，创建同类型同样大小同cuda的tensor，用fill-，fill-也保证了类型和cuda一致，保证了和目标类型一致" class="headerlink" title="在第十章，创建同类型同样大小同cuda的tensor，用fill_，fill_也保证了类型和cuda一致，保证了和目标类型一致"></a>在第十章，创建同类型同样大小同cuda的tensor，用fill_，fill_也保证了类型和cuda一致，保证了和目标类型一致</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">36</span>]: x = t.Tensor(<span class="number">3</span>,<span class="number">4</span>).cuda()</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: x</span><br><span class="line">Out[<span class="number">37</span>]: </span><br><span class="line">tensor([[ <span class="number">1.1395e-19</span>,  <span class="number">4.5886e-41</span>,  <span class="number">3.4482e+25</span>,  <span class="number">3.0966e-41</span>],</span><br><span class="line">        [ <span class="number">5.7353e-31</span>,  <span class="number">4.5886e-41</span>, <span class="number">-1.2545e+37</span>,  <span class="number">1.3914e+25</span>],</span><br><span class="line">        [ <span class="number">2.9680e-31</span>,  <span class="number">4.5886e-41</span>,  <span class="number">5.7344e-31</span>,  <span class="number">4.5886e-41</span>]],</span><br><span class="line">       device=<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: x.fill_(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">38</span>]: </span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]], device=<span class="string">'cuda:0'</span>)</span><br><span class="line"><span class="comment"># 测试requires_grad提示，不能</span></span><br><span class="line">In [<span class="number">43</span>]: x.requires_grad= <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: x</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]], device=<span class="string">'cuda:0'</span>, requires_grad=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: x.fill_(<span class="number">1</span>)</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">RuntimeError                              Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input<span class="number">-45</span><span class="number">-0</span>c255de765ba&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; 1 x.fill_(1)</span><br><span class="line"></span><br><span class="line">RuntimeError: a leaf Variable that requires grad has been used <span class="keyword">in</span> an <span class="keyword">in</span>-place operation.</span><br><span class="line"><span class="comment"># 强行修改值，则grad_fn也发生了变化。</span></span><br><span class="line">In [<span class="number">46</span>]: x[<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: x</span><br><span class="line">Out[<span class="number">47</span>]: </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]], device=<span class="string">'cuda:0'</span>, grad_fn=&lt;CopySlices&gt;)</span><br></pre></td></tr></table></figure><h3 id="第十章的copy-，类型不变，"><a href="#第十章的copy-，类型不变，" class="headerlink" title="第十章的copy_，类型不变，"></a>第十章的copy_，类型不变，</h3><p>可以作为计算图进行保留<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不共享内存</span></span><br><span class="line">In [<span class="number">49</span>]: x = t.Tensor(<span class="number">2</span>,<span class="number">2</span>).fill_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: x</span><br><span class="line">Out[<span class="number">50</span>]: </span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: y = t.Tensor(<span class="number">1</span>,<span class="number">2</span>).fill_(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: y</span><br><span class="line">Out[<span class="number">52</span>]: tensor([[<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: x[<span class="number">0</span>].copy_(y[<span class="number">0</span>])</span><br><span class="line">Out[<span class="number">53</span>]: tensor([<span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: x</span><br><span class="line">Out[<span class="number">54</span>]: </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: y</span><br><span class="line">Out[<span class="number">55</span>]: tensor([[<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">56</span>]: y[<span class="number">0</span>][<span class="number">0</span>]=<span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: y</span><br><span class="line">Out[<span class="number">57</span>]: tensor([[<span class="number">2.</span>, <span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: x</span><br><span class="line">Out[<span class="number">58</span>]: </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类型不变</span></span><br><span class="line">In [<span class="number">60</span>]: y = t.IntTensor(<span class="number">1</span>,<span class="number">2</span>).fill_(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: y</span><br><span class="line">Out[<span class="number">61</span>]: tensor([[<span class="number">1</span>, <span class="number">1</span>]], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: x = t.Tensor(<span class="number">2</span>,<span class="number">2</span>).fill_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: x</span><br><span class="line">Out[<span class="number">63</span>]: </span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: x[<span class="number">0</span>].copy_(y[<span class="number">0</span>])</span><br><span class="line">Out[<span class="number">64</span>]: tensor([<span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: x</span><br><span class="line">Out[<span class="number">65</span>]: </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># requires_grad，会作为一个计算图保留</span></span><br><span class="line">In [<span class="number">66</span>]: x</span><br><span class="line">Out[<span class="number">66</span>]: </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: x.requires_grad=<span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">68</span>]: x</span><br><span class="line">Out[<span class="number">68</span>]: </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>]], requires_grad=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">69</span>]: x[<span class="number">1</span>].copy_(y[<span class="number">0</span>])</span><br><span class="line">Out[<span class="number">69</span>]: tensor([<span class="number">1.</span>, <span class="number">1.</span>], grad_fn=&lt;AsStridedBackward&gt;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># cuda，可以保留</span></span><br><span class="line">In [<span class="number">76</span>]: y[<span class="number">0</span>]=<span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: y</span><br><span class="line">Out[<span class="number">77</span>]: tensor([[<span class="number">2</span>, <span class="number">2</span>]], dtype=torch.int32)</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: x[<span class="number">1</span>].copy_(y[<span class="number">0</span>])</span><br><span class="line">Out[<span class="number">78</span>]: tensor([<span class="number">2.</span>, <span class="number">2.</span>], device=<span class="string">'cuda:0'</span>, grad_fn=&lt;AsStridedBackward&gt;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: x</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]], device=<span class="string">'cuda:0'</span>, grad_fn=&lt;CopySlices&gt;)</span><br></pre></td></tr></table></figure></p><hr><h2 id="tensor赋值操作-只复制值，不共享内存"><a href="#tensor赋值操作-只复制值，不共享内存" class="headerlink" title="tensor赋值操作   只复制值，不共享内存"></a>tensor赋值操作   只复制值，不共享内存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种 利用tensor 只复制值</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: x = t.tensor([<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: x</span><br><span class="line">Out[<span class="number">7</span>]: tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: y = t.tensor(x)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: y</span><br><span class="line">Out[<span class="number">9</span>]: tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: x[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: y</span><br><span class="line">Out[<span class="number">11</span>]: tensor([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种 利用切片， 只复制值</span></span><br><span class="line">In [<span class="number">12</span>]: y = t.Tensor(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: y[<span class="number">0</span>:<span class="number">2</span>]=x</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: y</span><br><span class="line">Out[<span class="number">14</span>]: tensor([<span class="number">1.0000e+00</span>, <span class="number">4.0000e+00</span>, <span class="number">1.1395e-19</span>, <span class="number">4.5886e-41</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: x[<span class="number">0</span>]=<span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: y</span><br><span class="line">Out[<span class="number">16</span>]: tensor([<span class="number">1.0000e+00</span>, <span class="number">4.0000e+00</span>, <span class="number">1.1395e-19</span>, <span class="number">4.5886e-41</span>])</span><br></pre></td></tr></table></figure><hr><h2 id="t-save"><a href="#t-save" class="headerlink" title="t.save"></a>t.save</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 单个变量 不保留名字</span></span><br><span class="line">t.save(x, <span class="string">'a.pth'</span>)</span><br><span class="line">y = t.load(<span class="string">'a.pth'</span>) <span class="comment"># 这个时候已经和x没有任何关系了</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多个变量 或者保留名字</span></span><br><span class="line">dic = dict(aa=x, bb=y)</span><br><span class="line">t.save(dic, <span class="string">'a.pth'</span>)</span><br><span class="line">y = t.load(<span class="string">'a.pth'</span>) <span class="comment"># 这个时候已经和dic没有任何关系了，但是aa,bb还保留着</span></span><br><span class="line">y</span><br><span class="line">&#123;<span class="string">'aa'</span>: tensor([[ <span class="number">100.0000</span>,  <span class="number">100.0000</span>,  <span class="number">100.0000</span>,  <span class="number">100.0000</span>],</span><br><span class="line">         [  <span class="number">-0.0000</span>,    <span class="number">0.0000</span>,    <span class="number">0.0000</span>,    <span class="number">0.0000</span>],</span><br><span class="line">         [  <span class="number">-0.0000</span>,    <span class="number">0.0000</span>,   <span class="number">-0.0000</span>,    <span class="number">0.0000</span>]]),</span><br><span class="line"> <span class="string">'bb'</span>: tensor(<span class="number">1.00000e-11</span> *</span><br><span class="line">        [[<span class="number">-0.0000</span>,  <span class="number">0.0000</span>, <span class="number">-0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">         [ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">         [<span class="number">-3.9650</span>,  <span class="number">0.0000</span>, <span class="number">-0.0000</span>,  <span class="number">0.0000</span>]])&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="第十章的诡异装饰器"><a href="#第十章的诡异装饰器" class="headerlink" title="第十章的诡异装饰器"></a>第十章的诡异装饰器</h2><p>作者在这里实现了batcha_size的拼接的方式。<br>具体的函数闭包可以参考python<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># def create_collate_fn():</span></span><br><span class="line"><span class="comment">#     def collate_fn():</span></span><br><span class="line"><span class="comment">#         pass</span></span><br><span class="line"><span class="comment">#     return collate_fn</span></span><br></pre></td></tr></table></figure></p><p>来，猜一下这里为什么这么写，函数闭包，根据昨天看的，函数闭包和类函数有的一拼，或者说可以用于创建多个类似的函数，暂时先这么理解，因为还没有太多的用到，在这里的函数闭包是为了实现对作为函数的参数进行传递变量，也就是把函数作为变量传递，这种思想要注意一下。<br>设想几种情况。<br>假设函数h的定义是这样的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="function"><span class="keyword">def</span> <span class="title">h</span><span class="params">(x, f)</span>:</span></span><br><span class="line">   ...:     <span class="string">"""</span></span><br><span class="line"><span class="string">   ...:     Args:</span></span><br><span class="line"><span class="string">   ...:       x: int</span></span><br><span class="line"><span class="string">   ...:       f: function</span></span><br><span class="line"><span class="string">   ...:     """</span></span><br><span class="line">   ...:     out = f(x)</span><br><span class="line">   ...:     <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">   ...:     <span class="keyword">return</span> <span class="number">2</span>*x</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: h(<span class="number">2</span>,f)</span><br><span class="line">Out[<span class="number">3</span>]: <span class="number">4</span></span><br></pre></td></tr></table></figure></p><p>第一种情况，函数f的所有输入都是h可以给的，那么这时候如上所示，直接定义一个函数，然后把函数名或者其他等于函数的变量传进去就可以。<br>第二种情况，函数f的有一部分变量，需要是外界给的，即f的定义中，引用到了不属于h的输入的变量。就像这样。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">4</span>]: <span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">(i)</span>:</span></span><br><span class="line">   ...:     <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">   ...:         <span class="keyword">return</span> i*x</span><br><span class="line">   ...:     <span class="keyword">return</span> f</span><br><span class="line">   ...:</span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: ff = g(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: h(<span class="number">4</span>,ff)</span><br><span class="line">Out[<span class="number">6</span>]: <span class="number">12</span></span><br></pre></td></tr></table></figure></p><p>那么这个时候函数闭包就可以很好地实现这种想法。<br>这是暂时对于函数闭包的理解，但我知道这种想法肯定是有问题的。</p><hr><h2 id="rnn的pack和pad"><a href="#rnn的pack和pad" class="headerlink" title="rnn的pack和pad"></a>rnn的pack和pad</h2><p>from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_padded_sequence, pad_packed_sequence</span><br><span class="line">li_ = [[<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">0</span>,<span class="number">0</span>]]</span><br><span class="line">ten = t.Tensor(li_).long()</span><br><span class="line">pad_variable = ten</span><br><span class="line">embedding = nn.Embedding(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line">pad_embeddings = embedding(pad_variable)</span><br><span class="line">lengths = [<span class="number">5</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>]</span><br><span class="line">pad_embeddings</span><br><span class="line"></span><br><span class="line">pad_embeddings</span><br><span class="line"></span><br><span class="line">tensor([[[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">         [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">         [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">         [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">         [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">         [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">         [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">         [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">         [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">         [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">         [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">         [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">         [ <span class="number">0.5581</span>,  <span class="number">0.7382</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">         [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">         [ <span class="number">0.5581</span>,  <span class="number">0.7382</span>],</span><br><span class="line">         [ <span class="number">0.5581</span>,  <span class="number">0.7382</span>]]])</span><br><span class="line"></span><br><span class="line">packed_variable = pack_padded_sequence(pad_embeddings, lengths)</span><br><span class="line">PackedSequence(data=tensor([[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">        [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">        [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">        [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>],</span><br><span class="line">        [ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">        [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">        [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">        [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>],</span><br><span class="line">        [ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">        [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">        [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">        [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>],</span><br><span class="line">        [ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">        [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">        [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">        [ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">        [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>]]), batch_sizes=tensor([ <span class="number">4</span>,  <span class="number">4</span>,  <span class="number">4</span>,  <span class="number">3</span>,  <span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">packed_variable.data.shape</span><br><span class="line">torch.Size([<span class="number">17</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">rnn = nn.LSTM(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">output, hn = rnn(packed_variable)</span><br><span class="line"></span><br><span class="line">output</span><br><span class="line">PackedSequence(data=tensor([[<span class="number">-0.1698</span>, <span class="number">-0.1311</span>,  <span class="number">0.2030</span>],</span><br><span class="line">        [<span class="number">-0.0984</span>, <span class="number">-0.0693</span>,  <span class="number">0.1601</span>],</span><br><span class="line">        [<span class="number">-0.0791</span>, <span class="number">-0.1195</span>,  <span class="number">0.2111</span>],</span><br><span class="line">        [<span class="number">-0.0175</span>,  <span class="number">0.0069</span>,  <span class="number">0.0978</span>],</span><br><span class="line">        [<span class="number">-0.2580</span>, <span class="number">-0.1868</span>,  <span class="number">0.3193</span>],</span><br><span class="line">        [<span class="number">-0.1392</span>, <span class="number">-0.0959</span>,  <span class="number">0.2441</span>],</span><br><span class="line">        [<span class="number">-0.1221</span>, <span class="number">-0.1489</span>,  <span class="number">0.3270</span>],</span><br><span class="line">        [<span class="number">-0.0223</span>,  <span class="number">0.0109</span>,  <span class="number">0.1334</span>],</span><br><span class="line">        [<span class="number">-0.3011</span>, <span class="number">-0.2100</span>,  <span class="number">0.3821</span>],</span><br><span class="line">        [<span class="number">-0.1544</span>, <span class="number">-0.1061</span>,  <span class="number">0.2877</span>],</span><br><span class="line">        [<span class="number">-0.1452</span>, <span class="number">-0.1551</span>,  <span class="number">0.3886</span>],</span><br><span class="line">        [<span class="number">-0.0232</span>,  <span class="number">0.0129</span>,  <span class="number">0.1460</span>],</span><br><span class="line">        [<span class="number">-0.3222</span>, <span class="number">-0.2195</span>,  <span class="number">0.4168</span>],</span><br><span class="line">        [<span class="number">-0.1593</span>, <span class="number">-0.1098</span>,  <span class="number">0.3109</span>],</span><br><span class="line">        [<span class="number">-0.1575</span>, <span class="number">-0.1556</span>,  <span class="number">0.4222</span>],</span><br><span class="line">        [<span class="number">-0.3325</span>, <span class="number">-0.2233</span>,  <span class="number">0.4370</span>],</span><br><span class="line">        [<span class="number">-0.1603</span>, <span class="number">-0.1111</span>,  <span class="number">0.3235</span>]]), batch_sizes=tensor([ <span class="number">4</span>,  <span class="number">4</span>,  <span class="number">4</span>,  <span class="number">3</span>,  <span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">hn[<span class="number">1</span>].shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">pad_packed_sequence(packed_variable) </span><br><span class="line">(tensor([[[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">          [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">          [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">          [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>]],</span><br><span class="line"> </span><br><span class="line">         [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">          [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">          [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">          [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>]],</span><br><span class="line"> </span><br><span class="line">         [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">          [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">          [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">          [<span class="number">-0.7936</span>,  <span class="number">0.9621</span>]],</span><br><span class="line"> </span><br><span class="line">         [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">          [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">          [<span class="number">-1.4719</span>, <span class="number">-0.4871</span>],</span><br><span class="line">          [ <span class="number">0.0000</span>,  <span class="number">0.0000</span>]],</span><br><span class="line"> </span><br><span class="line">         [[ <span class="number">0.0256</span>, <span class="number">-1.6445</span>],</span><br><span class="line">          [<span class="number">-0.0939</span>, <span class="number">-0.4070</span>],</span><br><span class="line">          [ <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">          [ <span class="number">0.0000</span>,  <span class="number">0.0000</span>]]]), tensor([ <span class="number">5</span>,  <span class="number">5</span>,  <span class="number">4</span>,  <span class="number">3</span>]))</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># embedding_dim=3, seq_len=4,3 batch_size=2 即把两句话a,b作为一个batch,空余补0</span></span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line">a = t.ones(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">b = t.ones(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">pad_sequence([a,b])</span><br><span class="line">tensor([[[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">         [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a,b两句话，分别有3,2个词，batch_size=2, 共有3个batch_size，大小分别是2,2,1</span></span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line">a = t.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = t.tensor([<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">pack_sequence([a,b])</span><br><span class="line">PackedSequence(data=tensor([ <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">2</span>,  <span class="number">5</span>,  <span class="number">3</span>]), batch_sizes=tensor([ <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">1</span>]))</span><br></pre></td></tr></table></figure><hr><h2 id="beam-searching"><a href="#beam-searching" class="headerlink" title="beam_searching"></a>beam_searching</h2><p>[参考链接]<a href="https://blog.csdn.net/xljiulong/article/details/51554780" target="_blank" rel="noopener">https://blog.csdn.net/xljiulong/article/details/51554780</a><br>[参考链接]<a href="http://jhave.org/algorithms/graphs/beamsearch/beamsearch.shtml" target="_blank" rel="noopener">http://jhave.org/algorithms/graphs/beamsearch/beamsearch.shtml</a><br>网上讲的大部分都有各自的问题，不是很清晰，只有那篇英文才是标准的，这哥们应该是翻译的，还不错<br>作者使用的是beam_searching的变种，原理类似，但是条件不一致，具体的在代码注释中，不再陈述。</p><hr><h2 id="第十章和第九章关于生成语句的流程的区别"><a href="#第十章和第九章关于生成语句的流程的区别" class="headerlink" title="第十章和第九章关于生成语句的流程的区别"></a>第十章和第九章关于生成语句的流程的区别</h2><p>第十章和第九章在模型生成的地方有两个点不一样，<br>第九章的模型本身可以进行正常的输入与输出，所以第九章也写成这个样子<br>输入(LongTensor) 1<em>1 输出 tensor 1</em>vocabsize<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">results = list(start_words)</span><br><span class="line">start_word_len = len(start_words)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(opt.max_gen_len):</span><br><span class="line">    output, hidden = model(input, hidden)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i &lt; start_word_len:</span><br><span class="line">        w = results[i]</span><br><span class="line">        input = input.data.new([word2ix[w]]).view(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># output size 1×vocab_size [[1,2,3,...]]</span></span><br><span class="line">        <span class="comment"># 这里应该看一下，输出output是个什么东西</span></span><br><span class="line">        top_index = output.data[<span class="number">0</span>].topk(<span class="number">1</span>)[<span class="number">1</span>][<span class="number">0</span>].item()</span><br><span class="line">        w = ix2word[top_index]</span><br><span class="line">        results.append(w)</span><br><span class="line">        input = input.data.new([word2ix[w]]).view(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> w == <span class="string">'&lt;EOP&gt;'</span>:</span><br><span class="line">        <span class="keyword">del</span> results[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简写为</span></span><br><span class="line"><span class="comment"># model: embedder rnn classifier</span></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(opt.max_gen_len):</span><br><span class="line">    output, hidden = model(input, hidden) <span class="comment"># input(tensor) 1*1  output(tensor) 1*vocabsize hidden(tensor) 1*1*hidden_dim</span></span><br><span class="line">    top_index = output.data[<span class="number">0</span>].topk(<span class="number">1</span>)[<span class="number">1</span>][<span class="number">0</span>].item()</span><br><span class="line">    w = ix2word(top_index)</span><br><span class="line">    results.append(w)</span><br><span class="line">    </span><br><span class="line">    input = input.data.new(word2ix(w)).view(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> results</span><br></pre></td></tr></table></figure></p><p>第十章因为使用了pack_padded_sequence来加速训练，那么训练的模型就不能直接拿来像第九章进行生成，另外第一个字是图片特征的转化而成的，不需要embedding层，而是需要fc层，其实也可以直接拿来用，把captions设置为空就好了,在这里作者没有直接用，直接用好像比较麻烦。而是采用beam_search中把rnn和classifier层传进去，写了一个标准的beam_search函数，即输入是第一个字，输出是beam_size句话，因为设计到其他选词保留的问题，所以直接传入的的是各个分函数，进行自行拼接。也可能是为了复用logprobs = nn.functional.log_softmax(output, dim=1) ## 暂时不清楚这里为什么用log_softmax，是负数啊，大哥，不过大小好像不变<br>在rnn中有一个问题，就是能不能用t.no_grad,会不会影响其向前传播。</p><hr><h2 id="对数据的预处理"><a href="#对数据的预处理" class="headerlink" title="对数据的预处理"></a>对数据的预处理</h2><p>第九章是把对数据的预处理写在了data里面，但事实上，这个数据预处理应该与主模型分开，是属于前一个过程。有什么需要交互的，也是通过文件进行，包括配置。</p><hr><h2 id="新建立的数据结构的对比大小"><a href="#新建立的数据结构的对比大小" class="headerlink" title="新建立的数据结构的对比大小"></a>新建立的数据结构的对比大小</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Caption</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    现在不太确定这个集合是hash_table还是set，感觉是hash_tale,是因为set不需要专门的存储结构。再看看吧</span></span><br><span class="line"><span class="string">    这里应该不是那三个集合，而是集合中的每一个元素，比如G(i),这种，作者应该是重新创建了一种数据结构来用，来进行存储</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      sentence: list(int)</span></span><br><span class="line"><span class="string">      state: tuple(hn, cn) hn:1*1*hidden_dim</span></span><br><span class="line"><span class="string">      logprob: probability</span></span><br><span class="line"><span class="string">      score: 等于logprb或者logprb/len(sentence)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sentence, state, logprob, score, metadata=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">          sentence(list): </span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.sentence = sentence</span><br><span class="line">        self.state = state</span><br><span class="line">        self.logprob = logprob</span><br><span class="line">        self.score = score</span><br><span class="line">        self.metadata = metadata</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 这里我猜是为了实现堆排序的比较。尽管知道是，但是还是不知道为什么</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__cmp__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="string">"""Compares Captions by score."""</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(other, Caption)</span><br><span class="line">        <span class="keyword">if</span> self.score == other.score:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> self.score &lt; other.score:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># For Python 3 compatibility (__cmp__ is deprecated).</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__lt__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(other, Caption)</span><br><span class="line">        <span class="keyword">return</span> self.score &lt; other.score</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Also for Python 3 compatibility.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__eq__</span><span class="params">(self, other)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(other, Caption)</span><br><span class="line">        <span class="keyword">return</span> self.score == other.score</span><br></pre></td></tr></table></figure><hr><h2 id="作者在固定长度的列表中，使用了小顶堆的方式，来保证每次取出去的都是最小的。"><a href="#作者在固定长度的列表中，使用了小顶堆的方式，来保证每次取出去的都是最小的。" class="headerlink" title="作者在固定长度的列表中，使用了小顶堆的方式，来保证每次取出去的都是最小的。"></a>作者在固定长度的列表中，使用了小顶堆的方式，来保证每次取出去的都是最小的。</h2><hr><h2 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h2><p>现在还有一个问题就是当一个.py文件里的函数或者类超过2、3个时，应该以什么的方式注释才能更好地让别人知道这个文件里的函数和怎么干的。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>第十章的代码在难度上其实已经感觉下降了好多，当然自己又忘了写requires.txt。但是在调试改bug自己就用了三天。其中的bug有的时候自己已经忘记当初是怎么写的了，尴尬。<br>自己训练出来的模型也没有作者声称的那么好，暂时不知道</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;本文主要是针对陈云的PyTorch入门与实践的第八章的内容进行复现，准确地说，是看着他写的代码，自己再实现一遍，所以更多地是在讲解实现过程中遇到的问题或者看到的好的方法，而不是针对论文的原理的进行讲解。对于原理，也只是会一笔带过。原理篇暂时不准备留坑，因为原理是个玄学。&lt;br&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>html</title>
    <link href="http://yoursite.com/2018/09/24/html/"/>
    <id>http://yoursite.com/2018/09/24/html/</id>
    <published>2018-09-24T04:20:24.000Z</published>
    <updated>2018-09-24T08:40:45.746Z</updated>
    
    <content type="html"><![CDATA[<p>HTML 教程<br><a id="more"></a></p><h1 id="html-基础"><a href="#html-基础" class="headerlink" title="html 基础"></a>html 基础</h1><p>因为在visdom中的text支持html标签，所以来简单学学html。<br><a href="http://www.runoob.com/html/html-intro.html" target="_blank" rel="noopener">参考链接:菜鸟教程</a><br>[菜鸟工具在线编辑工具]<a href="https://c.runoob.com/front-end/61" target="_blank" rel="noopener">https://c.runoob.com/front-end/61</a><br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>菜鸟教程(runoob.com)<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>我的第一个标题<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>我的第一个段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>实例解析</p><ul><li>\&lt;!DOCTYPE html&gt; 声明为 HTML5 文档</li><li>&lt;\html&gt; 元素是 HTML 页面的根元素</li><li>&lt;\head&gt; 元素包含了文档的元（meta）数据，如 <meta charset="utf-8"> 定义网页编码格式为 utf-8。</li><li>&lt;\title&gt; 元素描述了文档的标题</li><li><body> 元素包含了可见的页面内容</body></li><li>&lt;\h1&gt; 元素定义一个大标题</li><li>&lt;\p&gt; 元素定义一个段落</li></ul><p>网页结构<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span> 页面标题<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>这是一个标题<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是一个段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是另一个段落<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>只有<body>与</body>之间的元素才会显示</p><p>标题 </p><h1>-<h6>  <h1>这是一个标题</h1><br>段落 <p>  </p><p>这是一个段落。</p> 段前段后有空行<br>链接 <a>  <a href="http://www.runoob.com" target="_blank" rel="noopener">这是一个链接</a><br>图片 <img>  <img src="/images/logo.png" width="258" height="39"><br><img src="/images/logo.png" width="258" height="39"><p></p><h1 id="html元素"><a href="#html元素" class="headerlink" title="html元素"></a>html元素</h1><p><br>空元素标签<br>html属性  html设置属性，常以键值对的形式出现  <a href="http://www.runoob.com" target="_blank" rel="noopener">这是一个链接</a> 常用属性： class id  style title<br>html<br>水平线 <hr><br>换行 <br><br>注释 <!-- 这是一个注释 --><br>格式化标签<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b</span>&gt;</span>加粗文本<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">i</span>&gt;</span>斜体文本<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">code</span>&gt;</span>电脑自动输出<span class="tag">&lt;/<span class="name">code</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">这是 <span class="tag">&lt;<span class="name">sub</span>&gt;</span> 下标<span class="tag">&lt;/<span class="name">sub</span>&gt;</span> 和 <span class="tag">&lt;<span class="name">sup</span>&gt;</span> 上标<span class="tag">&lt;/<span class="name">sup</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">small</span>&gt;</span>这个文本是缩小的<span class="tag">&lt;/<span class="name">small</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">big</span>&gt;</span>这个文本字体放大<span class="tag">&lt;/<span class="name">big</span>&gt;</span></span><br></pre></td></tr></table></figure></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&lt;pre&gt;</span></span><br><span class="line">此例演示如何使用 <span class="keyword">pre</span> 标签</span><br><span class="line">对空行和    空格</span><br><span class="line">进行控制</span><br><span class="line">&lt;/<span class="keyword">pre</span>&gt;</span><br><span class="line"></span><br><span class="line">此例演示如何使用 <span class="keyword">pre</span> 标签</span><br><span class="line">对空行和    空格</span><br><span class="line">进行控制</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">code</span>&gt;</span>计算机输出<span class="tag">&lt;/<span class="name">code</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">kbd</span>&gt;</span>键盘输入<span class="tag">&lt;/<span class="name">kbd</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">tt</span>&gt;</span>打字机文本<span class="tag">&lt;/<span class="name">tt</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">samp</span>&gt;</span>计算机代码样本<span class="tag">&lt;/<span class="name">samp</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">var</span>&gt;</span>计算机变量<span class="tag">&lt;/<span class="name">var</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br></pre></td></tr></table></figure><p>地址<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">address</span>&gt;</span></span><br><span class="line">Written by <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"mailto:webmaster@example.com"</span>&gt;</span>Jon Doe<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.<span class="tag">&lt;<span class="name">br</span>&gt;</span> </span><br><span class="line">Visit us at:<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">Example.com<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">Box 564, Disneyland<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">USA</span><br><span class="line"><span class="tag">&lt;/<span class="name">address</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>创建电子邮件标签</p><p>首字母缩写和缩写<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">abbr</span> <span class="attr">title</span>=<span class="string">"etcetera"</span>&gt;</span>etc.<span class="tag">&lt;/<span class="name">abbr</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">acronym</span> <span class="attr">title</span>=<span class="string">"World Wide Web"</span>&gt;</span>WWW<span class="tag">&lt;/<span class="name">acronym</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>文字显示方向<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;p&gt;<span class="xml"><span class="tag">&lt;<span class="name">bdo</span> <span class="attr">dir</span>=<span class="string">"rtl"</span>&gt;</span>该段落文字从右到左显示。<span class="tag">&lt;/<span class="name">bdo</span>&gt;</span></span><span class="xml"><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br></pre></td></tr></table></figure></p><p>块引用<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;p&gt;WWF's goal <span class="keyword">is</span> <span class="keyword">to</span>: </span><br><span class="line">&lt;q&gt;Build a future <span class="keyword">where</span> people live <span class="keyword">in</span> harmony <span class="keyword">with</span> nature.&lt;/q&gt;</span><br><span class="line">We hope they succeed.&lt;/p&gt;</span><br></pre></td></tr></table></figure></p><p>删除字和插入字的效果<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>My favorite color is <span class="tag">&lt;<span class="name">del</span>&gt;</span>blue<span class="tag">&lt;/<span class="name">del</span>&gt;</span> <span class="tag">&lt;<span class="name">ins</span>&gt;</span>red<span class="tag">&lt;/<span class="name">ins</span>&gt;</span>!<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>html 链接属性 target:定义文档在哪个窗口打开 id属性<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;a <span class="attribute">href</span>=<span class="string">"http://www.runoob.com/"</span> <span class="attribute">target</span>=<span class="string">"_blank"</span>&gt;访问菜鸟教程!&lt;/a&gt;</span><br></pre></td></tr></table></figure></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#C4"</span>&gt;</span>查看章节 4<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">id</span>=<span class="string">"C4"</span>&gt;</span>章节 4<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>这边显示该章节的内容……<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="html"><a href="#html" class="headerlink" title="html "></a>html <head></head></h1><p><title>, <style>, <meta>, <link>, <script>, <noscript>, and <base>.</p><p><title> </p><ul><li>定义了浏览器工具栏的标题</li><li>当网页添加到收藏夹时，显示在收藏夹中的标题</li><li>显示在搜索引擎结果页面的标题<br><base> 标签描述了基本的链接地址/链接目标，该标签作为HTML文档中所有的链接标签的默认链接 <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;base <span class="attribute">href</span>=<span class="string">"http://www.runoob.com/images/"</span> <span class="attribute">target</span>=<span class="string">"_blank"</span>&gt;</span><br></pre></td></tr></table></figure></li></ul><p><link> 标签定义了文档与外部资源之间的关系。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link <span class="attribute">rel</span>=<span class="string">"stylesheet"</span> <span class="attribute">type</span>=<span class="string">"text/css"</span> <span class="attribute">href</span>=<span class="string">"mystyle.css"</span>&gt;</span><br></pre></td></tr></table></figure></p><p><style> 标签定义了HTML文档的样式文件引用地址.<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">style</span> <span class="attr">type</span>=<span class="string">"text/css"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="css"><span class="selector-tag">body</span> &#123;<span class="attribute">background-color</span>:yellow&#125;</span></span><br><span class="line"><span class="css"><span class="selector-tag">p</span> &#123;<span class="attribute">color</span>:blue&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p><meta> 元素 META 元素通常用于指定网页的描述，关键词，文件的最后修改时间，作者，和其他元数据。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;meta <span class="attribute">name</span>=<span class="string">"keywords"</span> <span class="attribute">content</span>=<span class="string">"HTML, CSS, XML, XHTML, JavaScript"</span>&gt;</span><br><span class="line">&lt;meta <span class="attribute">name</span>=<span class="string">"description"</span> <span class="attribute">content</span>=<span class="string">"免费 Web &amp; 编程 教程"</span>&gt;</span><br><span class="line">&lt;meta <span class="attribute">http-equiv</span>=<span class="string">"refresh"</span> <span class="attribute">content</span>=<span class="string">"30"</span>&gt;</span><br></pre></td></tr></table></figure></p><h1 id="HTML-样式-CSS"><a href="#HTML-样式-CSS" class="headerlink" title="HTML 样式- CSS"></a>HTML 样式- CSS</h1><p>CSS (Cascading Style Sheets) 用于渲染HTML元素标签的样式.<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 使用添加到 <span class="tag">&lt;<span class="name">head</span>&gt;</span> 部分的样式信息对 HTML 进行格式化 内部样式表 应用于单个文件</span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>菜鸟教程(runoob.com)<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span> <span class="attr">type</span>=<span class="string">"text/css"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="css"><span class="selector-tag">h1</span> &#123;<span class="attribute">color</span>:red;&#125;</span></span><br><span class="line"><span class="css"><span class="selector-tag">p</span> &#123;<span class="attribute">color</span>:blue;&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"># 使用 style 属性制作一个没有下划线的链接 内联样式 应用于个别元素</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.runoob.com/"</span> <span class="attr">style</span>=<span class="string">"text-decoration:none;"</span>&gt;</span>访问 runoob.com!<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">#  标签链接到一个外部样式表 外部引用</span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>菜鸟教程(runoob.com)<span class="tag">&lt;/<span class="name">title</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">type</span>=<span class="string">"text/css"</span> <span class="attr">href</span>=<span class="string">"styles.css"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">font-family（字体），color（颜色），和font-size（字体大小）， text-align（文字对齐）</span><br><span class="line"></span><br><span class="line"># 图像</span><br></pre></td></tr></table></figure></p><p><img src="smiley.gif" alt="Smiley face" style="float:left" width="32" height="32"><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 表格</span></span><br></pre></td></tr></table></figure></p><p><table border="1"><br>    <tr><br>        <th>Header 1</th><br>        <th>Header 2</th><br>    </tr><br>    <tr><br>        <td>row 1, cell 1</td><br>        <td>row 1, cell 2</td><br>    </tr><br>    <tr><br>        <td>row 2, cell 1</td><br>        <td>row 2, cell 2</td><br>    </tr><br></table><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 列表</span></span><br></pre></td></tr></table></figure></p><ul><br>  <li>Coffee</li><br>  <li>Tea</li><br>  <li>Milk</li><br></ul><ol><br>  <li>Coffee</li><br>  <li>Tea</li><br>  <li>Milk</li><br></ol><ol start="50"><br>  <li>Coffee</li><br>  <li>Tea</li><br>  <li>Milk</li><br></ol><p><code>`</code></p><h1 id="区块-块级和-内联级"><a href="#区块-块级和-内联级" class="headerlink" title="区块  块级和 内联级"></a>区块 <div> 块级和<span> 内联级</h1><h1 id="表单"><a href="#表单" class="headerlink" title="表单"></a>表单</h1></style></title></p></a></h6></h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HTML 教程&lt;br&gt;
    
    </summary>
    
      <category term="html" scheme="http://yoursite.com/categories/html/"/>
    
    
      <category term="html" scheme="http://yoursite.com/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>python-picture</title>
    <link href="http://yoursite.com/2018/09/24/python-picture/"/>
    <id>http://yoursite.com/2018/09/24/python-picture/</id>
    <published>2018-09-24T04:08:02.000Z</published>
    <updated>2018-09-24T05:46:13.394Z</updated>
    
    <content type="html"><![CDATA[<h1 id="针对图像的操作-cv2-matplotlib-pylab-PIL-Image"><a href="#针对图像的操作-cv2-matplotlib-pylab-PIL-Image" class="headerlink" title="针对图像的操作 cv2, matplotlib.pylab, PIL.Image"></a>针对图像的操作 cv2, matplotlib.pylab, PIL.Image</h1><p>一般用PIL.Image或者cv2来打开或者保存，用matplotlib.pylab来显示<br>在pytorch中也可以用tv.utils.save_image()专门来保存图片。<br><a id="more"></a></p><h2 id="cv2"><a href="#cv2" class="headerlink" title="cv2"></a>cv2</h2><p><a href="https://www.jianshu.com/p/3977d674da85" target="_blank" rel="noopener">参考链接</a><br>注意：pylab.imread和PIL.Image.open读入的都是RBG顺序，而cv2.imread读入的是BGR顺序，混合使用的时候要特别注意<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img = cv2.imread(<span class="string">'examples.png'</span>) <span class="comment"># # 默认是读入为彩色图，即使原图是灰度图也会复制成三个相同的通道变成彩色图</span></span><br><span class="line">img_gray = cv2.imread(<span class="string">'examples.png'</span>,<span class="number">0</span>) <span class="comment"># 第二个参数为0的时候读入为灰度图，即使原图是彩色图也会转成灰度图</span></span><br><span class="line">print(type(img), img.dtype, np.min(img), np.max(img))</span><br><span class="line">print(img.shape)</span><br><span class="line">print(img_gray.shape)</span><br><span class="line"></span><br><span class="line">(&lt;type <span class="string">'numpy.ndarray'</span>&gt;, dtype(<span class="string">'uint8'</span>), <span class="number">0</span>, <span class="number">255</span>)    <span class="comment"># opencv读进来的是numpy数组，类型是uint8，0-255</span></span><br><span class="line">(<span class="number">824</span>, <span class="number">987</span>, <span class="number">3</span>)    <span class="comment"># 彩色图3通道</span></span><br><span class="line">(<span class="number">824</span>, <span class="number">987</span>)    <span class="comment"># 灰度图单通道</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示</span></span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">img = cv2.imread(<span class="string">'examples.png'</span>) </span><br><span class="line">plt.imshow(img[..., <span class="number">-1</span>::<span class="number">-1</span>]) <span class="comment"># 因为opencv读取进来的是bgr顺序呢的，而imshow需要的是rgb顺序，因此需要先反过来 plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 灰度与RGB转化</span></span><br><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plt </span><br><span class="line">img = cv2.imread(<span class="string">'examples.png'</span>) </span><br><span class="line">img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) <span class="comment"># BGR转灰度 </span></span><br><span class="line">img_bgr = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR) <span class="comment"># 灰度转BRG </span></span><br><span class="line">img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB) <span class="comment"># 也可以灰度转RGB</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 保存图片</span></span><br><span class="line"><span class="keyword">import</span> cv2 img = cv2.imread(<span class="string">'examples.png'</span>) <span class="comment"># 这是BGR图片 </span></span><br><span class="line">cv2.imwrite(<span class="string">'examples2.png'</span>, img) <span class="comment"># 这里也应该用BGR图片保存，这里要非常注意，因为用pylab或PIL读入的图片都是RGB的，如果要用opencv存图片就必须做一个转换 </span></span><br><span class="line">img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) </span><br><span class="line">cv2.imwrite(<span class="string">'examples_gray.png'</span>, img_gray)</span><br></pre></td></tr></table></figure></p><h2 id="matplotlib-pylab"><a href="#matplotlib-pylab" class="headerlink" title="matplotlib.pylab"></a>matplotlib.pylab</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img = plt.imread(<span class="string">'examples.png'</span>)</span><br><span class="line">print(type(img), img.dtype, np.min(img), np.max(img))</span><br><span class="line">[out]</span><br><span class="line">(&lt;type <span class="string">'numpy.ndarray'</span>&gt;, dtype(<span class="string">'float32'</span>), <span class="number">0.0</span>, <span class="number">1.0</span>)    <span class="comment"># matplotlib读取进来的图片是float，0-1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示</span></span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line"><span class="comment"># 有两种</span></span><br><span class="line"><span class="comment"># 其实产生这个现象的原因很简单：在 plt.show() 后调用了 plt.savefig() ，在 plt.show() 后实际上已经创建了一个新的空白的图片（坐标轴），这时候你再 plt.savefig() 就会保存这个新生成的空白图片</span></span><br><span class="line"><span class="comment"># ref:(https://blog.csdn.net/u010099080/article/details/52912439)</span></span><br><span class="line"><span class="comment"># 第一种:在plt.show之前保存</span></span><br><span class="line">plt.savefig(<span class="string">'test.png'</span>)</span><br><span class="line"><span class="comment"># 第二种:画图的时候保存句柄</span></span><br><span class="line">fig = plt.gcf()</span><br><span class="line">plt.show()</span><br><span class="line">fig.savefig(<span class="string">'test.png'</span>)</span><br></pre></td></tr></table></figure><h2 id="PIL-Image"><a href="#PIL-Image" class="headerlink" title="PIL.Image"></a>PIL.Image</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img = Image.open(<span class="string">'examples.jpg'</span>)</span><br><span class="line">print(type(img), img.dtype, np.min(img), np.max(img))</span><br><span class="line">img = np.array(img)     <span class="comment"># 将PIL格式图片转为numpy格式</span></span><br><span class="line">print(type(img), img.dtype, np.min(img), np.max(img))</span><br><span class="line"></span><br><span class="line">(&lt;class 'PIL.PngImagePlugin.PngImageFile'&gt;, 0, 255) # 注意，PIL是有自己的数据结构的，但是可以转换成numpy数组 </span><br><span class="line">(&lt;type <span class="string">'numpy.ndarray'</span>&gt;, dtype(<span class="string">'uint8'</span>), <span class="number">0</span>, <span class="number">255</span>) <span class="comment"># 和用matplotlib读取不同，PIL和matlab相同，读进来图片和其存储在硬盘的样子是一样的，uint8，0-255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 灰度和RGB转化</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image </span><br><span class="line">img = Image.open(<span class="string">'examples.png'</span>) </span><br><span class="line">img_gray = img.convert(<span class="string">'L'</span>) <span class="comment"># RGB转换成灰度图像 i</span></span><br><span class="line">mg_rgb = img_gray.convert(<span class="string">'RGB'</span>) <span class="comment"># 灰度转RGB </span></span><br><span class="line">print(img) </span><br><span class="line">print(img_gray) </span><br><span class="line">print(img_rgb) </span><br><span class="line">[out] </span><br><span class="line">&lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=<span class="number">987</span>x824 at <span class="number">0x7FC2CCAE04D0</span>&gt; </span><br><span class="line">&lt;PIL.Image.Image image mode=L size=<span class="number">987</span>x824 at <span class="number">0x7FC2CCAE0990</span>&gt; </span><br><span class="line">&lt;PIL.Image.Image image mode=RGB size=<span class="number">987</span>x824 at <span class="number">0x7FC2CCAE0250</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img = Image.open(<span class="string">'examples.png'</span>) </span><br><span class="line">img_gray = img.convert(<span class="string">'L'</span>) <span class="comment">#转换成灰度图像 </span></span><br><span class="line">img = np.array(img) </span><br><span class="line">img_gray = np.array(img_gray) </span><br><span class="line">plt.imshow(img) <span class="comment"># or plt.imshow(img / 255.0)，matplotlib和matlab一样，如果是float类型的图像，范围是0-1才能正常imshow，如果是uint8图像，范围则需要是0-255 </span></span><br><span class="line">plt.show() </span><br><span class="line">plt.imshow(img_gray, cmap=plt.gray()) <span class="comment"># 显示灰度图要设置cmap参数 </span></span><br><span class="line">plt.show() </span><br><span class="line">plt.imshow(Image.open(<span class="string">'examples.png'</span>)) <span class="comment"># 实际上plt.imshow可以直接显示PIL格式图像 plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line">img = Image.open(<span class="string">'examples.png'</span>) </span><br><span class="line">img.save(<span class="string">'examples2.png'</span>) </span><br><span class="line">img_gray = img.convert(<span class="string">'L'</span>) </span><br><span class="line">img_gray.save(<span class="string">'examples_gray.png'</span>) <span class="comment"># 不管是灰度还是彩色，直接用save函数保存就可以，但注意，只有PIL格式的图片能够用save函数</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;针对图像的操作-cv2-matplotlib-pylab-PIL-Image&quot;&gt;&lt;a href=&quot;#针对图像的操作-cv2-matplotlib-pylab-PIL-Image&quot; class=&quot;headerlink&quot; title=&quot;针对图像的操作 cv2, matplotlib.pylab, PIL.Image&quot;&gt;&lt;/a&gt;针对图像的操作 cv2, matplotlib.pylab, PIL.Image&lt;/h1&gt;&lt;p&gt;一般用PIL.Image或者cv2来打开或者保存，用matplotlib.pylab来显示&lt;br&gt;在pytorch中也可以用tv.utils.save_image()专门来保存图片。&lt;br&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python,picture" scheme="http://yoursite.com/tags/python-picture/"/>
    
  </entry>
  
  <entry>
    <title>CMC</title>
    <link href="http://yoursite.com/2018/09/24/CMC/"/>
    <id>http://yoursite.com/2018/09/24/CMC/</id>
    <published>2018-09-24T04:00:17.000Z</published>
    <updated>2018-09-24T05:46:07.768Z</updated>
    
    <content type="html"><![CDATA[<h1 id="rank-1-rank-5-mAP"><a href="#rank-1-rank-5-mAP" class="headerlink" title="rank-1,rank-5,mAP"></a>rank-1,rank-5,mAP</h1><a id="more"></a><h2 id="第一种，网上的标准计算公式"><a href="#第一种，网上的标准计算公式" class="headerlink" title="第一种，网上的标准计算公式"></a>第一种，网上的标准计算公式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">indexxx = np.array([[<span class="number">8</span>,<span class="number">9</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">9</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">0</span>],[<span class="number">7</span>,<span class="number">9</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">0</span>]])</span><br><span class="line">good_index = np.array([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>])</span><br><span class="line">CMC = np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line">mAP = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> indexxx:</span><br><span class="line">    cmc = np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line">    index = i</span><br><span class="line">    ngood = len(good_index)</span><br><span class="line">    mask = np.in1d(index, good_index)</span><br><span class="line">    rows_good = np.argwhere(mask==<span class="keyword">True</span>)</span><br><span class="line">    rows_good = rows_good.flatten()</span><br><span class="line">    cmc[rows_good[<span class="number">0</span>]:] = <span class="number">1</span></span><br><span class="line">    print(<span class="string">'cmc:'</span>,cmc)</span><br><span class="line">    CMC += cmc</span><br><span class="line"></span><br><span class="line">    ap = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(ngood):</span><br><span class="line">        d_recall = <span class="number">1.0</span>/ngood</span><br><span class="line">        precision = (i+<span class="number">1</span>)*<span class="number">1.0</span>/(rows_good[i]+<span class="number">1</span>)</span><br><span class="line">        ap = ap + d_recall*precision</span><br><span class="line">    print(<span class="string">'ap:&#123;:.2f&#125;%:'</span>.format(<span class="number">100</span>*ap))</span><br><span class="line">    mAP += ap</span><br><span class="line"></span><br><span class="line">CMC = CMC/<span class="number">3</span></span><br><span class="line">mAP = mAP/<span class="number">3</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'top1:&#123;:.2f&#125;%  top5:&#123;:.2f&#125;%  mAP:&#123;:.2f&#125;%'</span>.format(<span class="number">100</span>*CMC[<span class="number">0</span>],<span class="number">100</span>*CMC[<span class="number">4</span>],<span class="number">100</span>*mAP))</span><br><span class="line"></span><br><span class="line">cmc: [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">ap:<span class="number">54.54</span>%</span><br><span class="line">cmc: [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">ap:<span class="number">69.26</span>%</span><br><span class="line">cmc: [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">ap:<span class="number">100.00</span>%</span><br><span class="line">top1:<span class="number">66.67</span>%  top5:<span class="number">100.00</span>%  mAP:<span class="number">74.60</span>%</span><br></pre></td></tr></table></figure><h3 id="第二种：baseline的计算公式"><a href="#第二种：baseline的计算公式" class="headerlink" title="第二种：baseline的计算公式"></a>第二种：baseline的计算公式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_mAP</span><span class="params">(index, good_index, junk_index)</span>:</span></span><br><span class="line">    ap = <span class="number">0</span></span><br><span class="line">    cmc = torch.IntTensor(len(index)).zero_()</span><br><span class="line">    <span class="keyword">if</span> good_index.size==<span class="number">0</span>:   <span class="comment"># if empty</span></span><br><span class="line">        cmc[<span class="number">0</span>] = <span class="number">-1</span></span><br><span class="line">        <span class="keyword">return</span> ap,cmc</span><br><span class="line"></span><br><span class="line">    <span class="comment"># remove junk_index</span></span><br><span class="line">    mask = np.in1d(index, junk_index, invert=<span class="keyword">True</span>)</span><br><span class="line">    index = index[mask]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># find good_index index</span></span><br><span class="line">    ngood = len(good_index)</span><br><span class="line">    mask = np.in1d(index, good_index)</span><br><span class="line">    rows_good = np.argwhere(mask==<span class="keyword">True</span>)</span><br><span class="line">    rows_good = rows_good.flatten()</span><br><span class="line">    </span><br><span class="line">    cmc[rows_good[<span class="number">0</span>]:] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(ngood):</span><br><span class="line">        d_recall = <span class="number">1.0</span>/ngood</span><br><span class="line">        precision = (i+<span class="number">1</span>)*<span class="number">1.0</span>/(rows_good[i]+<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> rows_good[i]!=<span class="number">0</span>:</span><br><span class="line">            old_precision = i*<span class="number">1.0</span>/rows_good[i]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            old_precision=<span class="number">1.0</span></span><br><span class="line">        ap = ap + d_recall*(old_precision + precision)/<span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ap, cmc</span><br><span class="line"></span><br><span class="line">CMC = torch.IntTensor(len(gallery_label)).zero_()</span><br><span class="line">ap = <span class="number">0.0</span></span><br><span class="line"><span class="comment">#print(query_label)</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(query_label)):</span><br><span class="line">    ap_tmp, CMC_tmp = evaluate(query_feature[i],query_label[i],query_cam[i],gallery_feature,gallery_label,gallery_cam)</span><br><span class="line">    <span class="keyword">if</span> CMC_tmp[<span class="number">0</span>]==<span class="number">-1</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    CMC = CMC + CMC_tmp</span><br><span class="line">    ap += ap_tmp</span><br><span class="line">    print(i, CMC_tmp[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">CMC = CMC.float()</span><br><span class="line">CMC = CMC/len(query_label) <span class="comment">#average CMC</span></span><br><span class="line">print(<span class="string">'top1:%f top5:%f top10:%f mAP:%f'</span>%(CMC[<span class="number">0</span>],CMC[<span class="number">4</span>],CMC[<span class="number">9</span>],ap/len(query_label)))</span><br></pre></td></tr></table></figure><h3 id="第二种的简化版本，只计算CMC"><a href="#第二种的简化版本，只计算CMC" class="headerlink" title="第二种的简化版本，只计算CMC"></a>第二种的简化版本，只计算CMC</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(qf,ql,qc,gf,gl,gc)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    qf: list [1,2,3]</span></span><br><span class="line"><span class="string">    ql: 1</span></span><br><span class="line"><span class="string">    qc: 1</span></span><br><span class="line"><span class="string">    gf: list [[1,2,3],[1,2,3]]</span></span><br><span class="line"><span class="string">    gl: [1,2,3]</span></span><br><span class="line"><span class="string">    gc: [1,2,3]</span></span><br><span class="line"><span class="string">    len(gf)==len(gl)==len(gc)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    query = qf</span><br><span class="line">    score = np.dot(gf,query)</span><br><span class="line">    <span class="comment"># predict index</span></span><br><span class="line">    index = np.argsort(score)  <span class="comment">#from small to large # 表示位置，[4,3,1,0,2]</span></span><br><span class="line">    index = index[::<span class="number">-1</span>] <span class="comment"># 表示</span></span><br><span class="line">    <span class="comment">#index = index[0:2000]</span></span><br><span class="line">    <span class="comment"># good index</span></span><br><span class="line">    query_index = np.argwhere(gl==ql) <span class="comment"># list [[1],[2]] # 表示位置，即galley中的第几个样本是相同的id</span></span><br><span class="line">    camera_index = np.argwhere(gc==qc) <span class="comment"># list [[1],[2]] # 表示位置</span></span><br><span class="line"></span><br><span class="line">    good_index = np.setdiff1d(query_index, camera_index, assume_unique=<span class="keyword">True</span>) <span class="comment"># [2,3]表示同一个id不同摄像头的图片的位置</span></span><br><span class="line">    junk_index1 = np.argwhere(gl==<span class="number">-1</span>) <span class="comment">#  [[1],[2]] 表示id为-1的图片的位置</span></span><br><span class="line">    junk_index2 = np.intersect1d(query_index, camera_index) <span class="comment">#  [1,2] 表示同一个id同一个摄像头的图片的位置</span></span><br><span class="line">    junk_index = np.append(junk_index2, junk_index1) <span class="comment">#.flatten())</span></span><br><span class="line">    </span><br><span class="line">    CMC_tmp = compute_mAP(index, good_index, junk_index)</span><br><span class="line">    <span class="keyword">return</span> CMC_tmp</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_cmc</span><span class="params">(index, good_index, junk_index)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    index: list [4,3,1,0,2]，已经排序，数字表示第几张图片</span></span><br><span class="line"><span class="string">    good_index: [3,1] list 位置 数字表示第几张图片</span></span><br><span class="line"><span class="string">    junk_index: [4,2]list 位置 数字表示第几张图片</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    cmc = torch.IntTensor(len(index)).zero_()</span><br><span class="line">    <span class="keyword">if</span> good_index.size==<span class="number">0</span>:   <span class="comment"># if empty</span></span><br><span class="line">        cmc[<span class="number">0</span>] = <span class="number">-1</span></span><br><span class="line">        <span class="keyword">return</span> ap,cmc</span><br><span class="line"></span><br><span class="line">    <span class="comment"># remove junk_index</span></span><br><span class="line">    mask = np.in1d(index, junk_index, invert=<span class="keyword">True</span>)</span><br><span class="line">    index = index[mask]  <span class="comment"># [3,1,0]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># find good_index index</span></span><br><span class="line">    ngood = len(good_index)</span><br><span class="line">    mask = np.in1d(index, good_index) <span class="comment"># [t,t,f]</span></span><br><span class="line">    rows_good = np.argwhere(mask==<span class="keyword">True</span>) <span class="comment"># </span></span><br><span class="line">    rows_good = rows_good.flatten() <span class="comment"># [0,1]</span></span><br><span class="line">    </span><br><span class="line">    cmc[rows_good[<span class="number">0</span>]:] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cmc</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    result = scipy.io.loadmat(<span class="string">'pytorch_result.mat'</span>)</span><br><span class="line">    query_feature = result[<span class="string">'query_f'</span>]  <span class="comment"># list [[1,2,3],[1,2,3],[1,2,3]]</span></span><br><span class="line">    query_cam = result[<span class="string">'query_cam'</span>][<span class="number">0</span>] <span class="comment"># list [1,2,3]</span></span><br><span class="line">    query_label = result[<span class="string">'query_label'</span>][<span class="number">0</span>] <span class="comment"># list [1,2,3]</span></span><br><span class="line">    gallery_feature = result[<span class="string">'gallery_f'</span>]  <span class="comment"># list [[1,2,3],[1,2,3],[1,2,3]]</span></span><br><span class="line">    gallery_cam = result[<span class="string">'gallery_cam'</span>][<span class="number">0</span>] <span class="comment"># list [1,2,3]</span></span><br><span class="line">    gallery_label = result[<span class="string">'gallery_label'</span>][<span class="number">0</span>] <span class="comment"># list [1,2,3]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    CMC = torch.IntTensor(len(gallery_label)).zero_()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(query_label)):</span><br><span class="line">        CMC_tmp = evaluate(query_feature[i],query_label[i],query_cam[i],gallery_feature,gallery_label,gallery_cam)</span><br><span class="line">        <span class="keyword">if</span> CMC_tmp[<span class="number">0</span>]==<span class="number">-1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        CMC = CMC + CMC_tmp</span><br><span class="line">        print(i, CMC_tmp[<span class="number">0</span>])</span><br><span class="line">    CMC = CMC.float()</span><br><span class="line">    CMC = CMC/len(query_label) <span class="comment">#average CMC</span></span><br><span class="line">    print(<span class="string">'top1:%f top5:%f top10:%f'</span>%(CMC[<span class="number">0</span>],CMC[<span class="number">4</span>],CMC[<span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_id</span><span class="params">(img_path)</span>:</span></span><br><span class="line">    camera_id = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> path, v <span class="keyword">in</span> img_path:</span><br><span class="line">        filename = path.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        label = filename[<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">        camera = filename.split(<span class="string">'c'</span>)[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> label[<span class="number">0</span>:<span class="number">2</span>]==<span class="string">'-1'</span>:</span><br><span class="line">            labels.append(<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            labels.append(int(label))</span><br><span class="line">        camera_id.append(int(camera[<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> camera_id, labels</span><br><span class="line"></span><br><span class="line">gallery_cam,gallery_label = get_id(gallery_path)</span><br><span class="line">query_cam,query_label = get_id(query_path)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;rank-1-rank-5-mAP&quot;&gt;&lt;a href=&quot;#rank-1-rank-5-mAP&quot; class=&quot;headerlink&quot; title=&quot;rank-1,rank-5,mAP&quot;&gt;&lt;/a&gt;rank-1,rank-5,mAP&lt;/h1&gt;
    
    </summary>
    
      <category term="person-reid" scheme="http://yoursite.com/categories/person-reid/"/>
    
    
      <category term="CMC" scheme="http://yoursite.com/tags/CMC/"/>
    
  </entry>
  
  <entry>
    <title>pytorch chapter9 CharRNN</title>
    <link href="http://yoursite.com/2018/09/23/pytorch-chapter9-CharRNN/"/>
    <id>http://yoursite.com/2018/09/23/pytorch-chapter9-CharRNN/</id>
    <published>2018-09-23T15:04:12.000Z</published>
    <updated>2018-09-30T06:40:41.242Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文主要是针对陈云的PyTorch入门与实践的第八章的内容进行复现，准确地说，是看着他写的代码，自己再实现一遍，所以更多地是在讲解实现过程中遇到的问题或者看到的好的方法，而不是针对论文的原理的进行讲解。对于原理，也只是会一笔带过。原理篇暂时不准备留坑，因为原理是个玄学。<br>这是我的<a href="https://github.com/TJJTJJTJJ/pytorch__learn" target="_blank" rel="noopener">代码</a><br>大神链接：<a href="https://github.com/anishathalye/neural-style" target="_blank" rel="noopener">https://github.com/anishathalye/neural-style</a><br>这是论文作者写的<br><a id="more"></a></p><hr><h1 id="问题及其思考"><a href="#问题及其思考" class="headerlink" title="问题及其思考"></a>问题及其思考</h1><h2 id="data是鸭子类型"><a href="#data是鸭子类型" class="headerlink" title="data是鸭子类型"></a>data是鸭子类型</h2><p>因为data作为tensor，已经实现了__getitem__和__len__方法，可以被DataLoader加载。<br>或者说，只要能类似鸭子就可以，这方面掌握得还不熟悉。</p><h2 id="LSTM的输入"><a href="#LSTM的输入" class="headerlink" title="LSTM的输入"></a>LSTM的输入</h2><p>作者明确提出，LSTM的输入类型是(seq_len, batch_size, embedding_dim)，除去embedding_dim，就是(seq_len, batch_size)，原因很简单，LSTM是每次输入一个字，输出一个字，那么输入就是x[0]，对于图像，x[0]就是一张图片，那么对于文字，x[0]也应该就是一个字。好吧，还是说不通，等以后看了相关资料说不定才能理解。</p><h2 id="代码编写"><a href="#代码编写" class="headerlink" title="代码编写"></a>代码编写</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 变成列表，方便后续的操作，因为start_words的每个字用过之后就没用了，</span><br><span class="line"># 用<span class="keyword">pop</span>不行,因为对于空列表会报错,用None作为结尾标志。可以看出，如果我们想让某个序列正常退出，可以通过设置特殊的结尾来实现。</span><br><span class="line"># 这一段的逻辑有点乱，因为prefix_words可能没有，所以对于start_words，必须先进行一个模型生成。</span><br><span class="line"># 对于或有或无的perfix_words，为了消除其存在对代码和思路的影响，应该保证prefix_words前后的代码状态不变，即</span><br><span class="line"><span class="string">""</span><span class="comment">"</span></span><br><span class="line">第一种</span><br><span class="line">这种保证了output,hidden的状态不变</span><br><span class="line">output, hidden = model(<span class="built_in">input</span>, hidden)</span><br><span class="line"></span><br><span class="line"># step： 对prefix_words进行输入</span><br><span class="line">prefix_words = <span class="string">''</span> <span class="keyword">if</span> prefix_words==None <span class="keyword">else</span> prefix_words    </span><br><span class="line"><span class="keyword">for</span> word in prefix_word<span class="variable">s:</span></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.data.<span class="keyword">new</span>(word2ix[word]).<span class="keyword">view</span>(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    output, hidden = model(<span class="built_in">input</span>, hidden)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="keyword">opt</span>.max_gen_len-<span class="number">1</span>):</span><br><span class="line">    top_index = output[<span class="number">0</span>].topk(<span class="number">1</span>)[<span class="number">1</span>][<span class="number">0</span>].item()    </span><br><span class="line">    ...</span><br><span class="line">    output, hidden = model(<span class="built_in">input</span>, hidden)</span><br><span class="line"></span><br><span class="line">第二种</span><br><span class="line">这种保证了<span class="built_in">input</span>的状态不变</span><br><span class="line"><span class="keyword">for</span> word in prefix_word<span class="variable">s:</span></span><br><span class="line">    output, hidden = model(<span class="built_in">input</span>, hidden)</span><br><span class="line">    <span class="built_in">input</span> = (<span class="built_in">input</span>.data.<span class="keyword">new</span>([word2ix[word]])).<span class="keyword">view</span>(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="keyword">opt</span>.max_gen_len):</span><br><span class="line">    output, hidden = model(<span class="built_in">input</span>, hidden)</span><br><span class="line">    top_index = output.data[<span class="number">0</span>].topk(<span class="number">1</span>)[<span class="number">1</span>][<span class="number">0</span>].item()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">决定采用第二种，因为代码的主体思路是<span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="keyword">opt</span>.max_gen_len)，prefix_word是插入部分，是可有可无部分。</span><br><span class="line">第一种会造成 top_index与model的切分，不利于后期分析。</span><br><span class="line">或者说，以后碰到这种类型的代码，可以直接跳过中间部分，对后面进行分析。</span><br></pre></td></tr></table></figure><hr><h2 id="os-walk-amp-amp-os-listdir"><a href="#os-walk-amp-amp-os-listdir" class="headerlink" title="os.walk()  &amp;&amp; os.listdir()"></a>os.walk()  &amp;&amp; os.listdir()</h2><h3 id="os-walk"><a href="#os-walk" class="headerlink" title="os.walk()"></a>os.walk()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">6</span>]: <span class="keyword">for</span> i,j,k <span class="keyword">in</span> os.walk(<span class="string">'./'</span>):</span><br><span class="line">   ...:     print(i)</span><br><span class="line">./</span><br><span class="line">./b</span><br><span class="line">./a</span><br><span class="line">./a/aa2</span><br><span class="line">./a/aa1</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: <span class="keyword">for</span> i,j,k <span class="keyword">in</span> os.walk(<span class="string">'./'</span>):</span><br><span class="line">   ...:     print(j)   </span><br><span class="line">[<span class="string">'b'</span>, <span class="string">'a'</span>]</span><br><span class="line">[]</span><br><span class="line">[<span class="string">'aa2'</span>, <span class="string">'aa1'</span>]</span><br><span class="line">[]</span><br><span class="line">[]</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: <span class="keyword">for</span> i,j,k <span class="keyword">in</span> os.walk(<span class="string">'./'</span>):</span><br><span class="line">   ...:     print(k)</span><br><span class="line">[<span class="string">'1'</span>]</span><br><span class="line">[<span class="string">'cc'</span>, <span class="string">'bb'</span>]</span><br><span class="line">[<span class="string">'aa'</span>]</span><br><span class="line">[<span class="string">'bbb'</span>]</span><br><span class="line">[]</span><br><span class="line"></span><br><span class="line">i+k即可</span><br></pre></td></tr></table></figure><p>os.walk()返回的是当前文件夹下所有的可遍历的文件夹，生成的生成器，i表示文件夹，j表示i文件夹下的文件夹，k表示i文件夹下的文件。以上是os.walk的for用法，下面是直接的用法。对于文件访问，直接i+k，对于文件夹访问，i+j即可。</p><h3 id="os-listdir"><a href="#os-listdir" class="headerlink" title="os.listdir()"></a>os.listdir()</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">17</span>]: aa = os.walk(<span class="string">'./'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: bb = list(aa)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: bb</span><br><span class="line">Out[<span class="number">19</span>]: </span><br><span class="line">[(<span class="string">'./'</span>, [<span class="string">'b'</span>, <span class="string">'a'</span>], [<span class="string">'1'</span>]),</span><br><span class="line"> (<span class="string">'./b'</span>, [], [<span class="string">'cc'</span>, <span class="string">'bb'</span>]),</span><br><span class="line"> (<span class="string">'./a'</span>, [<span class="string">'aa2'</span>, <span class="string">'aa1'</span>], [<span class="string">'aa'</span>]),</span><br><span class="line"> (<span class="string">'./a/aa2'</span>, [], [<span class="string">'bbb'</span>]),</span><br><span class="line"> (<span class="string">'./a/aa1'</span>, [], [])]</span><br></pre></td></tr></table></figure><p>不知道为什么这里不能直接用 aa,bb,cc = os.walk(‘./‘)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">22</span>]: <span class="keyword">for</span> ii <span class="keyword">in</span> os.listdir(<span class="string">'./'</span>):</span><br><span class="line">    ...:     print(ii)</span><br><span class="line">    ...:     </span><br><span class="line"><span class="number">1</span></span><br><span class="line">b</span><br><span class="line">a</span><br><span class="line">In [<span class="number">23</span>]: aa = os.listdir(<span class="string">'./'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: aa</span><br><span class="line">Out[<span class="number">24</span>]: [<span class="string">'1'</span>, <span class="string">'b'</span>, <span class="string">'a'</span>]</span><br></pre></td></tr></table></figure></p><p>os.listdir()返回的是当前文件夹下的文件夹或者文件。<br>现在碰到的情况是文件夹排列有序，直接访问文件，所以os.list()就可以了。<br>对应的就是<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(src):</span><br><span class="line">      path = os.path.join(src,filename)</span><br></pre></td></tr></table></figure></p><hr><h2 id="小发现"><a href="#小发现" class="headerlink" title="小发现"></a>小发现</h2><ul><li>刚刚发现github上的chinese中的某个文件夹是一个新的github文件。这是个啥情况</li><li>python 可以在函数内部定义函数，是局部域，不能被外界访问，很好，这样就相当于说明了哪些函数是为哪些函数服务的。</li></ul><hr><h2 id="json数据格式的读取"><a href="#json数据格式的读取" class="headerlink" title="json数据格式的读取"></a>json数据格式的读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">25</span>]: <span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: s = &#123;<span class="string">"name"</span>: <span class="string">"ACME"</span>, <span class="string">"shares"</span>: <span class="number">50</span>, <span class="string">"price"</span>: <span class="number">490.1</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: json_str = json.dumps(s)</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: json_str.__class__</span><br><span class="line">Out[<span class="number">28</span>]: str</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: json_str</span><br><span class="line">Out[<span class="number">29</span>]: <span class="string">'&#123;"name": "ACME", "shares": 50, "price": 490.1&#125;'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: ss = json.loads(json_str)</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: ss</span><br><span class="line">Out[<span class="number">34</span>]: &#123;<span class="string">'name'</span>: <span class="string">'ACME'</span>, <span class="string">'shares'</span>: <span class="number">50</span>, <span class="string">'price'</span>: <span class="number">490.1</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="json文件的读取"><a href="#json文件的读取" class="headerlink" title="json文件的读取"></a>json文件的读取</h2><p>第一种:此时data里是该文件内的全部数据<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(file,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = json.load(f)</span><br></pre></td></tr></table></figure></p><p>第二种：此时data也是该文件内的全部数据，open(file).read()表示读取数据<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = json.loads(open(file).read())</span><br></pre></td></tr></table></figure></p><p>显然第一种安全，第二种还需要显示地关闭文件<br>可以使用pprint来打印data，好看<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pprint <span class="keyword">import</span> pprint </span><br><span class="line">pprint data</span><br></pre></td></tr></table></figure></p><hr><h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><p>普通字符和11个元字符：<br>.  匹配任意除换行符”\n”外的字符(在DOTALL模式中也能匹配换行符 a.c<br>\  转义字符，使后一个字符改变原来的意思<br>*  匹配前一个字符0或多次<br>+  匹配前一个字符1次或无限次<br>?  匹配一个字符0次或1次<br>^  匹配字符串开头。在多行模式中匹配每一行的开头<br>$  匹配字符串末尾，在多行模式中匹配每一行的末尾<br>|  或。匹配|左右表达式任意一个，从左到右匹配，如果|没有包括在()中，则它的范围是整个正则表达式<br>{} {m}匹配前一个字符m次，{m,n}匹配前一个字符m至n次，若省略n，则匹配m至无限次<br>[] 字符集。对应的位置可以是字符集中任意字符。字符集中的字符可以逐个列出，也可以给出范围，如[abc]或[a-c]。[^abc]表示取反，即非abc。<br>所有特殊字符在字符集中都失去其原有的特殊含义。用\反斜杠转义恢复特殊字符的特殊含义。<br>()表达式作为一个整体，可以后接数量词。表达式中的|仅在该组中有效。<br>print re.split(r”;|,|\?”, line1)<br>print re.split(r”[;,?]”, line1)<br>print re.split(r”\W+”, line)<br>不知道为什么<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">para = <span class="string">'-181-欲出未出光辣达，[千山]万山[如火]发（哈哈哈大笑）。须臾[走向][天上]'</span></span><br><span class="line">re.subn(<span class="string">'[\d-]'</span>,<span class="string">''</span>,para)</span><br><span class="line">(<span class="string">'欲出未出光辣达，[千山]万山[如火]发（哈哈哈大笑）。须臾[走向][天上]'</span>, <span class="number">5</span>)</span><br><span class="line">re.subn(<span class="string">'[\d-]*'</span>,<span class="string">''</span>,para)</span><br><span class="line">(<span class="string">'欲出未出光辣达，[千山]万山[如火]发（哈哈哈大笑）。须臾[走向][天上]'</span>, <span class="number">38</span>)</span><br></pre></td></tr></table></figure></p><hr><h2 id="list越界与切片"><a href="#list越界与切片" class="headerlink" title="list越界与切片"></a>list越界与切片</h2><p>list不能越界索引访问，但是对于切片，切片是会自动匹配长度的，所以使用slice不需要担心越界问题。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">s[<span class="number">8</span>] <span class="comment"># 报错</span></span><br><span class="line">s[<span class="number">1</span>] == <span class="number">1</span></span><br><span class="line">s[:<span class="number">1</span>] == [<span class="number">1</span>]</span><br><span class="line">s[<span class="number">1</span>:<span class="number">10</span>] <span class="comment"># return s[1:3]</span></span><br></pre></td></tr></table></figure></p><p>索引位置返回的是元素的副本<br>切片返回的是list的副本</p><hr><h2 id="嵌套列表压平"><a href="#嵌套列表压平" class="headerlink" title="嵌套列表压平"></a>嵌套列表压平</h2><p>func = lambda x: [y for l in x for y in l] if type(x) is list else [x]</p><hr><h2 id="tuple的连接"><a href="#tuple的连接" class="headerlink" title="tuple的连接"></a>tuple的连接</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1</span>,<span class="number">2</span>)+(<span class="number">3</span>,<span class="number">4</span>) == (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 定义只有一个数字的tuple，避免函数歧义</span></span><br><span class="line">t = (<span class="number">1</span>,)</span><br></pre></td></tr></table></figure><h2 id="求list的size"><a href="#求list的size" class="headerlink" title="求list的size"></a>求list的size</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">li = [[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">tu = np.asarray(li).shape</span><br><span class="line"><span class="comment"># shape返回的是tuple型，可以直接拼接</span></span><br></pre></td></tr></table></figure><hr><h2 id="异常触发"><a href="#异常触发" class="headerlink" title="异常触发"></a>异常触发</h2><p><a href="https://www.cnblogs.com/ospider/p/5267766.html" target="_blank" rel="noopener">参考链接</a><a href="http://www.runoob.com/python/python-exceptions.html" target="_blank" rel="noopener">http://www.runoob.com/python/python-exceptions.html</a><br>等总结的时候尝试一下<br>分为捕捉异常和触发异常</p><h3 id="捕捉异常"><a href="#捕捉异常" class="headerlink" title="捕捉异常"></a>捕捉异常</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 捕捉异常第一种 try/except语句</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">&lt;语句&gt;        <span class="comment">#运行别的代码</span></span><br><span class="line"><span class="keyword">except</span> &lt;名字&gt;：</span><br><span class="line">&lt;语句&gt;        <span class="comment">#如果在try部份引发了'name'异常</span></span><br><span class="line"><span class="keyword">except</span> &lt;名字&gt;，&lt;数据&gt;:</span><br><span class="line">&lt;语句&gt;        <span class="comment">#如果引发了'name'异常，获得附加的数据</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">&lt;语句&gt;        <span class="comment">#如果没有异常发生</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 捕捉异常第二种 try/finally</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">&lt;语句&gt;</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">&lt;语句&gt;    <span class="comment">#退出try时总会执行</span></span><br><span class="line"><span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例1</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"> </span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    f = open(<span class="string">'myfile.txt'</span>)</span><br><span class="line">    s = f.readline()</span><br><span class="line">    i = int(s.strip())</span><br><span class="line"><span class="keyword">except</span> OSError <span class="keyword">as</span> err:</span><br><span class="line">    print(<span class="string">"OS error: &#123;0&#125;"</span>.format(err))</span><br><span class="line"><span class="keyword">except</span> ValueError:</span><br><span class="line">    print(<span class="string">"Could not convert data to an integer."</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"Unexpected error:"</span>, sys.exc_info()[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例2</span></span><br><span class="line">如果你只想知道这是否抛出了一个异常，并不想去处理它，那么一个简单的 <span class="keyword">raise</span> 语句就可以再次把它抛出。</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">raise</span> NameError(<span class="string">'HiThere'</span>)</span><br><span class="line"><span class="keyword">except</span> NameError:</span><br><span class="line">    print(<span class="string">'An exception flew by!'</span>)</span><br><span class="line">    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例3</span></span><br><span class="line">处理有参数的异常</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">temp_convert</span><span class="params">(var)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> int(var)</span><br><span class="line">    <span class="keyword">except</span> (ValueError) <span class="keyword">as</span> Argument:</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"参数没有包含数字\n"</span>, Argument)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用函数</span></span><br><span class="line">temp_convert(<span class="string">"xyz"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment"># 捕捉异常共同使用</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    fh = open(<span class="string">"testfile"</span>, <span class="string">"w"</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        fh.write(<span class="string">"这是一个测试文件，用于测试异常!!"</span>)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"关闭文件"</span></span><br><span class="line">        fh.close()</span><br><span class="line"><span class="keyword">except</span> IOError:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Error: 没有找到文件或读取文件失败"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注</span></span><br><span class="line"><span class="keyword">except</span> (RuntimeError, TypeError, NameError):</span><br></pre></td></tr></table></figure><h3 id="触发异常"><a href="#触发异常" class="headerlink" title="触发异常"></a>触发异常</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 函数触发异常</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">functionName</span><span class="params">( level )</span>:</span></span><br><span class="line">    <span class="keyword">if</span> level &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"Invalid level!"</span>, level)</span><br><span class="line">        <span class="comment"># 触发异常后，后面的代码就不会再执行</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 捕捉异常和触发异常的配合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mye</span><span class="params">( level )</span>:</span></span><br><span class="line">    <span class="keyword">if</span> level &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"Invalid level!"</span>)</span><br><span class="line">        <span class="comment"># 触发异常后，后面的代码就不会再执行</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    mye(<span class="number">0</span>)            <span class="comment"># 触发异常</span></span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">    <span class="keyword">print</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><h3 id="自定义异常"><a href="#自定义异常" class="headerlink" title="自定义异常"></a>自定义异常</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="class"><span class="keyword">class</span> <span class="title">MyError</span><span class="params">(Exception)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value)</span>:</span></span><br><span class="line">            self.value = value</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> repr(self.value)</span><br><span class="line">   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">raise</span> MyError(<span class="number">2</span>*<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">except</span> MyError <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">'My exception occurred, value:'</span>, e.value)</span><br></pre></td></tr></table></figure><hr><h2 id="list的更新"><a href="#list的更新" class="headerlink" title="list的更新"></a>list的更新</h2><p>更新分为逐元素更新和逐列表更新</p><h3 id="逐元素更新"><a href="#逐元素更新" class="headerlink" title="逐元素更新"></a>逐元素更新</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># list的逐元素更新</span></span><br><span class="line">li = [] </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    li.append(i)</span><br><span class="line"><span class="comment"># 对于空列表，等价于</span></span><br><span class="line">li = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br><span class="line"><span class="comment"># 或者等价于generator</span></span><br><span class="line">li = (i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>))</span><br><span class="line"><span class="comment"># 或者转化为逐列表更新,常用与列表头和列表尾同时更新</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    li=[i]+li+[i+<span class="number">11</span>]</span><br><span class="line"><span class="comment"># 或者对于已经得到的元素</span></span><br><span class="line">[a,b,c]</span><br></pre></td></tr></table></figure><p>即对于一个空列表的append，我们总是可以将其转化成列表推导式，<br>并且对于dict和set，只需要将中括号换成大括号即可</p><h3 id="逐列表更新"><a href="#逐列表更新" class="headerlink" title="逐列表更新"></a>逐列表更新</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># list的逐列表更新</span></span><br><span class="line">li = []</span><br><span class="line">ll = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ll:</span><br><span class="line">    li.extend(i)</span><br><span class="line">li</span><br><span class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="comment"># 或者对于有限个列表</span></span><br><span class="line">c = a+b</span><br></pre></td></tr></table></figure><p>注：append()和extend()和+=都是在原有列表增加，+是生成一个新的列表<br>感觉逐列表更新应该可以更优美.</p><h2 id="os-path-join"><a href="#os-path-join" class="headerlink" title="os.path.join()"></a>os.path.join()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">42</span>]: <span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'bbbb'</span>,<span class="string">'ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: aaaa/bbbb/ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'/aaaa'</span>,<span class="string">'bbbb'</span>,<span class="string">'ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: /aaaa/bbbb/ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'/bbbb'</span>,<span class="string">'ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: /bbbb/ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'bbbb'</span>,<span class="string">'/ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: /ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'/bbbb'</span>,<span class="string">'/ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: /ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'./bbbb'</span>,<span class="string">'ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: aaaa/./bbbb/ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'../bbbb'</span>,<span class="string">'ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: aaaa/../bbbb/ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'bbbb'</span>,<span class="string">'./ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: aaaa/bbbb/./ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'bbbb'</span>,<span class="string">'../ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: aaaa/bbbb/../ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'/bbbb'</span>,<span class="string">'....../ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: /bbbb/....../ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'bbbb/'</span>,<span class="string">'ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: aaaa/bbbb/ccccc.txt</span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: print(<span class="string">"1:"</span>,os.path.join(<span class="string">'aaaa'</span>,<span class="string">'bbbb\\'</span>,<span class="string">'ccccc.txt'</span>))</span><br><span class="line"><span class="number">1</span>: aaaa/bbbb\/ccccc.txt</span><br></pre></td></tr></table></figure><p>对os.path.join()总结如下：从后往前，遇到绝对路径，则绝对路径前面的元素丢弃，遇到类似’…/‘，则将其看成一个普通的路径名字，而对于/在末尾的，会自动根据情况补充。</p><h2 id="list-和-的区别，字符串分割成单个字符"><a href="#list-和-的区别，字符串分割成单个字符" class="headerlink" title="list()和[]的区别，字符串分割成单个字符"></a>list()和[]的区别，字符串分割成单个字符</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">58</span>]: list(<span class="string">'abcd'</span>)</span><br><span class="line">Out[<span class="number">58</span>]: [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: [<span class="string">'abcd'</span>]</span><br><span class="line">Out[<span class="number">59</span>]: [<span class="string">'abcd'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: aa = (<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: list(aa)</span><br><span class="line">Out[<span class="number">62</span>]: [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: [aa]</span><br><span class="line">Out[<span class="number">63</span>]: [(<span class="number">1</span>, <span class="number">2</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: bb = [<span class="string">'abc'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: list(*bb)</span><br><span class="line">Out[<span class="number">66</span>]: [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">'abcd'</span>:</span><br><span class="line">    print(i)</span><br></pre></td></tr></table></figure><p>即，list()会拆解输入值，拼接成list，可以用在’abcd’这样的字符串直接拆成’a’,’b’,’c’,’d’这样的形式，因为re.split不支持这种拆分法。当然，如果只是单纯地逐元素访问并逐元素地进行操作，我们可以使用for i in ‘abcd’:这样的访问。<br>也可以认为是’’.join()的逆操作<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">65</span>]: bb = [<span class="string">'abc'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: list(*bb)</span><br><span class="line">Out[<span class="number">66</span>]: [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: <span class="string">''</span>.join(list(bb))</span><br><span class="line">Out[<span class="number">71</span>]: <span class="string">'abc'</span></span><br></pre></td></tr></table></figure></p><hr><h2 id="list、dict和numpy的互相转换"><a href="#list、dict和numpy的互相转换" class="headerlink" title="list、dict和numpy的互相转换"></a>list、dict和numpy的互相转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">74</span>]: c = np.array(&#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>&#125;)</span><br><span class="line">In [<span class="number">75</span>]: c[<span class="number">0</span>]</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">IndexError                                Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input<span class="number">-75</span><span class="number">-71463270</span>cd6c&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; 1 c[0]</span><br><span class="line"></span><br><span class="line">IndexError: too many indices <span class="keyword">for</span> array</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: c</span><br><span class="line">Out[<span class="number">77</span>]: array(&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;, dtype=object)</span><br><span class="line">In [<span class="number">79</span>]: c.tolist()</span><br><span class="line">Out[<span class="number">79</span>]: &#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">80</span>]: d = c.tolist()</span><br><span class="line"></span><br><span class="line">In [<span class="number">81</span>]: d.__class__</span><br><span class="line">Out[<span class="number">81</span>]: dict</span><br></pre></td></tr></table></figure><h2 id="shell的基础教程"><a href="#shell的基础教程" class="headerlink" title="shell的基础教程"></a>shell的基础教程</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for fff in `ls *.json`</span><br><span class="line">do</span><br><span class="line">cconv -f utf8-tw  -t UTF8-CN $fff  -o simplified/$fff</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">for skill in Ada Coffe Action Java; do</span><br><span class="line">    echo "I am good at $&#123;skill&#125;Script"</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="shell-传递参数"><a href="#shell-传递参数" class="headerlink" title="shell 传递参数"></a>shell 传递参数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> author:菜鸟教程</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> url:www.runoob.com</span></span><br><span class="line"></span><br><span class="line">echo "Shell 传递参数实例！";</span><br><span class="line">echo "执行的文件名：$0";</span><br><span class="line">echo "第一个参数为：$1";</span><br><span class="line">echo "第二个参数为：$2";</span><br><span class="line">echo "第三个参数为：$3";</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod +x test.sh </span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ./test.sh 1 2 3</span></span><br><span class="line">Shell 传递参数实例！</span><br><span class="line">执行的文件名：./test.sh</span><br><span class="line">第一个参数为：1</span><br><span class="line">第二个参数为：2</span><br><span class="line">第三个参数为：3</span><br></pre></td></tr></table></figure><h3 id="shell-流程控制"><a href="#shell-流程控制" class="headerlink" title="shell 流程控制"></a>shell 流程控制</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if condition1</span><br><span class="line">then</span><br><span class="line">    command1</span><br><span class="line">elif condition2 </span><br><span class="line">then </span><br><span class="line">    command2</span><br><span class="line">else</span><br><span class="line">    commandN</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="Shell-输入-输出重定向"><a href="#Shell-输入-输出重定向" class="headerlink" title="Shell 输入/输出重定向"></a>Shell 输入/输出重定向</h3><p>命令                           说明<br>command &gt; file    将输出重定向到 file。<br>command &lt; file    将输入重定向到 file。<br>command &gt;&gt; file    将输出以追加的方式重定向到 file。<br>n &gt; file    将文件描述符为 n 的文件重定向到 file。<br>n &gt;&gt; file    将文件描述符为 n 的文件以追加的方式重定向到 file。<br>n &gt;&amp; m    将输出文件 m 和 n 合并。<br>n &lt;&amp; m    将输入文件 m 和 n 合并。<br>&lt;&lt; tag    将开始标记 tag 和结束标记 tag 之间的内容作为输入。<br>需要注意的是文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 如果希望 stderr 重定向到 file，可以这样写：</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">command</span> 2 &gt; file</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果希望将 stdout 和 stderr 合并后重定向到 file</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">command</span> &gt; file 2&gt;&amp;1</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">command</span> &gt;&gt; file 2&gt;&amp;1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果希望对 stdin 和 stdout 都重定向</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">command</span> &lt; file1 &gt;file2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">Here Document 是 Shell 中的一种特殊的重定向方式，用来将输入重定向到一个交互式 Shell 脚本或程序。</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> wc -l &lt;&lt; EOF</span></span><br><span class="line">    欢迎来到</span><br><span class="line">    菜鸟教程</span><br><span class="line">    www.runoob.com</span><br><span class="line">EOF</span><br><span class="line">3          # 输出结果为 3 行</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null：</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">command</span> &gt; /dev/null</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果希望屏蔽 stdout 和 stderr，可以这样写：</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">command</span> &gt; /dev/null 2&gt;&amp;1</span></span><br></pre></td></tr></table></figure></p><hr><h2 id="str-split-‘’"><a href="#str-split-‘’" class="headerlink" title="str.split(‘’)"></a>str.split(‘’)</h2><p>以列表形式返回<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">label_dim = <span class="string">'16803+100'</span></span><br><span class="line">cc = label_dim.split(<span class="string">'+'</span>)</span><br><span class="line">cc</span><br><span class="line">[<span class="string">'16803'</span>,<span class="string">'100'</span>]</span><br></pre></td></tr></table></figure></p><h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scales_tr = <span class="string">'20,20--20,20'</span></span><br><span class="line">scale = [map(int, x.split(<span class="string">','</span>)) <span class="keyword">for</span> x <span class="keyword">in</span> scales_tr.split(<span class="string">'--'</span>)]</span><br><span class="line">scale</span><br><span class="line">[&lt;map at <span class="number">0x7fd798714748</span>&gt;, &lt;map at <span class="number">0x7fd798714588</span>&gt;]</span><br><span class="line">list(scale[<span class="number">0</span>])</span><br><span class="line">[<span class="number">20</span>,<span class="number">20</span>]</span><br></pre></td></tr></table></figure><hr><h2 id="tensor的拼接-t-cat-t-stack"><a href="#tensor的拼接-t-cat-t-stack" class="headerlink" title="tensor的拼接 t.cat t.stack"></a>tensor的拼接 t.cat t.stack</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> index:</span><br><span class="line"><span class="comment"># tensor的截取与合并  cat, stack,cat+view=stack,stack 新增维度进行合并</span></span><br><span class="line">    result.append(fake_img.data[ii])</span><br><span class="line">tv.utils.save_image(t.stack(result), opt.gen_img, normalize=<span class="keyword">True</span>, range=(<span class="number">-1</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure><h2 id="tensor-view"><a href="#tensor-view" class="headerlink" title="tensor.view()"></a>tensor.view()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = x.view(x.size(<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">x = x.view(x.size()[<span class="number">0</span>],<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><hr><h2 id="Inception-V3"><a href="#Inception-V3" class="headerlink" title="Inception-V3"></a>Inception-V3</h2><p><a href="https://www.cnblogs.com/ospider/p/5267766.html" target="_blank" rel="noopener">参考链接</a><a href="https://www.jianshu.com/p/3bbf0675cfce" target="_blank" rel="noopener">https://www.jianshu.com/p/3bbf0675cfce</a><br><a href="https://blog.csdn.net/loveliuzz/article/details/79135583" target="_blank" rel="noopener">https://blog.csdn.net/loveliuzz/article/details/79135583</a><br>其中都有一些错误，还需要看着源码纠正一下。</p><hr><h2 id="python-文件IO"><a href="#python-文件IO" class="headerlink" title="python 文件IO"></a>python 文件IO</h2><p>python中的三个读read(),readline()和readlines()<br>.read() 每次读取整个文件，它通常用于将文件内容放到一个字符串变量中，然而 .read() 生成文件内容最直接的字符串表示，但对于连续的面向行的处理，它却是不必要的<br>.readlines()之间的差异是后者一次读取整个文件，象 .read()一样。.readlines()自动将文件内容分析成一个行的列表，该列表可以由 Python 的 for… in … 结构进行处理<br>.readline()每次只读取一行</p><h2 id="python打开多个文件"><a href="#python打开多个文件" class="headerlink" title="python打开多个文件"></a>python打开多个文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'a.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> a, open(<span class="string">'b.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> b:</span><br><span class="line">    print(a.read())</span><br><span class="line">    print(b.read())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">open_many</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, files=None, mode=<span class="string">'r'</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> files <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self._files = []</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self._files = files</span><br><span class="line">        self.mode = mode</span><br><span class="line">        self.fds = []  <span class="comment"># fd is short for file descriptor</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__enter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'--&gt;enter'</span>)</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> self._files:</span><br><span class="line">            print(<span class="string">'--&gt;opening file'</span>)</span><br><span class="line">            self.fds.append(open(f, self.mode))</span><br><span class="line">        <span class="keyword">return</span> self.fds</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__exit__</span><span class="params">(self, exc_type, exc_val, traceback)</span>:</span></span><br><span class="line">        print(<span class="string">'--&gt;exit'</span>)</span><br><span class="line">        <span class="keyword">for</span> fd <span class="keyword">in</span> self.fds:</span><br><span class="line">            print(<span class="string">'--&gt;closing file'</span>)</span><br><span class="line">            fd.close()</span><br><span class="line">        <span class="keyword">if</span> exc_type == ValueError:</span><br><span class="line">            print(<span class="string">'--&gt;exception: '</span> + str(exc_val))</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">with</span> open_many([<span class="string">'a.txt'</span>, <span class="string">'b.txt'</span>], <span class="string">'r'</span>) <span class="keyword">as</span> files:</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">print</span> f.read()</span><br><span class="line">    print(<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">with</span> open_many() <span class="keyword">as</span> files:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'captured'</span>)</span><br><span class="line">    print(<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">with</span> open_many() <span class="keyword">as</span> files:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">'uncaptureable'</span>)</span><br></pre></td></tr></table></figure><h2 id="python-csv"><a href="#python-csv" class="headerlink" title="python csv"></a>python csv</h2><p>在使用常规的读取文件的方法的时候，出现了问题，每一个数字包括小数点都被当成了一个字符，这样明显是不对的，对于数字的csv，要考虑下这个方法，我感觉应该和写的方式有关，待续。<br><a href="https://www.cnblogs.com/ospider/p/5267766.html" target="_blank" rel="noopener">参考链接</a><a href="https://www.cnblogs.com/dmir/p/5009075.html" target="_blank" rel="noopener">https://www.cnblogs.com/dmir/p/5009075.html</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(path) <span class="keyword">as</span> f:</span><br><span class="line">    f_csv = csv.reader(f)</span><br><span class="line">    headers = next(f_csv)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> f_csv:</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">csv_data = pd.read_csv(path)</span><br></pre></td></tr></table></figure><hr><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>优化器与模型参数完全共享内存，一个改变，另一个会立即跟着改变。<br>不能重复加载同一个参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种</span></span><br><span class="line">optimizer = t.optim.Adam(model.parameters(), lr = <span class="number">0.1</span>)</span><br><span class="line">optimizer</span><br><span class="line"></span><br><span class="line">Adam (</span><br><span class="line">Parameter Group <span class="number">0</span></span><br><span class="line">    amsgrad: <span class="keyword">False</span></span><br><span class="line">    betas: (<span class="number">0.9</span>, <span class="number">0.999</span>)</span><br><span class="line">    eps: <span class="number">1e-08</span></span><br><span class="line">    lr: <span class="number">0.1</span></span><br><span class="line">    weight_decay: <span class="number">0</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">    print(i)</span><br><span class="line">    print(<span class="string">'______'</span>)</span><br><span class="line">    </span><br><span class="line">&#123;<span class="string">'params'</span>: [Parameter containing:</span><br><span class="line">tensor([[[[ <span class="number">0.0493</span>,  <span class="number">0.1696</span>,  <span class="number">0.0647</span>],</span><br><span class="line">          [ <span class="number">0.1935</span>,  <span class="number">0.3102</span>, <span class="number">-0.0871</span>],</span><br><span class="line">          [<span class="number">-0.2787</span>,  <span class="number">0.0894</span>, <span class="number">-0.0438</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">-0.2671</span>,  <span class="number">0.2079</span>,  <span class="number">0.2474</span>],</span><br><span class="line">          [ <span class="number">0.2068</span>, <span class="number">-0.1825</span>,  <span class="number">0.1427</span>],</span><br><span class="line">          [<span class="number">-0.0853</span>, <span class="number">-0.1799</span>, <span class="number">-0.2465</span>]]]]), Parameter containing:</span><br><span class="line">tensor([<span class="number">-0.3158</span>,  <span class="number">0.1429</span>]), Parameter containing:</span><br><span class="line">tensor([[[[ <span class="number">0.2063</span>,  <span class="number">0.0771</span>,  <span class="number">0.1579</span>],</span><br><span class="line">          [ <span class="number">0.1543</span>,  <span class="number">0.1374</span>, <span class="number">-0.1951</span>],</span><br><span class="line">          [<span class="number">-0.1221</span>,  <span class="number">0.0099</span>, <span class="number">-0.1331</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">-0.1899</span>,  <span class="number">0.1978</span>,  <span class="number">0.1065</span>],</span><br><span class="line">          [ <span class="number">0.1400</span>, <span class="number">-0.0740</span>,  <span class="number">0.0397</span>],</span><br><span class="line">          [<span class="number">-0.2165</span>, <span class="number">-0.0180</span>,  <span class="number">0.1072</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.0692</span>, <span class="number">-0.1296</span>,  <span class="number">0.0524</span>],</span><br><span class="line">          [ <span class="number">0.0577</span>, <span class="number">-0.1184</span>,  <span class="number">0.0697</span>],</span><br><span class="line">          [ <span class="number">0.0859</span>, <span class="number">-0.2086</span>,  <span class="number">0.0419</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">-0.0270</span>,  <span class="number">0.1836</span>, <span class="number">-0.0649</span>],</span><br><span class="line">          [ <span class="number">0.1680</span>, <span class="number">-0.1061</span>, <span class="number">-0.2357</span>],</span><br><span class="line">          [<span class="number">-0.0408</span>,  <span class="number">0.0799</span>,  <span class="number">0.0065</span>]]]]), Parameter containing:</span><br><span class="line">tensor([ <span class="number">0.1269</span>, <span class="number">-0.1582</span>]), Parameter containing:</span><br><span class="line">tensor([[[[ <span class="number">0.0185</span>, <span class="number">-0.2579</span>, <span class="number">-0.1185</span>],</span><br><span class="line">          [ <span class="number">0.1269</span>,  <span class="number">0.0274</span>,  <span class="number">0.1019</span>],</span><br><span class="line">          [ <span class="number">0.0329</span>, <span class="number">-0.1229</span>, <span class="number">-0.1922</span>]]]]), Parameter containing:</span><br><span class="line">tensor([<span class="number">-0.2731</span>])], <span class="string">'lr'</span>: <span class="number">0.1</span>, <span class="string">'betas'</span>: (<span class="number">0.9</span>, <span class="number">0.999</span>), <span class="string">'eps'</span>: <span class="number">1e-08</span>, <span class="string">'weight_decay'</span>: <span class="number">0</span>, <span class="string">'amsgrad'</span>: <span class="keyword">False</span>&#125;</span><br><span class="line">______    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># 第二种</span></span><br><span class="line">optimizer = t.optim.Adam([&#123;<span class="string">'params'</span>:model.net1.parameters(),<span class="string">'lr'</span>:<span class="number">0.4</span>&#125;, &#123;<span class="string">'params'</span>:model.net2.parameters(),<span class="string">'lr'</span>:<span class="number">0.1</span>&#125;],lr=<span class="number">0.04</span>)</span><br><span class="line"></span><br><span class="line">optimizer</span><br><span class="line"></span><br><span class="line">Adam (</span><br><span class="line">Parameter Group <span class="number">0</span></span><br><span class="line">    amsgrad: <span class="keyword">False</span></span><br><span class="line">    betas: (<span class="number">0.9</span>, <span class="number">0.999</span>)</span><br><span class="line">    eps: <span class="number">1e-08</span></span><br><span class="line">    lr: <span class="number">0.4</span></span><br><span class="line">    weight_decay: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">Parameter Group <span class="number">1</span></span><br><span class="line">    amsgrad: <span class="keyword">False</span></span><br><span class="line">    betas: (<span class="number">0.9</span>, <span class="number">0.999</span>)</span><br><span class="line">    eps: <span class="number">1e-08</span></span><br><span class="line">    lr: <span class="number">0.1</span></span><br><span class="line">    weight_decay: <span class="number">0</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">    print(i)</span><br><span class="line">    print(<span class="string">'______'</span>)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">'params'</span>: [Parameter containing:</span><br><span class="line">tensor([[[[ <span class="number">0.0493</span>,  <span class="number">0.1696</span>,  <span class="number">0.0647</span>],</span><br><span class="line">          [ <span class="number">0.1935</span>,  <span class="number">0.3102</span>, <span class="number">-0.0871</span>],</span><br><span class="line">          [<span class="number">-0.2787</span>,  <span class="number">0.0894</span>, <span class="number">-0.0438</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">-0.2671</span>,  <span class="number">0.2079</span>,  <span class="number">0.2474</span>],</span><br><span class="line">          [ <span class="number">0.2068</span>, <span class="number">-0.1825</span>,  <span class="number">0.1427</span>],</span><br><span class="line">          [<span class="number">-0.0853</span>, <span class="number">-0.1799</span>, <span class="number">-0.2465</span>]]]]), Parameter containing:</span><br><span class="line">tensor([<span class="number">-0.3158</span>,  <span class="number">0.1429</span>])], <span class="string">'lr'</span>: <span class="number">0.4</span>, <span class="string">'betas'</span>: (<span class="number">0.9</span>, <span class="number">0.999</span>), <span class="string">'eps'</span>: <span class="number">1e-08</span>, <span class="string">'weight_decay'</span>: <span class="number">0</span>, <span class="string">'amsgrad'</span>: <span class="keyword">False</span>&#125;</span><br><span class="line">______</span><br><span class="line">&#123;<span class="string">'params'</span>: [Parameter containing:</span><br><span class="line">tensor([[[[ <span class="number">0.2063</span>,  <span class="number">0.0771</span>,  <span class="number">0.1579</span>],</span><br><span class="line">          [ <span class="number">0.1543</span>,  <span class="number">0.1374</span>, <span class="number">-0.1951</span>],</span><br><span class="line">          [<span class="number">-0.1221</span>,  <span class="number">0.0099</span>, <span class="number">-0.1331</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">-0.1899</span>,  <span class="number">0.1978</span>,  <span class="number">0.1065</span>],</span><br><span class="line">          [ <span class="number">0.1400</span>, <span class="number">-0.0740</span>,  <span class="number">0.0397</span>],</span><br><span class="line">          [<span class="number">-0.2165</span>, <span class="number">-0.0180</span>,  <span class="number">0.1072</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.0692</span>, <span class="number">-0.1296</span>,  <span class="number">0.0524</span>],</span><br><span class="line">          [ <span class="number">0.0577</span>, <span class="number">-0.1184</span>,  <span class="number">0.0697</span>],</span><br><span class="line">          [ <span class="number">0.0859</span>, <span class="number">-0.2086</span>,  <span class="number">0.0419</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">-0.0270</span>,  <span class="number">0.1836</span>, <span class="number">-0.0649</span>],</span><br><span class="line">          [ <span class="number">0.1680</span>, <span class="number">-0.1061</span>, <span class="number">-0.2357</span>],</span><br><span class="line">          [<span class="number">-0.0408</span>,  <span class="number">0.0799</span>,  <span class="number">0.0065</span>]]]]), Parameter containing:</span><br><span class="line">tensor([ <span class="number">0.1269</span>, <span class="number">-0.1582</span>]), Parameter containing:</span><br><span class="line">tensor([[[[ <span class="number">0.0185</span>, <span class="number">-0.2579</span>, <span class="number">-0.1185</span>],</span><br><span class="line">          [ <span class="number">0.1269</span>,  <span class="number">0.0274</span>,  <span class="number">0.1019</span>],</span><br><span class="line">          [ <span class="number">0.0329</span>, <span class="number">-0.1229</span>, <span class="number">-0.1922</span>]]]]), Parameter containing:</span><br><span class="line">tensor([<span class="number">-0.2731</span>])], <span class="string">'lr'</span>: <span class="number">0.1</span>, <span class="string">'betas'</span>: (<span class="number">0.9</span>, <span class="number">0.999</span>), <span class="string">'eps'</span>: <span class="number">1e-08</span>, <span class="string">'weight_decay'</span>: <span class="number">0</span>, <span class="string">'amsgrad'</span>: <span class="keyword">False</span>&#125;</span><br><span class="line">______</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer.state_dict()</span><br><span class="line">&#123;<span class="string">'state'</span>: &#123;&#125;,</span><br><span class="line"> <span class="string">'param_groups'</span>: [&#123;<span class="string">'lr'</span>: <span class="number">0.4</span>,</span><br><span class="line">   <span class="string">'betas'</span>: (<span class="number">0.9</span>, <span class="number">0.999</span>),</span><br><span class="line">   <span class="string">'eps'</span>: <span class="number">1e-08</span>,</span><br><span class="line">   <span class="string">'weight_decay'</span>: <span class="number">0</span>,</span><br><span class="line">   <span class="string">'amsgrad'</span>: <span class="keyword">False</span>,</span><br><span class="line">   <span class="string">'params'</span>: [<span class="number">140617843939944</span>, <span class="number">140617843755120</span>]&#125;,</span><br><span class="line">  &#123;<span class="string">'lr'</span>: <span class="number">0.1</span>,</span><br><span class="line">   <span class="string">'betas'</span>: (<span class="number">0.9</span>, <span class="number">0.999</span>),</span><br><span class="line">   <span class="string">'eps'</span>: <span class="number">1e-08</span>,</span><br><span class="line">   <span class="string">'weight_decay'</span>: <span class="number">0</span>,</span><br><span class="line">   <span class="string">'amsgrad'</span>: <span class="keyword">False</span>,</span><br><span class="line">   <span class="string">'params'</span>: [<span class="number">140617843755192</span>,</span><br><span class="line">    <span class="number">140617843755264</span>,</span><br><span class="line">    <span class="number">140617843755336</span>,</span><br><span class="line">    <span class="number">140617843755408</span>]&#125;]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三种</span></span><br><span class="line">optimizer = t.optim.Adam([&#123;<span class="string">'params'</span>:model.net1.parameters(),<span class="string">'lr'</span>:<span class="number">0.4</span>&#125;])</span><br><span class="line">optimizer.add_param_group(&#123;<span class="string">'params'</span>:model.net2.parameters(),<span class="string">'lr'</span>:<span class="number">0.3</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四种</span></span><br><span class="line"><span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">     param_group[<span class="string">'lr'</span>]=lr_new</span><br></pre></td></tr></table></figure></p><h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只保留模型参数并且加载</span></span><br><span class="line">t.save(model.state_dict(),<span class="string">'model_state_dict'</span>)</span><br><span class="line">model.state_dict()</span><br><span class="line"></span><br><span class="line">OrderedDict([(<span class="string">'net1.weight'</span>, tensor([[[[<span class="number">-0.3164</span>, <span class="number">-0.2508</span>, <span class="number">-0.3294</span>],</span><br><span class="line">                        [ <span class="number">0.2388</span>, <span class="number">-0.1582</span>,  <span class="number">0.0678</span>],</span><br><span class="line">                        [ <span class="number">0.0194</span>,  <span class="number">0.1120</span>,  <span class="number">0.2794</span>]]],</span><br><span class="line">              </span><br><span class="line">              </span><br><span class="line">                      [[[<span class="number">-0.2425</span>,  <span class="number">0.0833</span>, <span class="number">-0.0842</span>],</span><br><span class="line">                        [ <span class="number">0.0687</span>, <span class="number">-0.0637</span>, <span class="number">-0.3034</span>],</span><br><span class="line">                        [<span class="number">-0.3268</span>, <span class="number">-0.1049</span>, <span class="number">-0.0286</span>]]]])),</span><br><span class="line">             (<span class="string">'net1.bias'</span>, tensor([ <span class="number">0.2742</span>,  <span class="number">0.2194</span>])),</span><br><span class="line">             (<span class="string">'net2.weight'</span>, tensor([[[[ <span class="number">0.2241</span>,  <span class="number">0.2280</span>, <span class="number">-0.0597</span>],</span><br><span class="line">                        [<span class="number">-0.1045</span>, <span class="number">-0.1610</span>,  <span class="number">0.0445</span>],</span><br><span class="line">                        [<span class="number">-0.1772</span>, <span class="number">-0.0639</span>, <span class="number">-0.0172</span>]],</span><br><span class="line">              </span><br><span class="line">                       [[ <span class="number">0.0975</span>, <span class="number">-0.0081</span>,  <span class="number">0.0690</span>],</span><br><span class="line">                        [<span class="number">-0.1273</span>,  <span class="number">0.0693</span>,  <span class="number">0.1792</span>],</span><br><span class="line">                        [ <span class="number">0.0773</span>,  <span class="number">0.1652</span>, <span class="number">-0.1688</span>]]],</span><br><span class="line">              </span><br><span class="line">              </span><br><span class="line">                      [[[<span class="number">-0.2314</span>,  <span class="number">0.0494</span>, <span class="number">-0.0648</span>],</span><br><span class="line">                        [<span class="number">-0.1919</span>,  <span class="number">0.2145</span>,  <span class="number">0.0369</span>],</span><br><span class="line">                        [<span class="number">-0.1336</span>, <span class="number">-0.1077</span>, <span class="number">-0.0743</span>]],</span><br><span class="line">              </span><br><span class="line">                       [[ <span class="number">0.1510</span>, <span class="number">-0.0868</span>, <span class="number">-0.1766</span>],</span><br><span class="line">                        [<span class="number">-0.1764</span>,  <span class="number">0.0398</span>,  <span class="number">0.2146</span>],</span><br><span class="line">                        [<span class="number">-0.0269</span>,  <span class="number">0.1241</span>, <span class="number">-0.2304</span>]]]])),</span><br><span class="line">             (<span class="string">'net2.bias'</span>, tensor(<span class="number">1.00000e-02</span> *</span><br><span class="line">                     [<span class="number">-7.3981</span>, <span class="number">-0.8345</span>]))])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">temp = t.load(<span class="string">'model_state_dict.pth'</span>)</span><br><span class="line">OrderedDict([(<span class="string">'net1.weight'</span>, tensor([[[[<span class="number">-0.3164</span>, <span class="number">-0.2508</span>, <span class="number">-0.3294</span>],</span><br><span class="line">                        [ <span class="number">0.2388</span>, <span class="number">-0.1582</span>,  <span class="number">0.0678</span>],</span><br><span class="line">                        [ <span class="number">0.0194</span>,  <span class="number">0.1120</span>,  <span class="number">0.2794</span>]]],</span><br><span class="line">              </span><br><span class="line">              </span><br><span class="line">                      [[[<span class="number">-0.2425</span>,  <span class="number">0.0833</span>, <span class="number">-0.0842</span>],</span><br><span class="line">                        [ <span class="number">0.0687</span>, <span class="number">-0.0637</span>, <span class="number">-0.3034</span>],</span><br><span class="line">                        [<span class="number">-0.3268</span>, <span class="number">-0.1049</span>, <span class="number">-0.0286</span>]]]])),</span><br><span class="line">             (<span class="string">'net1.bias'</span>, tensor([ <span class="number">0.2742</span>,  <span class="number">0.2194</span>])),</span><br><span class="line">             (<span class="string">'net2.weight'</span>, tensor([[[[ <span class="number">0.2241</span>,  <span class="number">0.2280</span>, <span class="number">-0.0597</span>],</span><br><span class="line">                        [<span class="number">-0.1045</span>, <span class="number">-0.1610</span>,  <span class="number">0.0445</span>],</span><br><span class="line">                        [<span class="number">-0.1772</span>, <span class="number">-0.0639</span>, <span class="number">-0.0172</span>]],</span><br><span class="line">              </span><br><span class="line">                       [[ <span class="number">0.0975</span>, <span class="number">-0.0081</span>,  <span class="number">0.0690</span>],</span><br><span class="line">                        [<span class="number">-0.1273</span>,  <span class="number">0.0693</span>,  <span class="number">0.1792</span>],</span><br><span class="line">                        [ <span class="number">0.0773</span>,  <span class="number">0.1652</span>, <span class="number">-0.1688</span>]]],</span><br><span class="line">              </span><br><span class="line">              </span><br><span class="line">                      [[[<span class="number">-0.2314</span>,  <span class="number">0.0494</span>, <span class="number">-0.0648</span>],</span><br><span class="line">                        [<span class="number">-0.1919</span>,  <span class="number">0.2145</span>,  <span class="number">0.0369</span>],</span><br><span class="line">                        [<span class="number">-0.1336</span>, <span class="number">-0.1077</span>, <span class="number">-0.0743</span>]],</span><br><span class="line">              </span><br><span class="line">                       [[ <span class="number">0.1510</span>, <span class="number">-0.0868</span>, <span class="number">-0.1766</span>],</span><br><span class="line">                        [<span class="number">-0.1764</span>,  <span class="number">0.0398</span>,  <span class="number">0.2146</span>],</span><br><span class="line">                        [<span class="number">-0.0269</span>,  <span class="number">0.1241</span>, <span class="number">-0.2304</span>]]]])),</span><br><span class="line">             (<span class="string">'net2.bias'</span>, tensor(<span class="number">1.00000e-02</span> *</span><br><span class="line">                     [<span class="number">-7.3981</span>, <span class="number">-0.8345</span>]))])</span><br><span class="line"></span><br><span class="line">model2.state_dict()</span><br><span class="line"></span><br><span class="line">OrderedDict([(<span class="string">'net3.weight'</span>, tensor([[[[ <span class="number">0.2793</span>, <span class="number">-0.2330</span>,  <span class="number">0.3270</span>],</span><br><span class="line">                        [<span class="number">-0.1419</span>,  <span class="number">0.1562</span>,  <span class="number">0.1875</span>],</span><br><span class="line">                        [<span class="number">-0.0249</span>,  <span class="number">0.1297</span>,  <span class="number">0.1642</span>]]],</span><br><span class="line">              </span><br><span class="line">              </span><br><span class="line">                      [[[ <span class="number">0.2770</span>,  <span class="number">0.1016</span>, <span class="number">-0.1096</span>],</span><br><span class="line">                        [ <span class="number">0.1929</span>,  <span class="number">0.0210</span>,  <span class="number">0.1722</span>],</span><br><span class="line">                        [ <span class="number">0.1304</span>,  <span class="number">0.0820</span>,  <span class="number">0.1205</span>]]]])),</span><br><span class="line">             (<span class="string">'net3.bias'</span>, tensor([<span class="number">-0.3235</span>, <span class="number">-0.1770</span>])),</span><br><span class="line">             (<span class="string">'net4.weight'</span>, tensor([[[[<span class="number">-0.2043</span>, <span class="number">-0.1492</span>],</span><br><span class="line">                        [ <span class="number">0.1728</span>, <span class="number">-0.1069</span>]],</span><br><span class="line">              </span><br><span class="line">                       [[<span class="number">-0.2903</span>,  <span class="number">0.3385</span>],</span><br><span class="line">                        [ <span class="number">0.2778</span>,  <span class="number">0.1589</span>]]],</span><br><span class="line">              </span><br><span class="line">              </span><br><span class="line">                      [[[<span class="number">-0.1423</span>, <span class="number">-0.0439</span>],</span><br><span class="line">                        [ <span class="number">0.2849</span>, <span class="number">-0.0840</span>]],</span><br><span class="line">              </span><br><span class="line">                       [[ <span class="number">0.0354</span>,  <span class="number">0.1711</span>],</span><br><span class="line">                        [<span class="number">-0.0274</span>, <span class="number">-0.2220</span>]]]])),</span><br><span class="line">             (<span class="string">'net4.bias'</span>, tensor([<span class="number">-0.0264</span>, <span class="number">-0.1094</span>]))])</span><br><span class="line"></span><br><span class="line">model2.load_state_dict(temp)</span><br><span class="line"></span><br><span class="line">Missing key(s) <span class="keyword">in</span> state_dict: <span class="string">"net3.weight"</span>, <span class="string">"net3.bias"</span>, <span class="string">"net4.weight"</span>, <span class="string">"net4.bias"</span>. </span><br><span class="line">Unexpected key(s) <span class="keyword">in</span> state_dict: <span class="string">"net1.weight"</span>, <span class="string">"net1.bias"</span>, <span class="string">"net2.weight"</span>, <span class="string">"net2.bias"</span>.</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 印证了在保存模型参数的时候是根据名字进行保存，</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留模型</span></span><br><span class="line">t.save(model,<span class="string">'model.pth'</span>)</span><br><span class="line">temp2 = t.load(<span class="string">'model.pth'</span>)</span><br><span class="line">Nettest(</span><br><span class="line">  (net1): Conv2d(<span class="number">1</span>, <span class="number">2</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (net2): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">2</span>, <span class="number">2</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line">加载进来就是一个模型，包括forward什么的都还在。</span><br></pre></td></tr></table></figure><hr><h2 id="numpy和list和tensor对于size的访问区别"><a href="#numpy和list和tensor对于size的访问区别" class="headerlink" title="numpy和list和tensor对于size的访问区别"></a>numpy和list和tensor对于size的访问区别</h2><ol><li>list:   只有len()方法，返回的是最外层的个数，reshape方法</li><li>numpy:  b.size是全部个数，b.shape是(2,3)  b = np.arange(6).reshape(2,3),  b.resize(2,3)        np.arange(1,6,2)</li><li>tensor: c.shape==c.size()  len(c)==c.size(0) 返回torch.size([3,2]), c.resize_(4,4)(可以改变自身尺寸)  c.resize(1,4)（来源于torchvision，可以忽略）==c.reshape(1,4)(对于连续地址共享内存，不连续地址则复制)==c.view(1,4)(共享内存)  t.arange(1,6,2) t_.unsqueeze(1)<br>tensor的普通索引基本共享内存，而高级索引基本不共享内存。 </li><li>numpy–&gt;tensor t_ = t.from_numpy(numpy_)(共享内存）或者 t_ = t.tensor(numpy_)(返回新对象)</li><li>tensor–&gt;numpy np_ = t_.numpy()(共享内存) 或者 np_ = np.array(t_)</li><li>numpy–&gt;list   list_ = np_.tolist()(不共享内存）</li><li>list–&gt;numpy   np_ = np.array(list_)(不共享内存）</li><li>tensor–&gt;list  list_ = t_.tolist() (不共享内存)  或者 item_ = t_.item() (不共享内存）</li><li>list–&gt;tensor  t_ = t.tensor(list_)(不共享内存）<br>也就是说numpy和tensor可以做到互相共享内存，而list只是一个对外的和Python相连接的一个形式.<br>补充：基于numpy和tensor，推荐使用shape属性， 修改形状则分别使用reshape()和view(),</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"></span><br><span class="line"><span class="comment"># a,b,c共享内存</span></span><br><span class="line">a = np.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = t.from_numpy(a)</span><br><span class="line">c = b.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># a,b,c不共享内存</span></span><br><span class="line">a = np.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = t.tensor(a)</span><br><span class="line">c = np.array(b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 不共享内存</span></span><br><span class="line">a = np.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = a.tolist()</span><br><span class="line">c = np.array(b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensor <span class="keyword">as</span> t</span><br><span class="line">a = t.tensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">b = a.item()</span><br><span class="line">b = a.tolist()</span><br><span class="line">c = t.tensor(b)</span><br></pre></td></tr></table></figure><h2 id="torch-Tensor-和-torch-tensor的区别"><a href="#torch-Tensor-和-torch-tensor的区别" class="headerlink" title="torch.Tensor 和 torch.tensor的区别"></a>torch.Tensor 和 torch.tensor的区别</h2><p>暂时还没有组织好的语言，先以代码的形式记录下来<br>主要是类型和对0维元素的区别。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">12</span>]: <span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: t.Tensor(<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">13</span>]: tensor([<span class="number">-4.8232e+13</span>,  <span class="number">4.5581e-41</span>, <span class="number">-1.8931e-03</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: t.Tensor([<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">Out[<span class="number">14</span>]: tensor([ <span class="number">3.</span>,  <span class="number">4.</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: t.tensor(<span class="number">3</span>)</span><br><span class="line">Out[<span class="number">15</span>]: tensor(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: t.tensor([<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">Out[<span class="number">16</span>]: tensor([ <span class="number">3</span>,  <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: a = t.tensor([<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: type(a)</span><br><span class="line">Out[<span class="number">18</span>]: torch.Tensor</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: a.dtype</span><br><span class="line">Out[<span class="number">19</span>]: torch.int64</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor只是tensor(dtype=float)的别名。</span></span><br><span class="line">x = torch.tensor([<span class="number">3.0</span>],requires_grad=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># torch.Tensor不接收requires_grad参数</span></span><br><span class="line"><span class="comment"># torch.tensor只有是float型参数的情况下才接受requires_grad参数</span></span><br></pre></td></tr></table></figure></p><h2 id="tensor-new-和tensor-data-new"><a href="#tensor-new-和tensor-data-new" class="headerlink" title="tensor.new()和tensor.data.new()"></a>tensor.new()和tensor.data.new()</h2><p>暂时不知道这两者的区别，但是书上的代码多数都是tensor.data.new()</p><hr><h2 id="topk的用法"><a href="#topk的用法" class="headerlink" title="topk的用法"></a>topk的用法</h2><p>output.data[0].topk(1)[1][0].item()<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">20</span>]: x = t.arange(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: y = t.topk(x,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: type(y)</span><br><span class="line">Out[<span class="number">22</span>]: tuple</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: y</span><br><span class="line">Out[<span class="number">23</span>]: (tensor([ <span class="number">5.</span>,  <span class="number">4.</span>]), tensor([ <span class="number">4</span>,  <span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: y[<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">24</span>]: tensor([ <span class="number">4</span>,  <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: y[<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">25</span>]: tensor(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: y[<span class="number">1</span>][<span class="number">1</span>].item()</span><br><span class="line">Out[<span class="number">26</span>]: <span class="number">3</span></span><br></pre></td></tr></table></figure></p><h2 id="ipython和jupyter和pycharm"><a href="#ipython和jupyter和pycharm" class="headerlink" title="ipython和jupyter和pycharm"></a>ipython和jupyter和pycharm</h2><p>在写代码的前期，用jupyter好使，因为对于不确定的比较多的代码是可以直接看到结果，对某一段进行调试，检查某一段的基本语法错误，或者对于某个想法的实现，是简单直接的甚至对于中型代码，用代码框可以实现视觉上的分离，逻辑清晰，并且支持markdown的记录与注释，对于不了解的代码有很好的支持性。<br>但是在写代码的后期，jupyter的弊端逐渐显现，不能使用模板，<strong>init</strong>.py的生成不好使，文件与文件夹的关系不清晰。甚至一个简单的文件或者文件夹挪动位置都很麻烦，需要桌面的辅助。<br>而pycharm对于文件管理，<strong>init</strong>.py等有很好的支持性。更适合写已经成熟的代码。<br>这一下难住我了，作为新手，肯定每次都要实验好些代码，看输入输出的效果，如果是pycharm则比较麻烦，对于调试很啰嗦。<br>命令行窗口做为补充，也不好使，因为每次能看到的东西有限，重复性差，只能用于单句代码的验证。<br>所以不妨这样，前期开发还是用jupyter，等开发的差不多了，甚至等单个文件已经开发完毕，这样的话开发就可以先不管文件夹的事，等各个文件开发完毕，再转成pycharm，来实现文件夹、文件的组织管理和后期的调试，这是因为现在多数不使用jupyter直接运行，而是使用py进行运行。我觉得应该有很多人用.ipynb进行运行，但是我不知道怎么才能更好的运行。</p><h3 id="anaconda"><a href="#anaconda" class="headerlink" title="anaconda"></a>anaconda</h3><p>虚拟环境不错</p><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><p>如果在 Python 脚本文件首行输入#!/usr/bin/env python，那么可以在命令行窗口中执行/path/to/script-file.py以执行该脚本文件。<br>使用三引号(‘’’或”””)可以指定一个多行字符串。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;本文主要是针对陈云的PyTorch入门与实践的第八章的内容进行复现，准确地说，是看着他写的代码，自己再实现一遍，所以更多地是在讲解实现过程中遇到的问题或者看到的好的方法，而不是针对论文的原理的进行讲解。对于原理，也只是会一笔带过。原理篇暂时不准备留坑，因为原理是个玄学。&lt;br&gt;这是我的&lt;a href=&quot;https://github.com/TJJTJJTJJ/pytorch__learn&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;代码&lt;/a&gt;&lt;br&gt;大神链接：&lt;a href=&quot;https://github.com/anishathalye/neural-style&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/anishathalye/neural-style&lt;/a&gt;&lt;br&gt;这是论文作者写的&lt;br&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="numpy" scheme="http://yoursite.com/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>numpy</title>
    <link href="http://yoursite.com/2018/09/13/numpy/"/>
    <id>http://yoursite.com/2018/09/13/numpy/</id>
    <published>2018-09-13T14:27:14.000Z</published>
    <updated>2018-10-01T06:02:51.164Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>参考链接<br><a href="https://www.yiibai.com/numpy/numpy_ndarray_object.html#article-start" target="_blank" rel="noopener">NumPy Ndarray对象</a><br>这只是简单的入门，以后接触得越多，对于其中的理解也才会更加全面，并做补充。<br><a id="more"></a><br><!--more--><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.简单的array对象</span></span><br><span class="line">a = np.array([<span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>], dtype = complex)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.结构数组形式的array对象</span></span><br><span class="line">student = np.dtype([(<span class="string">'name'</span>,<span class="string">'S20'</span>),  (<span class="string">'age'</span>,  <span class="string">'i1'</span>),  (<span class="string">'marks'</span>,  <span class="string">'f4'</span>)]) </span><br><span class="line">a = np.array([(<span class="string">'abc'</span>,  <span class="number">21</span>,  <span class="number">50</span>),(<span class="string">'xyz'</span>,  <span class="number">18</span>,  <span class="number">75</span>)], dtype = student)  </span><br><span class="line">print(a)</span><br><span class="line">[(<span class="string">'abc'</span>, <span class="number">21</span>, <span class="number">50.0</span>), (<span class="string">'xyz'</span>, <span class="number">18</span>, <span class="number">75.0</span>)]</span><br><span class="line">a[<span class="number">0</span>][<span class="string">'name'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.其他形式</span></span><br><span class="line">a.shape</span><br><span class="line">a.reshape(<span class="number">2</span>,<span class="number">4</span>,<span class="number">3</span>)  </span><br><span class="line">x.itemsize 每个元素的字节单位长度</span><br><span class="line">numpy.frombuffer() 怎么理解？？</span><br><span class="line">np.fromiter(iter(list))</span><br><span class="line">numpy.arange(start, stop, step, dtype)</span><br><span class="line">numpy.linspace(start, stop, num, endpoint, retstep, dtype)</span><br><span class="line">numpy.logscale(start, stop, num, endpoint, base, dtype)</span><br></pre></td></tr></table></figure></p><hr><h2 id="numpy的保存和读取，这里还是有点东西的，待续"><a href="#numpy的保存和读取，这里还是有点东西的，待续" class="headerlink" title="numpy的保存和读取，这里还是有点东西的，待续"></a>numpy的保存和读取，这里还是有点东西的，待续</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy在save和load的时候没有显式保存变量名</span></span><br><span class="line">np.save(<span class="string">"A.npy"</span>,A)</span><br><span class="line">B=np.load(<span class="string">"A.npy"</span>)</span><br><span class="line">B</span><br><span class="line"></span><br><span class="line">np.savez(<span class="string">"files.npz"</span>,A,B,C_array=C)</span><br><span class="line">np.savez_compressed(<span class="string">"files.npz"</span>,A,B,C_array=C)</span><br><span class="line">D=np.load(<span class="string">"files.npz"</span>)</span><br><span class="line">D[<span class="string">'arr_1'</span>]</span><br><span class="line">D[<span class="string">'C_array'</span>]</span><br></pre></td></tr></table></figure><h2 id="numpy-savetxt-loadtxt"><a href="#numpy-savetxt-loadtxt" class="headerlink" title="numpy savetxt() loadtxt"></a>numpy savetxt() loadtxt</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.savetxt(<span class="string">'a.txt'</span>,a,fmt=<span class="string">'%d'</span>, delimiter=<span class="string">','</span>)</span><br><span class="line">b= np.loadtxt(<span class="string">'a.txt'</span>,delimiter=<span class="string">','</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.savetxt(<span class="string">'a.csv'</span>,a,fmt=<span class="string">'%d'</span>, delimiter=<span class="string">','</span>)</span><br><span class="line">b= np.loadtxt(<span class="string">'a.csv'</span>,delimiter=<span class="string">','</span>)</span><br></pre></td></tr></table></figure><hr><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p>ndarray对象中的元素遵循基于零的索引。 有三种可用的索引方法类型： 字段访问，基本切片和高级索引，可以使用省略号当全部<br>切片只是返回一个视图，高级索引返回数据的副本，并且切片是全取，而高级索引是取对应的位置的元素<br>y = x[1:3,1:2]:两行元素,y = x[[1,2],[1,3]]:两个元素<br>布尔索引是数据的复制<br>广播法则<br>数组上的迭代 for i in np.nditer(a,order=’C’ or order=’F’), np.nditer(a).<strong>next</strong>()<br>广播迭代</p><p>reshape：不改变数据的条件下修改形状<br>flat：数组上的一维迭代器， for i in a.flat  ,   a.flat[2:4],  暂时看不出来flat和nditer的区别<br>flatten: 返回折叠为一维的数组副本<br>ravel： 返回连续的展开数组    flattten和ravel的区别暂时不知道在哪<br>numpy.rollaxis：这里的转轴有问题，比较好的理解是[[[000,001],[010,011]],[[100,101],[110,111]]]，[参考：]<a href="https://blog.csdn.net/liaoyuecai/article/details/80193996" target="_blank" rel="noopener">https://blog.csdn.net/liaoyuecai/article/details/80193996</a>，还有一种理解是从页，行，列的方式，每次都在原数组上以固定页，固定行的方式进行读取，保证所有的数字以一列的方式，即总是表示成000,001,010,011,100,101,110,111，再想一个更简单的方法。跨括号法，不扯<br>numpy.swapaxes(arr, axis1, axis2)</p><h1 id="修改维度"><a href="#修改维度" class="headerlink" title="修改维度"></a>修改维度</h1><p>序号     维度和描述</p><ol><li>broadcast 产生模仿广播的对象 b = np.broadcast(x,y) c = np.empty(b.shape)  c.flat = [u + v for (u,v) in b],并且np.nditer()也可以达到相同的效果 </li><li>broadcast_to 将数组广播到新形状 numpy.broadcast_to(array, shape, subok)</li><li>expand_dims 扩展数组的形状numpy.expand_dims(arr, axis)</li><li>squeeze 从数组的形状中删除单维条目 y = np.squeeze(x,axis=(0,1))</li></ol><p>数组的连接<br>序号     数组及描述</p><ol><li>concatenate 沿着现存的轴连接数据序列，不产生新的轴</li><li>stack 沿着新轴连接数组序列，产生新的轴</li><li>hstack 水平堆叠序列中的数组(列方向)</li><li>vstack 竖直堆叠序列中的数组(行方向)<br>数组分割<br>序号     数组及操作</li><li>split 将一个数组分割为多个子数组</li><li>hsplit 将一个数组水平分割为多个子数组(按列)</li><li>vsplit 将一个数组竖直分割为多个子数组(按行)</li></ol><p>添加/删除元素<br>序号     元素及描述</p><ol><li>resize 返回指定形状的新数组</li><li>append 将值添加到数组末尾</li><li>insert 沿指定轴将值插入到指定下标之前</li><li>delete 返回删掉某个轴的子数组的新数组</li><li>unique 寻找数组内的唯一元素</li></ol><p>切片的新表达式： np.s_[::2]<br>位运算：跳过</p><p>字符串函数：对dtype为numpy.string_或numpy.unicode_的数组执行向量化字符串操作</p><ol><li>add() 返回两个str或Unicode数组的逐个字符串连接</li><li>multiply() 返回按元素多重连接后的字符串</li><li>center() 返回给定字符串的副本，其中元素位于特定字符串的中央</li><li>capitalize() 返回给定字符串的副本，其中只有第一个字符串大写</li><li>title() 返回字符串或 Unicode 的按元素标题转换版本</li><li>lower() 返回一个数组，其元素转换为小写</li><li>upper() 返回一个数组，其元素转换为大写</li><li>split() 返回字符串中的单词列表，并使用分隔符来分割</li><li>splitlines() 返回元素中的行列表，以换行符分割</li><li>strip() 返回数组副本，其中元素移除了开头或者结尾处的特定字符</li><li>join() 返回一个字符串，它是序列中字符串的连接</li><li>replace() 返回字符串的副本，其中所有子字符串的出现位置都被新字符串取代</li><li>decode() 按元素调用str.decode</li><li>encode() 按元素调用str.encode</li></ol><p>dtype???<br>add()，subtract()，multiply()和divide()<br>排序quicksort, mergesort, heaqsort<br>dt = np.dtype([(‘name’,  ‘S10’),(‘age’,  int)])<br>a = np.array([(“raju”,21),(“anil”,25),(“ravi”,  17),  (“amar”,27)], dtype = dt)<br>print(np.sort(a, order =  ‘name’))<br>numpy.argsort()<br>numpy.lexsort()<br>np.argmax() np.argmin()<br>np.nonzero()<br>np.where()<br>np.extract()</p><p>改变形状： b.shape = 3,2<br>无复制： b = a 值和形状都是共享，id相同<br>浅复制: b = a.view()　值共享，形状不共享，id不同　切片也是浅复制<br>深复制：ｂ＝ a.copy()</p><p>numpy.matlib　<br>矩阵库，返回的是矩阵matrix对象，而不是ndarray对象 .empty(), .zeros(), .ones(), eye(), identity(), rand() 只能是二维的<br>np.matrix(‘1,2;3,4’) np.matirx([[1,2],[3,4]])</p><p>array和asarray都可以将结构数据转化为ndarray，但是主要区别就是当数据源是ndarray时，array仍然会copy出一个副本，占用新的内存，但asarray不会。<br>matrix和array互换： np.matrix(np.array) np.array(np.matrix),此时两者值和形状没有关系，使用asmatrix和asarray时，值共享，形状不共享<br>暂时没有想到matrix的意义</p><p>线性代数<br>numpy.linalg<br>貌似可以直接作用于列表</p><ol><li>dot 两个数组的点积，也就是矩阵式乘法 np.dot(a,b)，对于多维数组的乘法，可以同样以XXX0.和XXX.0的方法<br>对于两个1维数组，是点积，对于两个矩阵，是矩阵乘法，对于1维数组和矩阵，则对1维数组适当地转置，然后进行矩阵乘法，需要满足倒数第一维和倒数第二维相等。</li><li>vdot 两个向量的点积，也就是矩阵式对应元素的乘积和</li><li>inner 两个数组的内积 </li><li>matmul 两个数组的矩阵积</li><li>determinant 数组的行列式  numpy.linalg.det()</li><li>solve 求解线性矩阵方程</li><li>inv 寻找矩阵的乘法逆矩阵</li></ol><p>Matplotlib<br>from matplotlib import pyplot as plt</p><hr><h2 id="numpy转化数据类型"><a href="#numpy转化数据类型" class="headerlink" title="numpy转化数据类型"></a>numpy转化数据类型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">11</span>]: arr = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: arr</span><br><span class="line">Out[<span class="number">12</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 该命令查看数据类型</span></span><br><span class="line">In [<span class="number">13</span>]: arr.dtype</span><br><span class="line">Out[<span class="number">13</span>]: dtype(<span class="string">'int64'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: float_arr = arr.astype(np.float64)</span><br><span class="line"><span class="comment"># 等价于，即str和data-type是一样的</span></span><br><span class="line">float_arr = arr.asdtype(<span class="string">'float64'</span>)</span><br><span class="line"><span class="comment">#该命令查看数据类型</span></span><br><span class="line">In [<span class="number">15</span>]: float_arr.dtype</span><br><span class="line">Out[<span class="number">15</span>]: dtype(<span class="string">'float64'</span>)</span><br></pre></td></tr></table></figure><hr><p>字符串数组转化为数值型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">4</span>]: numeric_strings = np.array([<span class="string">'1.2'</span>,<span class="string">'2.3'</span>,<span class="string">'3.2141'</span>], dtype=np.string_)</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: numeric_strings</span><br><span class="line">Out[<span class="number">5</span>]: array([<span class="string">'1.2'</span>, <span class="string">'2.3'</span>, <span class="string">'3.2141'</span>], dtype=<span class="string">'|S6'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处写的是float 而不是np.float64, Numpy很聪明，会将python类型映射到等价的dtype上</span></span><br><span class="line"><span class="comment"># # 这里的float是Python的数据类型，NumPy会自动的将其映射到等价的dtype上，即np.float64</span></span><br><span class="line">In [<span class="number">6</span>]: numeric_strings.astype(float)</span><br><span class="line">Out[<span class="number">6</span>]: array([ <span class="number">1.2</span>, <span class="number">2.3</span>, <span class="number">3.2141</span>])</span><br></pre></td></tr></table></figure></p><p>所以astype一共可以接受三种参数</p><ul><li>第一种是dtype，即np.int32这种，</li><li>第二种是字符串，即’int32’这样，与第一种相呼应，</li><li>第三种是Python的数据类型，会自动转化。</li></ul><p>numpy中的数据类型转换，不能直接改原数据的dtype!  只能用函数astype()。<br>[参考链接]<a href="https://www.cnblogs.com/hhh5460/p/5129032.html" target="_blank" rel="noopener">https://www.cnblogs.com/hhh5460/p/5129032.html</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果直接修改dtype，会导致长度发生改变</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.dtype = <span class="string">'float16'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([ <span class="number">-9.58442688e-05</span>,   <span class="number">7.19000000e+02</span>,   <span class="number">2.38159180e-01</span>,</span><br><span class="line">         <span class="number">1.92968750e+00</span>,              nan,  <span class="number">-1.66034698e-03</span>,</span><br><span class="line">        <span class="number">-2.63427734e-01</span>,   <span class="number">1.96875000e+00</span>,  <span class="number">-1.07519531e+00</span>,</span><br><span class="line">        <span class="number">-1.19625000e+02</span>,              nan,   <span class="number">1.97167969e+00</span>,</span><br><span class="line">        <span class="number">-1.60156250e-01</span>,  <span class="number">-7.76290894e-03</span>,   <span class="number">4.07226562e-01</span>,</span><br><span class="line">         <span class="number">1.94824219e+00</span>], dtype=float16)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.shape</span><br><span class="line">(<span class="number">16</span>,)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.dtype = <span class="string">'float16'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([ <span class="number">-9.58442688e-05</span>,   <span class="number">7.19000000e+02</span>,   <span class="number">2.38159180e-01</span>,</span><br><span class="line">         <span class="number">1.92968750e+00</span>,              nan,  <span class="number">-1.66034698e-03</span>,</span><br><span class="line">        <span class="number">-2.63427734e-01</span>,   <span class="number">1.96875000e+00</span>,  <span class="number">-1.07519531e+00</span>,</span><br><span class="line">        <span class="number">-1.19625000e+02</span>,              nan,   <span class="number">1.97167969e+00</span>,</span><br><span class="line">        <span class="number">-1.60156250e-01</span>,  <span class="number">-7.76290894e-03</span>,   <span class="number">4.07226562e-01</span>,</span><br><span class="line">         <span class="number">1.94824219e+00</span>], dtype=float16)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.shape</span><br><span class="line">(<span class="number">16</span>,)</span><br></pre></td></tr></table></figure></p><p>对于字符串数组还没有找到合理的说明，sad</p><hr><h2 id="np-in1d-x-y"><a href="#np-in1d-x-y" class="headerlink" title="np.in1d(x,y)"></a>np.in1d(x,y)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>test = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>states = [<span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = np.in1d(test, states)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask</span><br><span class="line">array([ <span class="keyword">True</span>, <span class="keyword">False</span>,  <span class="keyword">True</span>, <span class="keyword">False</span>,  <span class="keyword">True</span>], dtype=bool)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test[mask]</span><br><span class="line">array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = np.in1d(test, states, invert=<span class="keyword">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask</span><br><span class="line">array([<span class="keyword">False</span>,  <span class="keyword">True</span>, <span class="keyword">False</span>,  <span class="keyword">True</span>, <span class="keyword">False</span>], dtype=bool)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test[mask]</span><br><span class="line">array([<span class="number">1</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure><h2 id="np-argsort"><a href="#np-argsort" class="headerlink" title="np.argsort()"></a>np.argsort()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">y = np.argsort(x)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: xx</span><br><span class="line">Out[<span class="number">48</span>]: array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: yy</span><br><span class="line">Out[<span class="number">49</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: xx[yy]</span><br><span class="line">Out[<span class="number">50</span>]: array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><h2 id="np-setdiff1d"><a href="#np-setdiff1d" class="headerlink" title="np.setdiff1d()"></a>np.setdiff1d()</h2><p>这种是以集合的方式，会把列表先压平，<br>@return: sorted 1D array<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.array([<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.setdiff1d(a, b)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure></p><h2 id="np-argwhere"><a href="#np-argwhere" class="headerlink" title="np.argwhere()"></a>np.argwhere()</h2><p>@return: index_array<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.argwhere(x&gt;<span class="number">1</span>)</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: x[<span class="number">0</span>,<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">32</span>]: <span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: x[[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">0</span>]]</span><br><span class="line">Out[<span class="number">26</span>]: array([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: z = zip([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: <span class="keyword">for</span> i <span class="keyword">in</span> z:</span><br><span class="line">    ...:     print(i)</span><br><span class="line">    ...:     </span><br><span class="line">(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: x[(<span class="number">0</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">0</span>)]</span><br><span class="line">Out[<span class="number">53</span>]: array([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">73</span>]: z = list(zip(*y))</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: x[z]</span><br><span class="line">Out[<span class="number">74</span>]: array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure></p><h2 id="np-setdiff1d-x-y-intersect1d-x-y"><a href="#np-setdiff1d-x-y-intersect1d-x-y" class="headerlink" title="np.setdiff1d(x,y),intersect1d(x,y)"></a>np.setdiff1d(x,y),intersect1d(x,y)</h2><p>集合的减法运算,交集运算</p><hr><h2 id="np-random-choice-5-3"><a href="#np-random-choice-5-3" class="headerlink" title="np.random.choice(5,3)"></a>np.random.choice(5,3)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.choice(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;参考链接&lt;br&gt;&lt;a href=&quot;https://www.yiibai.com/numpy/numpy_ndarray_object.html#article-start&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NumPy Ndarray对象&lt;/a&gt;&lt;br&gt;这只是简单的入门，以后接触得越多，对于其中的理解也才会更加全面，并做补充。&lt;br&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="numpy" scheme="http://yoursite.com/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>pytorch chapter8 neural style</title>
    <link href="http://yoursite.com/2018/09/11/pytorch-chapter8-neural-style/"/>
    <id>http://yoursite.com/2018/09/11/pytorch-chapter8-neural-style/</id>
    <published>2018-09-11T03:19:25.000Z</published>
    <updated>2018-10-01T07:49:55.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>本文主要是针对<a href="https://github.com/chenyuntc/pytorch-book" target="_blank" rel="noopener">陈云的PyTorch入门与实践</a>的第八章的内容进行复现，准确地说，是看着他写的代码，自己再实现一遍，所以更多地是在讲解实现过程中遇到的问题或者看到的好的方法，而不是针对论文的原理的进行讲解。对于原理，也只是会一笔带过。原理篇暂时不准备留坑，因为原理是个玄学。<br>这是我的<a href="https://github.com/TJJTJJTJJ/pytorch__learn" target="_blank" rel="noopener">代码</a><br>大神链接：(<a href="https://github.com/anishathalye/neural-style" target="_blank" rel="noopener">https://github.com/anishathalye/neural-style</a>)</p><hr><a id="more"></a><h1 id="2-问题及其解决"><a href="#2-问题及其解决" class="headerlink" title="2 问题及其解决"></a>2 问题及其解决</h1><p>我在第六章和第七章的时候还是基于pytorch 0.4.0，而第八章的时候我开始基于pytorch 0.4.1，所以以下的内容介绍都是基于0.4.1</p><h2 id="2-1-文件组织形式"><a href="#2-1-文件组织形式" class="headerlink" title="2.1 文件组织形式"></a>2.1 文件组织形式</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">├─checkpoints/</span><br><span class="line">├─content_img/</span><br><span class="line">│  ├─<span class="selector-tag">input</span>.jpg</span><br><span class="line">│  ├─output.jpg</span><br><span class="line">│  └─style.jpg</span><br><span class="line">├─data/</span><br><span class="line">│  ├─coco/<span class="selector-tag">a</span>.jpg</span><br><span class="line"></span><br><span class="line">├─dataset/</span><br><span class="line">│  ├─__init__.py</span><br><span class="line">│  └─dataset.py</span><br><span class="line">├─models/</span><br><span class="line">│  ├─__init__.py</span><br><span class="line">│  └─PackedVGG.py</span><br><span class="line">│  └─transformer_net.py</span><br><span class="line">└─utils/</span><br><span class="line">│  ├─__init__.py</span><br><span class="line">│  └─utils.py</span><br><span class="line">│  └─visualize.py</span><br><span class="line">├─config.py</span><br><span class="line">└─main.py</span><br></pre></td></tr></table></figure><p>其中，上半部分是对数据和模型的保存组织形式，我们只需要能对应起来即可，其中，checkpoints是为了保存模型，content_img中的style.jpg是训练时候的风格图片，input.jpg是测试的输入，output.jpg是测试的输出，data中的数据是训练数据，主要是因为这个训练数据太整齐，是用ImageFolder读取的，为了避免麻烦，也为了在测试的时候方便观察图片，所以style.jpg我们暂时放在了content中。<br>下半部分是重点，我们需要写的代码，每次都是先从dataset.py和models开始写起，然后导入visualize.py，这个文件基本不会发生改变，然后同时写main.py和config.py，边写边扩展utils中的其他文件，例如main中用到的函数等等。</p><h2 id="2-2-models"><a href="#2-2-models" class="headerlink" title="2.2 models"></a>2.2 models</h2><h3 id="PackedVGG-py"><a href="#PackedVGG-py" class="headerlink" title="PackedVGG.py"></a>PackedVGG.py</h3><p>这里我们主要是取已有的网络，得到中间层的输出<br><strong>models.named_parameters()</strong>:返回的是一个生成器，每次返回一个参数的关键字和值<br><strong>models.state_dict()</strong>:返回的是一个字典，记录了参数的关键字和值<br><strong>models.parameters()</strong>:返回的是变量，没有名字，可以在requires_grad中用到<br>models.features返回的是相对应的模型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">7</span>]: <span class="keyword">from</span> torchvision.models <span class="keyword">import</span> vgg16</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: models = vgg16(pretrained=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: model = models.features[:<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: model</span><br><span class="line">Out[<span class="number">10</span>]: </span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: models.parameters()</span><br><span class="line">Out[<span class="number">11</span>]: &lt;generator object Module.parameters at <span class="number">0x7f8fad26b3b8</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: models.named_parameters()</span><br><span class="line">Out[<span class="number">12</span>]: &lt;generator object Module.named_parameters at <span class="number">0x7f8f29e99d58</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: model.named_parameters()</span><br><span class="line">Out[<span class="number">13</span>]: &lt;generator object Module.named_parameters at <span class="number">0x7f8fad26b2b0</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: model.parameters()</span><br><span class="line">Out[<span class="number">14</span>]: &lt;generator object Module.parameters at <span class="number">0x7f8fad26b4c0</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: model.state_dict()</span><br><span class="line">Out[<span class="number">15</span>]: </span><br><span class="line">OrderedDict([(<span class="string">'0.weight'</span>, tensor([[[[<span class="number">-0.5537</span>,  <span class="number">0.1427</span>,  <span class="number">0.5290</span>],</span><br><span class="line">                        [<span class="number">-0.5831</span>,  <span class="number">0.3566</span>,  <span class="number">0.7657</span>],</span><br><span class="line">                        [<span class="number">-0.6902</span>, <span class="number">-0.0480</span>,  <span class="number">0.4841</span>]],</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> vgg16</span><br><span class="line">models = vgg16(pretarined = <span class="keyword">True</span>)</span><br><span class="line">In [<span class="number">19</span>]: models</span><br><span class="line">Out[<span class="number">19</span>]: </span><br><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">    (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">6</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">8</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">    (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">11</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">13</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">15</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">16</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">    (<span class="number">17</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">18</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">19</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">20</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">22</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">23</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">    (<span class="number">24</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">25</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">26</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">27</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">29</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">30</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">4096</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">2</span>): Dropout(p=<span class="number">0.5</span>)</span><br><span class="line">    (<span class="number">3</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">    (<span class="number">4</span>): ReLU(inplace)</span><br><span class="line">    (<span class="number">5</span>): Dropout(p=<span class="number">0.5</span>)</span><br><span class="line">    (<span class="number">6</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">1000</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: models.features</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">3</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">  (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">6</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">8</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">  (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">11</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">13</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">15</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">16</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">  (<span class="number">17</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">18</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">19</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">20</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">22</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">23</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">  (<span class="number">24</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">25</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">26</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">27</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">29</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">30</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="keyword">False</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: models.features[<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">21</span>]: ReLU(inplace)</span><br><span class="line"><span class="comment"># list</span></span><br><span class="line">In [<span class="number">27</span>]: models4 = models2[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: models4</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU(inplace)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: models4list</span><br><span class="line">Out[<span class="number">32</span>]: </span><br><span class="line">[Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line"> ReLU(inplace)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: models4list[<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">36</span>]: ReLU(inplace)</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: models4list[<span class="number">1</span>].named_parameters</span><br><span class="line">Out[<span class="number">37</span>]: &lt;bound method Module.named_parameters of ReLU(inplace)&gt;</span><br></pre></td></tr></table></figure><p>sequencial是支持索引操作的<br>list(module)会变成一个list，可以通过索引来获取层，注意，nn.ModuleList, nn.Sequential, nn.Conv等都是Module,都可以通过named_parameters来获取参数。<br>为了能够提取出中间层的输出，作者换了一个方法，用的nn.ModuleList,nn.ModuleList和nn.Sequential的区别在此才真正显现，nn.Sequential更有利于直接把输入传给Module，计算是一个整体，写起来更方便，而nn.Modulist则不能直接把输入传给Module，需要用循环传输入，更有利于在层中做一些保留，提取中间层的输出。后面我们会讲到hook。或者说提取中间层的输出我们可以选择在定义网络的forward中进行，另外，就是需要注意的是，这里的输入是一个batch_size大小的矩阵，所以即便像作者这样，用一个列表保存输出，但实际输出的列表中的元素都是(b,n,h,w)大小的。后面我会验证。</p><p>提取中间层的输出有两种方法：<br>第二种方法参考链接：<a href="https://www.jianshu.com/p/0a23db1df55a" target="_blank" rel="noopener">https://www.jianshu.com/p/0a23db1df55a</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种方法，这种方法是在前向网络中提取输出，好像也是在反向传播网络中，但这种提取中间层是永久性的，也适合用这些层的做其他运算，这些运算是计算在整体网络框架中的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> ii, model <span class="keyword">in</span> enumerate(self.features):</span><br><span class="line">        x = model(x)</span><br><span class="line">        <span class="keyword">if</span> ii <span class="keyword">in</span> &#123;<span class="number">3</span>, <span class="number">8</span>, <span class="number">15</span>, <span class="number">22</span>&#125;:</span><br><span class="line">            results.append(x)</span><br><span class="line"></span><br><span class="line">    vgg_outputs = namedtuple(<span class="string">"VggOutputs"</span>, [<span class="string">'relu1_2'</span>, <span class="string">'relu2_2'</span>, <span class="string">'relu3_3'</span>, <span class="string">'relu4_3'</span>])</span><br><span class="line">    <span class="keyword">return</span> vgg_outputs(*results)</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第二种方法，适合在在不影响整体网络的情况下拿出一个分支进行单独计算，现在还不清楚这样子会不会影响backward，个人感觉会，因为也是相当于一个变量对其进行计算，导数为1。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    x= self.model(x)</span><br><span class="line">    self.fea = x</span><br><span class="line">   x = self.main(x)</span><br></pre></td></tr></table></figure><hr><h3 id="transformer-py"><a href="#transformer-py" class="headerlink" title="transformer.py"></a>transformer.py</h3><p>可参考<a href="https://github.com/abhiskk/fast-neural-style/blob/master/neural_style/transformer_net.py" target="_blank" rel="noopener">链接</a></p><ol><li>padding的操作是边界反射补充</li><li>放大方法是双线性插值，而不是ConvTransposed2d，即unsample或者说是interpolate， 但是其中的一个参数align_corners一直<strong>没有理解</strong>，既然是双线性插值，那结果就是固定的，怎么还会因为其他参数发生变化。</li><li><p>其中，写的时候必要的时候可以写写子网络<br>这里我对residualblock提出了疑问，事实上left+right后面可以没有relu层，这一点我们可以从以下链接找到说明。<br><a href="https://github.com/abhiskk/fast-neural-style/blob/master/neural_style/transformer_net.py" target="_blank" rel="noopener">https://github.com/abhiskk/fast-neural-style/blob/master/neural_style/transformer_net.py</a><br><a href="http://torch.ch/blog/2016/02/04/resnets.html" target="_blank" rel="noopener">http://torch.ch/blog/2016/02/04/resnets.html</a></p><blockquote><p>The above result seems to suggest that it’s important to avoid changing data that passes through identity connections only. We can take this philosophy one step further: should we remove the ReLU layers at the end of each residual block? ReLU layers also perturb data that flows through identity connections, but unlike batch normalization, ReLU’s idempotence means that it doesn’t matter if data passes through one ReLU or thirty ReLUs. When we remove ReLU layers at the end of each building block, we observe a small improvement in test performance compared to the paper’s suggested ReLU placement after the addition. However, the effect is fairly minor. More exploration is needed.</p></blockquote></li><li><p>对于其他的出现的网络架构，其实都是有理可循的，但暂时不是本篇的重点，所以只做一个记录。<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">上卷积</a>简单地看了看这篇论文，unsample要比ConvTransposed2D要好，但是没有看懂。留作后续。  </p></li></ol><hr><h3 id="dataset-py-amp-visualize-py"><a href="#dataset-py-amp-visualize-py" class="headerlink" title="dataset.py &amp; visualize.py"></a>dataset.py &amp; visualize.py</h3><p>因为加载数据是用的tv.datasets.ImageFolder，所以dataset.py不需要写，<br>visualize.py是第六章的时候写好的，这里只写几个改进的</p><ol><li>self.vis = Visdom(env=env,use_incoming_socket=False, **kwargs)，这里的use_incoming_socket是不需要从浏览器接受数据到软件中，如果没有的话会提示 ‘&gt;’ not supported between instances of ‘float’ and ‘NoneType’</li><li>在一个函数前提示输入的大小和类型是一件很重要的事情，必要的时候需要输入分布，</li><li>这里的plot用了一个很巧的方法，用字典记录不同的点<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.index = &#123;&#125;</span><br><span class="line">x = self.index.get(win,<span class="number">0</span>)</span><br><span class="line">self.index[win] = x+<span class="number">1</span></span><br></pre></td></tr></table></figure></li></ol><p>其他的细节可以看代码中的记录，应该比较清晰了。</p><hr><h3 id="main-py-amp-utils-py-amp-config-py"><a href="#main-py-amp-utils-py-amp-config-py" class="headerlink" title="main.py &amp; utils.py &amp;  config.py"></a>main.py &amp; utils.py &amp;  config.py</h3><p>其中utils主要为main提供一些用到的函数，config提供参数，<br>main作为主函数，里面主要就是train(),val(),test(),help(),下面记录一些写main函数的一些疑问。</p><h4 id="cuda"><a href="#cuda" class="headerlink" title="cuda"></a>cuda</h4><p>这里写几种怎么从cpu到gpu的方法以及应用场景。<br><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种</span></span><br><span class="line">device = t.device(<span class="string">'cuda'</span>) <span class="keyword">if</span> opt.use_gpu <span class="keyword">else</span> t.device(<span class="string">'cpu'</span>)</span><br><span class="line">models.<span class="keyword">to</span>(device)</span><br><span class="line">tensor = tensor.<span class="keyword">to</span>(device)</span><br><span class="line">此时使用默认的cuda，一般是cuda:<span class="number">0</span>，适用于全局</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种</span></span><br><span class="line">torch.cuda.current_device() <span class="comment"># 查询当前GPU</span></span><br><span class="line">torch.cuda.set_device(<span class="number">1</span>)</span><br><span class="line">device = torch.device(<span class="string">'cuda'</span>)</span><br><span class="line">models.<span class="keyword">to</span>(device)</span><br><span class="line">此时用的是cuda:<span class="number">1</span>，使用于全局</span><br><span class="line"></span><br><span class="line"><span class="comment">#第三种</span></span><br><span class="line"><span class="comment">#上下文管理器</span></span><br><span class="line"><span class="keyword">with</span> torch.cuda.device(<span class="number">1</span>):</span><br><span class="line">    models.<span class="keyword">to</span>(device)</span><br><span class="line"><span class="comment">#第四种</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>]=<span class="string">"2"</span></span><br><span class="line">没用过</span><br></pre></td></tr></table></figure></p><h3 id="tqdm"><a href="#tqdm" class="headerlink" title="tqdm"></a><a href="">tqdm</a></h3><p><a href="https://blog.csdn.net/langb2014/article/details/54798823?locationnum=8&amp;fps=1" target="_blank" rel="noopener">https://blog.csdn.net/langb2014/article/details/54798823?locationnum=8&amp;fps=1</a><br>进度条，但是只在jupyter和终端中用的时候效果很明显，在代码中用的效果没有那么好，tqdm试了试，用在enumerate()中时，需要写成这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">elements = (<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>)</span><br><span class="line"><span class="keyword">for</span> count, ele <span class="keyword">in</span> tqdm(enumerate(elements)):</span><br><span class="line">    print(count, i)</span><br><span class="line"><span class="comment"># two arguments</span></span><br><span class="line"><span class="keyword">for</span> count, ele <span class="keyword">in</span> tqdm(enumerate(elements), total=len(train_ids), leave=<span class="keyword">False</span>):</span><br><span class="line">    print(count, i)</span><br></pre></td></tr></table></figure></p><p>包括zip也是一样，因为他们返回的是一个生成器，并不知道长度。</p><h3 id="反向传播和梯度下降"><a href="#反向传播和梯度下降" class="headerlink" title="反向传播和梯度下降"></a>反向传播和梯度下降</h3><p>参考链接<a href="https://blog.csdn.net/qq_16234613/article/details/80025832" target="_blank" rel="noopener">https://blog.csdn.net/qq_16234613/article/details/80025832</a><br>这里主要是针对第七章和第八章出现的反向传播和梯度下降出现的问题进行记录。<br>在第七章，是这么实现分别训练的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fake_img =  netg(noises).detach() </span><br><span class="line">fake_output = netd(fake_img)</span><br><span class="line">error_d_fake = criterion(fake_output, fake_labels)</span><br><span class="line">error_d_fake.backward()</span><br><span class="line">optimizer_d.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">optimizer_g.zero_grad()</span><br><span class="line">noises.data.copy_(t.randn(opt.batch_size, opt.nz, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">fake_img = netg(noises)</span><br><span class="line">output = netd(fake_img)</span><br><span class="line">error_g = criterion(output, true_labels)</span><br><span class="line">error_g.backward()</span><br><span class="line">optimizer_g.step()</span><br></pre></td></tr></table></figure></p><p>y = x.detach()：表示将生成一个新的叶子节点，值与当前节点的值相同，但是y.requires_grad = False, y.grad_fn=None，此时x和y共享内存，对y数据的操作也会影响x，可以理解为冻结了通过y进行反向传播的路。如果在网络的输出detach，即y= models(x).detach()，可以理解成，models只进行前向传播，grad=None。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">17</span>]: <span class="selector-tag">a</span> = torch.ones(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: <span class="selector-tag">a</span>.requires_grad=True</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: <span class="selector-tag">b</span> = a*<span class="number">2</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: <span class="selector-tag">b</span>.requires_grad</span><br><span class="line">Out[<span class="number">20</span>]: True</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: <span class="selector-tag">b</span>.grad_fn</span><br><span class="line">Out[<span class="number">21</span>]: &lt;MulBackward at <span class="number">0</span>x7f8fac6e40f0&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: c = <span class="selector-tag">b</span>.detach()</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: c.requires_grad</span><br><span class="line">Out[<span class="number">23</span>]: False</span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: print(c.grad_fn)</span><br><span class="line">None</span><br><span class="line">In [<span class="number">25</span>]: c.is_leaf</span><br></pre></td></tr></table></figure></p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">In <span class="comment">[2]</span>: a = torch.ones(3,3)</span><br><span class="line">In <span class="comment">[14]</span>: b</span><br><span class="line">Out<span class="comment">[14]</span>: </span><br><span class="line">tensor(<span class="comment">[<span class="comment">[2., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>]</span>, grad_fn=&lt;MulBackward&gt;)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[15]</span>: c =  b.detach()</span><br><span class="line"></span><br><span class="line">In <span class="comment">[16]</span>: c</span><br><span class="line">Out<span class="comment">[16]</span>: </span><br><span class="line">tensor(<span class="comment">[<span class="comment">[2., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>]</span>)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[17]</span>: c<span class="comment">[0,0]</span>=1</span><br><span class="line"></span><br><span class="line">In <span class="comment">[18]</span>: c</span><br><span class="line">Out<span class="comment">[18]</span>: </span><br><span class="line">tensor(<span class="comment">[<span class="comment">[1., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>]</span>)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[19]</span>: b</span><br><span class="line">Out<span class="comment">[19]</span>: </span><br><span class="line">tensor(<span class="comment">[<span class="comment">[1., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>,</span></span><br><span class="line"><span class="comment">        <span class="comment">[2., 2., 2.]</span>]</span>, grad_fn=&lt;MulBackward&gt;)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[20]</span>: c.requires_grad</span><br><span class="line">Out<span class="comment">[20]</span>: False</span><br><span class="line"></span><br><span class="line">In <span class="comment">[21]</span>: b.grad_fn</span><br><span class="line">Out<span class="comment">[21]</span>: &lt;MulBackward at 0x7f764429ffd0&gt;</span><br><span class="line"></span><br><span class="line">In <span class="comment">[22]</span>: b.grad_fn.next_functions</span><br><span class="line">Out<span class="comment">[22]</span>: ((&lt;AccumulateGrad at 0x7f7644428358&gt;, 0),)</span><br><span class="line"></span><br><span class="line">In <span class="comment">[23]</span>: a.grad_fn</span><br></pre></td></tr></table></figure><p>在第八章，是这么表示的<br><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">param</span> <span class="built_in">in</span> vgg16.parameters():</span><br><span class="line">    <span class="built_in">param</span>.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure></p><p>这种表示可以使得某一个网络不参与梯度下降这个过程，但是对于网络的输入和输出还是支持梯度下降的。<br>requires_grad只是表示当前的变量不再需要梯度下降，<br>综上所述，对于中间变量，需要使用x.detach()，使其变成默认的叶子节点，对于叶子节点，使用x.requires_grad。并且对于中间变量使用requires_grad会报错。</p><p>在第八章，还有一种表示方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> t.no_grad():</span><br><span class="line">    features = vgg16(style_img)</span><br><span class="line">    gram_style = [gram_matrix(feature) <span class="keyword">for</span> feature <span class="keyword">in</span> features]</span><br><span class="line"></span><br><span class="line"><span class="meta">@t.no_grad()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stylize</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p><p>这种方法会使得任何计算得到的结果都是requires_grad = False,暂时不清楚和detach()的区别。也是一种表示只前向传播的方法，不参与反向传播和梯度下降。</p><h3 id="train"><a href="#train" class="headerlink" title="train()"></a>train()</h3><p>图片分为两种：风格图片，只需要一张，内容图片，很多，用于训练，这一点没有暂时没有理解为什么这么设置。其中，对输入的图片进行了乘以255，我觉得是因为为了使模型的输出直接就是255，不需要再进行处理，没有验证。<br>ensor.item()<br> tensor.tolist()<br>content_image = tv.datasets.folder.default_loader(opt.content_path)<br>在训练过程中，会发现对于整个训练过程，不仅有神经网络，而且还有自己定义的函数，nn.functional，还有两个损失函数，这是之前没有预料到的。</p><h3 id="保存图片"><a href="#保存图片" class="headerlink" title="保存图片"></a>保存图片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存图片的几种方法，第七章的是 </span></span><br><span class="line"><span class="comment"># 0-1</span></span><br><span class="line">tv.utils.save_image(fix_fake_imgs,<span class="string">'%s/%s.png'</span> % (opt.img_save_path, epoch),normalize=<span class="keyword">True</span>, range=(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># vis.save竟然没找到  我的神   </span></span><br><span class="line"><span class="comment"># 0-1</span></span><br><span class="line">vis.img(<span class="string">'input'</span>)</span><br><span class="line">vis.save([opt.env])</span><br></pre></td></tr></table></figure><h3 id="utils-py"><a href="#utils-py" class="headerlink" title="utils.py"></a>utils.py</h3><p>这里的疑问是得到gram矩阵的时候，为什么要除以c*h*w,而不是h*w，虽然源码都是这么写的。</p><p>写到这里也还是还要很多疑问，暂时保留。<br>昨天发现训练的过程不对，今天在对比代码的过程中，发现了自己写代码的一些漏洞，主要有</p><ol><li>命名不规范：表示同一个东西出现了两个命名，导致了自己在写代码的过程中传参出现了问题，或者是一类东西没有一个规则进行命名，导致自己在写代码的过程中用到之前的变量的时候必须返回去去查找这个变量，效率低且容易出错。</li><li>对源码的修改不是很恰当，导致在写上卷积层的输出和源码完全不一致，这个是自己之前没有遇到的。</li><li>visdom的运用，我用不同的environment导致结果也不一样，default是之前一直用的，这次换成了test1之后显示的结果就对了。这个暂时还不清楚原因，如果是会保留信息的话，但是plot是重新开始画的，等会测试测试vis的问题。是网络的问题。但是vis.save()的介绍是序列化信息，暂时还没有理解。</li></ol><hr><p>## </p><h1 id="对单张图片进行加载验证"><a href="#对单张图片进行加载验证" class="headerlink" title="对单张图片进行加载验证"></a>对单张图片进行加载验证</h1><p>content_image = tv.datasets.folder.default_loader(opt.content_path)<br>可以理解成Image.open，看源码就可以知道的</p><p>贴两个成果图看看效果。<br><img src="/pictures/neural-style/pic1.png" alt="训练过程中的图片"></p><h2 id="遗留的问题"><a href="#遗留的问题" class="headerlink" title="遗留的问题"></a>遗留的问题</h2><p>Gram矩阵为什么可以代表图片风格，这里有个解释(<a href="https://arxiv.org/pdf/1701.01036.pdf)，还没来得及看。" target="_blank" rel="noopener">https://arxiv.org/pdf/1701.01036.pdf)，还没来得及看。</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1 前言&quot;&gt;&lt;/a&gt;1 前言&lt;/h1&gt;&lt;p&gt;本文主要是针对&lt;a href=&quot;https://github.com/chenyuntc/pytorch-book&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;陈云的PyTorch入门与实践&lt;/a&gt;的第八章的内容进行复现，准确地说，是看着他写的代码，自己再实现一遍，所以更多地是在讲解实现过程中遇到的问题或者看到的好的方法，而不是针对论文的原理的进行讲解。对于原理，也只是会一笔带过。原理篇暂时不准备留坑，因为原理是个玄学。&lt;br&gt;这是我的&lt;a href=&quot;https://github.com/TJJTJJTJJ/pytorch__learn&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;代码&lt;/a&gt;&lt;br&gt;大神链接：(&lt;a href=&quot;https://github.com/anishathalye/neural-style&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/anishathalye/neural-style&lt;/a&gt;)&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="deep learning" scheme="http://yoursite.com/categories/deep-learning/"/>
    
    
      <category term="neural style transfer" scheme="http://yoursite.com/tags/neural-style-transfer/"/>
    
  </entry>
  
  <entry>
    <title>data</title>
    <link href="http://yoursite.com/2018/09/06/data/"/>
    <id>http://yoursite.com/2018/09/06/data/</id>
    <published>2018-09-06T15:06:10.000Z</published>
    <updated>2018-09-17T09:13:19.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Market-1501"><a href="#Market-1501" class="headerlink" title="Market-1501"></a>Market-1501</h1><p>[参考链接]<a href="http://blog.fangchengjin.cn/reid-market-1501.html" target="_blank" rel="noopener">http://blog.fangchengjin.cn/reid-market-1501.html</a><br><a href="https://github.com/RSL-NEU/person-reid-benchmark" target="_blank" rel="noopener">https://github.com/RSL-NEU/person-reid-benchmark</a></p><ul><li>6个摄像头</li><li>1501个人，其中751个人、12936张图片用于训练，750个人、19732张图片用于测试，</li><li>3368张查询图片 </li></ul><hr><a id="more"></a><h2 id="目录说明"><a href="#目录说明" class="headerlink" title="目录说明"></a>目录说明</h2><ul><li>bounding_box_test <ul><li>19732张测试图片</li><li>0000_c1s1_000151_01.jpg</li><li>前缀为 0000 表示在提取这 750 人的过程中DPM检测错的图（可能与query是同一个人），-1 表示检测出来其他人的图（不在这 750 人中）</li><li>DPM检测出的</li><li>gallery样本</li></ul></li><li>bounding_box_train <ul><li>12936张训练图片</li><li>0002_c1s1_000451_03.jpg</li><li>train样本</li></ul></li><li>query <ul><li>3368张图片，与test的750人对应 但是是人工绘制的 与bounding_box_test中的图片略微有所不同 与gt_bbox中的图片是一样的</li><li>0001_c1s1_001051_00.jpg</li><li>为 750 人在每个摄像头中随机选择一张图像作为query，因此一个人的query最多有 6 个，共有 3,368 张图像</li><li>query样本</li></ul></li><li>gt_bbox <ul><li>25259张图片 手工绘制  包含1501个行人</li><li>0001_c1s1_001051_00.jpg </li><li>手工标注的bounding box，用于判断DPM检测的bounding box是不是一个好的box</li></ul></li><li>gt_query 是对3368张图片的查询图片的判定，好坏，<ul><li>0001_c1s1_001051_00_good.mat</li><li>matlab格式，用于判断一个query的哪些图片是好的匹配（同一个人不同摄像头的图像）和不好的匹配（同一个人同一个摄像头的图像或非同一个人的图像）</li></ul></li></ul><hr><h2 id="命名规则"><a href="#命名规则" class="headerlink" title="命名规则"></a>命名规则</h2><p>以 0001_c1s1_000151_01.jpg 为例<br>1） 0001 表示每个人的标签编号，从0001到1501；<br>2） c1 表示第一个摄像头(camera1)，共有6个摄像头；<br>3） s1 表示第一个录像片段(sequece1)，每个摄像机都有数个录像段；<br>4） 000151 表示 c1s1 的第000151帧图片，视频帧率25fps；<br>5） 01 表示 c1s1_001051 这一帧上的第1个检测框，由于采用DPM检测器，对于每一帧上的行人可能会框出好几个bbox。00 表示手工标注框 </p><h1 id="DukeMTMC-reID"><a href="#DukeMTMC-reID" class="headerlink" title="DukeMTMC-reID"></a>DukeMTMC-reID</h1><p>DukeMTMC是多目标多摄像机行人跟踪数据集，8个摄像头，2700多个人物，DukeMTMC-reID是DukeMTMC的行人重识别子集，并且提供了人工标注的bounding box。<br>从视频中每 120 帧采样一张图像，得到了 36,411 张图像。一共有 1,404 个人出现在大于两个摄像头下，有 408 个人 (distractor ID) 只出现在一个摄像头下<br>[参考链接]:<a href="http://blog.fangchengjin.cn/reid-duke.html" target="_blank" rel="noopener">http://blog.fangchengjin.cn/reid-duke.html</a></p><hr><h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><ul><li>bounding_box_test<ul><li>0002_c1_f0044158.jpg</li><li>用于测试集的 702 人</li><li>包含 17,661 张图像（随机采样，702 ID + 408 distractor ID）</li></ul></li><li>bounding_box_train<ul><li>0001_c2_f0046182.jpg</li><li>用于训练集的 702 人</li><li>包含 16,522 张图像（随机采样）</li></ul></li><li>query<ul><li>0005_c2_f0046985.jpg</li><li>为测试集中的 702 人在每个摄像头中随机选择一张图像作为 query，共有 2,228 张图像</li></ul></li></ul><p>。</p><hr><h2 id="命名规则-1"><a href="#命名规则-1" class="headerlink" title="命名规则"></a>命名规则</h2><p>0001_c2_f0046182.jpg<br>1） 0001 表示每个人的标签编号；<br>2） c2 表示来自第二个摄像头(camera2)，共有 8 个摄像头；<br>3） f0046182 表示来自第二个摄像头的第 46182 帧。</p><hr><h1 id="CUHK03"><a href="#CUHK03" class="headerlink" title="CUHK03"></a>CUHK03</h1><p>CUHK03是第一个足以进行深度学习的大规模行人重识别数据集，该数据集的图像采集于香港中文大学（CUHK）校园。数据以”cuhk-03.mat”的 MAT 文件格式存储，含有 1467 个不同的人物，由 5 对摄像头采集。<br>[参考链接]<a href="http://blog.fangchengjin.cn/reid-cuhk03.html" target="_blank" rel="noopener">http://blog.fangchengjin.cn/reid-cuhk03.html</a></p><hr><h2 id="目录结构-1"><a href="#目录结构-1" class="headerlink" title="目录结构"></a>目录结构</h2><ul><li>detected - 5 * 1 cell  由机器标注，每个 cell 中包含一对摄像头组采集的照片，每个摄像头组由 M x 10 cells 组成，M 为行人索引，前 5 列和后 5 列分别来自同一组的不同摄像头。cell 内每个元素为一幅 H x W x 3 的行人框图像(uint8 数据类型)，个别图像可能空缺，为空集。<ul><li>843*10 cell 摄像头组pair 1</li><li>440*10 cell 摄像头组pair 2</li><li>77*10 cell 摄像头组pair 3</li><li>58*10 cell  摄像头组pair 4</li><li>49*10 cell摄像头组pair 5</li></ul></li><li>labeled  - 5 * 1 cell  行人框由人工标注，格式和内容和”detected”相同。<ul><li>843*10 cell</li><li>440*10 cell</li><li>77*10 cell</li><li>58*10 cell</li><li>49*10 cell</li></ul></li><li>testsets - 20*1 cell 测试协议，由 20 个 100 x 2 double 类型矩阵组成 (重复二十次)<ul><li>100*2 double matrix 100 行代表 100 个测试样本，第 1 列为摄像头 pair 索引，第 2 列为行人索引</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Market-1501&quot;&gt;&lt;a href=&quot;#Market-1501&quot; class=&quot;headerlink&quot; title=&quot;Market-1501&quot;&gt;&lt;/a&gt;Market-1501&lt;/h1&gt;&lt;p&gt;[参考链接]&lt;a href=&quot;http://blog.fangchengjin.cn/reid-market-1501.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://blog.fangchengjin.cn/reid-market-1501.html&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/RSL-NEU/person-reid-benchmark&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/RSL-NEU/person-reid-benchmark&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;6个摄像头&lt;/li&gt;
&lt;li&gt;1501个人，其中751个人、12936张图片用于训练，750个人、19732张图片用于测试，&lt;/li&gt;
&lt;li&gt;3368张查询图片 &lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="re-id" scheme="http://yoursite.com/categories/re-id/"/>
    
    
      <category term="data" scheme="http://yoursite.com/tags/data/"/>
    
      <category term="re-id" scheme="http://yoursite.com/tags/re-id/"/>
    
  </entry>
  
  <entry>
    <title>Inception</title>
    <link href="http://yoursite.com/2018/09/04/Inception/"/>
    <id>http://yoursite.com/2018/09/04/Inception/</id>
    <published>2018-09-04T11:23:43.000Z</published>
    <updated>2018-09-24T05:50:40.398Z</updated>
    
    <content type="html"><![CDATA[<p>关于Inception的好的讲解<br><a href="https://blog.csdn.net/loveliuzz/article/details/79135583" target="_blank" rel="noopener">深度学习卷积神经网络——经典网络GoogLeNet(Inception V3)网络的搭建与实现</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;关于Inception的好的讲解&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/loveliuzz/article/details/79135583&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;深度学习卷积神经网络——经典网络Goo
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>deconv\dilated conv</title>
    <link href="http://yoursite.com/2018/09/04/deconv/"/>
    <id>http://yoursite.com/2018/09/04/deconv/</id>
    <published>2018-09-04T08:07:46.000Z</published>
    <updated>2018-09-12T03:09:02.924Z</updated>
    
    <content type="html"><![CDATA[<p>最近看的一片论文里看到了反卷积，找了一些材料，记录一下，留作纪念。<br>首先定义符号：    </p><ul><li>假设本文提到的图形和卷积核都是一维的线或者二维的正方形，$x$和$y$轴方向的padding和stride相同    </li><li>$i,o,k,p,s,i’,o’,k’,p’,s’$分别表示卷积/反卷积输入图片的大小input size, 输出图片的大小 output size，卷积/反卷积的核大小kernel size，padding，stride.<br><a href="https://github.com/vdumoulin/conv_arithmetic#convolution-arithmetic" target="_blank" rel="noopener">动图演示</a><br><a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/" target="_blank" rel="noopener">详细解析</a>    <a id="more"></a>反卷积对应的是直接在原图上添加0<br>对应的公式如下：<br>$$ i’=o$$<br>$$ o’=i $$<br>$$ k’=k $$<br>$$ s’=1$$<br>$$ p’=k-1-p $$<br>$$ d’=1 $$<br>$$ o’ = (s-1)(i’-1)+i’-k’+2p’ $$<br>$$ o’ =   s(i’-1)+k-2p $$<br>$$ d’ = 2$$<br>$$ k’ = k + (d-1)<em>(k-1) $$<br>$$ p’ = k-1-p+(d-1)</em>(k-1) $$<br>$$ o’ = (s-1)(i’-1)+i’-k’+2p’ $$<br>$$ o’ = s(i’-1)+k+(d-1)<em>(k-1)-2p’ $$<br>所以要保持图片图片大小不变，必须令s=1，$$ d = \frac{2}{k-1}</em>p $$<br>例如：k=3，d=p,</li></ul><p>以上只是先说明了对应尺寸的大小，具体的数学原理留作补充。</p><p>扩张卷积的计算公式与上面不一样<br>扩张卷积扩张的是卷积核的大小，在卷积核上添加0<br><a href="https://blog.csdn.net/Quincuntial/article/details/78743033" target="_blank" rel="noopener">扩张卷积</a><br>$$ o’=\frac{i’-k+2p-(k-1)*(d-1)}{s}+1$$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近看的一片论文里看到了反卷积，找了一些材料，记录一下，留作纪念。&lt;br&gt;首先定义符号：    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设本文提到的图形和卷积核都是一维的线或者二维的正方形，$x$和$y$轴方向的padding和stride相同    &lt;/li&gt;
&lt;li&gt;$i,o,k,p,s,i’,o’,k’,p’,s’$分别表示卷积/反卷积输入图片的大小input size, 输出图片的大小 output size，卷积/反卷积的核大小kernel size，padding，stride.&lt;br&gt;&lt;a href=&quot;https://github.com/vdumoulin/conv_arithmetic#convolution-arithmetic&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;动图演示&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://buptldy.github.io/2016/10/29/2016-10-29-deconv/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;详细解析&lt;/a&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="卷积\反卷积 扩张卷积" scheme="http://yoursite.com/tags/%E5%8D%B7%E7%A7%AF-%E5%8F%8D%E5%8D%B7%E7%A7%AF-%E6%89%A9%E5%BC%A0%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>pytorch</title>
    <link href="http://yoursite.com/2018/08/26/pytorch-1/"/>
    <id>http://yoursite.com/2018/08/26/pytorch-1/</id>
    <published>2018-08-26T13:38:25.000Z</published>
    <updated>2018-09-17T07:36:14.630Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>魔术方法: P23  </p><p>调试: P27<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ipdb</span><br><span class="line"><span class="title">ipdb</span>.set_trace()</span><br></pre></td></tr></table></figure></p><p>带下划线_的函数会修改Tensor本身，比如x.add_(y)和x.add(y)的区别  </p><h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>Numpy与Tensor共享内存<br>b = a.numpy() # Tensor -&gt; Numpy<br><a id="more"></a><br>a = t.from_numpy(a)# Numpy -&gt; Tensor<br>x = x.cuda()<br>tensor的操作:torch.function,tensor.function.<br>普通索引共享内存<br>高级索引不共享内存<br>线性代数函数 P70<br>自动广播原则: unsqueese(view),expand(expand_as)<br>tensor=Tensor+Storage<br>持久化和加载: t.save(a,’a.pth’) b=t.load(‘a.pth’) P77<br>%timeit -n 10</p><hr><h2 id="Variable和autograd"><a href="#Variable和autograd" class="headerlink" title="Variable和autograd"></a>Variable和autograd</h2><p>from torch.autograd import Variable<br>三个属性<br>data: 对应Tensor<br>grad: 梯度，和data大小一样，也是Variable<br>grad_fn: 指向Function对象,用于构建计算图。用户创建对应叶子节点,grad_fn=None.记录的是它什么操作的输出。<br>Variable的构造函数的关键字参数:requires_grad(bool):是否需要求导; volatile(bool):True表示之上的计算图都不会求导<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = Variable(t.ones(2,2),requires_grad = True)</span><br><span class="line">y = x.sum()</span><br><span class="line">y.grad_fn</span><br><span class="line">y.backward()</span><br><span class="line">x.grad</span><br><span class="line">x.grad.data.zero_() <span class="comment"># 反向传播清零</span></span><br></pre></td></tr></table></figure></p><p>variable.backward(grad_variable=None, retain_graph=None, create_graph=None)<br>假设用户输入的数据是真实的不需要求导的。<br>数值在前向传导过程成会保存成buffer,计算梯度之后自动清空。多次反向求导可以使用关键字参数retain_graph=True<br>retain_graph=True 实现多次反向传播？？？？</p><p>反向传播过程中非叶子节点的导数在计算完之后就会清空，y=x*w,z=y.sum() 其中y.grad会清空。其对应的方法有两种，P92，t.autograd.grad(z,y)和hook<br>扩展Autograd Function：P95 自己实现前向和反向</p><hr><h2 id="nn-Module"><a href="#nn-Module" class="headerlink" title="nn.Module"></a>nn.Module</h2><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">Net</span>(<span class="title">nn</span>.<span class="type">Module</span>):</span></span><br><span class="line"><span class="class">    def \_\_init\_\_():</span></span><br><span class="line"><span class="class">super(<span class="type">Net</span>,<span class="title">self</span>).__init__()</span></span><br><span class="line"><span class="class">\# 有参数的层的定义</span></span><br><span class="line"><span class="class">def forward(<span class="title">self</span>,<span class="title">x</span>):</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">net = <span class="type">Net</span>()</span></span><br><span class="line"><span class="class">print(<span class="title">net</span>)</span></span><br><span class="line"><span class="class">list(<span class="title">net</span>.<span class="title">parameters</span>())</span></span><br><span class="line"><span class="class">for name,paramenters in net.named_parameters():</span></span><br><span class="line"><span class="class">print(<span class="title">name</span>,':',<span class="title">parameters</span>.<span class="title">size</span>())</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">out = net(<span class="title">input</span>)</span></span><br><span class="line"><span class="class">net.zero_grad()</span></span><br><span class="line"><span class="class">out.backwad(<span class="type">Variable</span>(<span class="title">t</span>.<span class="title">ones</span>(1,10)))</span></span><br><span class="line"><span class="class">&gt; ???</span></span><br></pre></td></tr></table></figure><p>nn.Sequential()<br>nn.ModuleList()<br>nn.ParameterList()<br>在优化器中为各层分别设置学习率<br>nn.functional对应nn.Module<br>参数初始化:<br>nn.Conv2d: nSamples<em>nChannels</em>Height*Widh<br>单样本: input.unsqueeze(0)<br>model.train()<br>model.eval()<br>前向或者后向注册钩子函数，P125，可以查看中间层。<br>获取网络的模块属性：getattr(module)P128<br>保存模型：t.save(net.state_dict(), ‘net.pth’)<br>加载模型：net2=Net() net2.load_state_dict(t.load(‘net.pth’))<br>多个GPU并行操作</p><hr><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output = net(input)</span><br><span class="line">target = Variable(t.arrange(0,10))</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">net</span><span class="selector-class">.zero_grad</span>()</span><br><span class="line"><span class="selector-tag">print</span>(<span class="selector-tag">net</span><span class="selector-class">.con1</span><span class="selector-class">.bias</span><span class="selector-class">.grad</span>)</span><br><span class="line"><span class="selector-tag">loss</span><span class="selector-class">.backward</span>()</span><br><span class="line"><span class="selector-tag">print</span>(<span class="selector-tag">net</span><span class="selector-class">.conv1</span><span class="selector-class">.bias</span><span class="selector-class">.grad</span>)</span><br></pre></td></tr></table></figure><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learning_rate=0.01</span><br><span class="line">for f in net.parameters():</span><br><span class="line">　　f.data.sub_(f.grad.data*leaning_data)</span><br></pre></td></tr></table></figure><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import torch.optim as optim</span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=0.01)</span><br><span class="line"><span class="comment"># 训练过程中 梯度清零</span></span><br><span class="line">optimizer.zero_grad() <span class="comment"># 等效于 net.zero_grad()</span></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">output=net(input)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line"><span class="comment"># 反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="comment"># 更新参数</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><h2 id="CIFAR-10分类"><a href="#CIFAR-10分类" class="headerlink" title="CIFAR-10分类"></a>CIFAR-10分类</h2><ol><li>数据预处理:transform,trainset,trainloader,testset,testloader </li><li>定义网络:Net(nn.Module),super(Net,self).<strong>init</strong>(),forward()</li><li>定义损失函数和优化器</li><li>训练网络<ol><li>输入数据</li><li>梯度清零</li><li>前向传播+反向传播</li><li>更新参数  </li></ol></li></ol><hr><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>自定义的数据集需要继承Dataset类，并实现两个Python魔术方法<br>__getitem__:返回一个样本。obj[index]=obj.<strong>getitem</strong>(index)<br>__len__:返回样本数量。<br>transform=T.Compose()<br>trans=T.Lambda(lambda img:img.rotate(randonm()*360))<br>ImageFolder(root,transform,target_transform,loader)P139<br>self.class_to_idx了解label和文件夹名的映射关系<br>DataLoader()定义shuffle等P142<br>取样:P146<br>工具包:torchvision  P147</p><ul><li>models:训练好模型</li><li>dataset:数据集加载</li><li>transforms:数据预处理操作，主要针对Tensor和PIL Image对象的操作    </li></ul><p>make_grid和save_img<br>可视化工具 Tensorboard和visdom<br>tensor_board和TensorboardX<br>visdom:env pane</p><p>%env LS_COLORS=None<br>!tree –charset ascii data/dogcat<br>Tensor–numpy:np.array(Tensor) torch.Tensor(np.darray)<br>PIL.image–numpy:np.asarray(PIL.image) image.fromarray(numpy.ndarray)<br>PIL.image–Tensor:trans = transforms.Compose([transforms.ToTensor()]) tens = trans(img)  ToPILImage()  </p><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>P158<br>with t.cuda.device(1):<br>t.cuda.set_device(1)<br>export CUDA_VISIVLE_DEVICES=1<br>b = t.load(‘a.pth’)<br>c = t.load(‘a.pth’,map_location=lamdba storage, loc: storage)<br>d = t.load(‘a.pth’,map_location={‘cuda:1’:’cuda:0’})<br>Module和Optimizer: state_dict  </p><h2 id="Dog-vs-Cat"><a href="#Dog-vs-Cat" class="headerlink" title="Dog.vs.Cat"></a>Dog.vs.Cat</h2><p>checkpoints/ 中间模型<br>data/</p><ul><li>__init__.py  </li><li>dataset.py  </li><li><ul><li>def <strong>init</strong>(self,root,transform=None, train=True, test=False):</li></ul></li><li><ul><li>def <strong>getitem</strong>(self,index):</li></ul></li><li><ul><li>def <strong>len</strong>(self):</li></ul></li><li>get_data.sh<br>models/</li><li>__init__.py</li><li>AlexNet.py</li><li>BasicModule.py</li><li>ResNet34.py<br>utils/</li><li>__init__.py</li><li>visualize.py<br>config.py<br>main.py<br>requirements.txt<br>README.md</li></ul><p>main.py</p><ul><li>def train(**kwargs):</li><li>def test(**kwargs):</li><li>def val(model,dataloader):</li><li>def help():</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__==<span class="string">'main'</span>:</span><br><span class="line">    <span class="keyword">import</span> fire</span><br><span class="line">    fire.Fire()</span><br></pre></td></tr></table></figure><h2 id="pytorch-中文文档"><a href="#pytorch-中文文档" class="headerlink" title="pytorch 中文文档"></a>pytorch 中文文档</h2><p><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/functional/" target="_blank" rel="noopener">https://pytorch-cn.readthedocs.io/zh/latest/package_references/functional/</a></p><h1 id="PyTorch实战指南-第六章-Dog-VS-Cat"><a href="#PyTorch实战指南-第六章-Dog-VS-Cat" class="headerlink" title="PyTorch实战指南 第六章  Dog.VS.Cat"></a>PyTorch实战指南 第六章  Dog.VS.Cat</h1><p>这是根据深度学习框架：PyTorch入门与实践这本书的第六章写的代码，是关于猫狗识别的，在这个过程中，一边看，一边写，刚开始是运行作者已经写好的代码，后来自己在jupyter上进行复制的复现，发现import无法导入ipynb文件，在使用了Ipynb_importer.py之后可以实现同一文件内导入ipynb模块，如果是在其他文件中进行导入，会有点费事，以下会记录Ipynb_importer.py的用法。因为费事，自己开始开始使用pycharm+jupyter的方式，直接自己根据作者提供的源码进行编写，在编写的过程中接受作者的思想。用pycharm的不方便的地方是无法直接运行测试，所以采取的是对自己不熟悉的模块或者方法，用jupyter进行测试，而直接编写则是pycharm。但是感觉pycharm还是没有那么好用，可能是自己用的少。我是按照data、model、util、main+config、requirement的顺序编写的。在编写函数的过程中，因为刚开始不理解各个模块是怎么组织起来的，所以都是从简单的开始，所以函数的位置和作者的不一样，其中对于model.save和model.load、vis.plot和vis.log的封装让我感觉很有意思，刚开始是编写的时候只能直接打上问号，因为不懂这么编写的意义，但在编写主函数main的时候才感觉到了这种编写的好处，基本把模型训练和对模型、结果的处理完全分离开，避免了耦合性很强的后果。</p><hr><h2 id="Ipynb-importer-py"><a href="#Ipynb-importer-py" class="headerlink" title="Ipynb_importer.py"></a>Ipynb_importer.py</h2><p>我通过几次测试发现，import Ipynb_importer 只需要放在你的当前要运行的文件中即可，然后在其他文件下的<strong>init</strong>.py 中导入所有的当前文件夹中的Module，就像这样<br>/first/second/models/<br>—–<strong>init</strong>.py<br>————- None<br>—–BasicModule.ipynb<br>—–AlexNet.ipynb<br>———-from models.BasicModule import BasicModule</p><p>/first/main.py<br>import Ipynb_importer<br>from models import AlexNet    </p><p>之所以在AlexNet中写models.BasicModule是因为直接导入BasicModule会报错，我根据<strong>dict</strong>的输出发现有问题，这一点和<a href="https://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Importing%20Notebooks.html" target="_blank" rel="noopener">官网</a>介绍的有一点区别，我没有实现官网说明的跨文件夹导入。因为如果改文件夹导入的话，models.BasicModule要接着换成相应的名字，与我预想的不一致，我预想的是不管在哪里导入，已经导入的应该不受影响才对。</p><hr><h2 id="ipynb-py-sh"><a href="#ipynb-py-sh" class="headerlink" title="ipynb-py.sh"></a>ipynb-py.sh</h2><p>之后发现了这个神器，可以把ipynb转化成.py，还是挺好用的，转化之后也没问题。</p><hr><p>同时，借助这次实验，自己对python的掌握也更深了一点。</p><hr><p>不过对于网络的构成还是有一些问题，那就是网络为什么这么写，这应该属于理论的东西。还需要进一步加强。    </p><hr><p>这次实验一共用了三天才完全搞懂，可以说其中涉及到的函数的用法基本都明白了。<br>本意是记录自己，不过如果有任何问题，欢迎交流。     </p><hr><h1 id="PyTorch实战指南-第七章-DCGAN"><a href="#PyTorch实战指南-第七章-DCGAN" class="headerlink" title="PyTorch实战指南 第七章 DCGAN"></a>PyTorch实战指南 第七章 DCGAN</h1><p>这一次实现的也比较慢，用了小三天才做完，现在记录一下其中学到的几个东西。</p><h2 id="file"><a href="#file" class="headerlink" title="__file__:"></a>__file__:</h2><p>用来获取模块所在路径 可能是一个相对路径，可能是一个绝对路径，<br>如果当前文件包含在sys.path里面，那么，__file__返回一个相对路径！<br>也可以认为获取模块的名字<br>最后的落脚点一定是XX/XX.py<br>类没有这个属性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">import</span> numpy</span><br><span class="line">In [<span class="number">3</span>]: numpy.__file__                                                                                                 </span><br><span class="line">Out[<span class="number">3</span>]: <span class="string">'F:\\Programs\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py'</span></span><br><span class="line">In [<span class="number">6</span>]: numpy.random.__file__</span><br><span class="line">Out[<span class="number">6</span>]: <span class="string">'F:\\Programs\\Anaconda3\\lib\\site-packages\\numpy\\random\\__init__.py'</span></span><br><span class="line"></span><br><span class="line">$ python test.py <span class="comment">##print(__file__)</span></span><br><span class="line">test.py</span><br></pre></td></tr></table></figure><h2 id="name"><a href="#name" class="headerlink" title="__name__:"></a>__name__:</h2><p>__name__就是标识模块的名字的一个系统变量。这里分两种情况：假如当前模块是主模块（也就是调用其他模块的模块），那么此模块名字就是__main__，通过if判断这样就可以执行“__mian__:”后面的主函数内容；假如此模块是被import的，则此模块名字为文件名字（不加后面的.py），通过if判断这样就会跳过“__main__:”后面的内容。<br>这个模块可以是文件夹的名字，可以是类的名字，可以是__mian__”,XX的形式。<br>可以用于获取当前文件的文件名<br>通过上面方式，python就可以分清楚哪些是主函数，进入主函数执行；并且可以调用其他模块的各个函数等等。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> test.py</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># print(__file__)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># print(__name__)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> test2.py</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># import test</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># print(__file__)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># print(__name__)</span></span></span><br><span class="line">H:\GitHub\pytorch_learn\Chapter7\test.py</span><br><span class="line">test</span><br><span class="line">test2.py</span><br><span class="line">__main__</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># from test import ccc</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># print(ccc.__name__)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># print(__file__)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># print(__name__)</span></span></span><br><span class="line">ccc</span><br><span class="line">test2.py</span><br><span class="line">__main__</span><br></pre></td></tr></table></figure></p><h2 id="type"><a href="#type" class="headerlink" title="type():"></a>type():</h2><p>返回对象的类型<br>如果是module,则返回module<br>如果是类的实例，则返回类的名称，这个名称以XXX.XXX的形式返回，从import的第一个开始算起。<br>常用于判断数据类型，在pytorch中，用于返回模型名称，这个用法很巧妙，相当于返回了子类的类型名字<br>我觉得没有理解作者是怎么用的。在父类里的type(self) 返回的是子类的类名<br><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">In</span> [<span class="number">1</span>]: import numpy</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">2</span>]: <span class="keyword">type</span>(numpy)</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">2</span>]: module</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">3</span>]: a = numpy.<span class="keyword">array</span>(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">4</span>]: <span class="keyword">type</span>(a)</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">4</span>]: numpy.ndarray</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">5</span>]: <span class="keyword">type</span>(numpy.<span class="keyword">array</span>)</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">5</span>]: builtin_function_or_method</span><br></pre></td></tr></table></figure></p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    pass</span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>(<span class="title">A</span>):</span></span><br><span class="line">    pass</span><br><span class="line">  </span><br><span class="line">isinstance(A(), A)    <span class="comment"># returns True</span></span><br><span class="line"><span class="keyword">type</span>(A()) == A        <span class="comment"># returns True</span></span><br><span class="line">isinstance(B(), A)    <span class="comment"># returns True</span></span><br><span class="line"><span class="keyword">type</span>(B()) == A        <span class="comment"># returns False</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>(<span class="title">object</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span></span>(<span class="keyword">self</span>):</span><br><span class="line">print(<span class="keyword">type</span>(<span class="keyword">self</span>))</span><br><span class="line">pass</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>(<span class="title">A</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span></span>(<span class="keyword">self</span>):</span><br><span class="line"><span class="keyword">super</span>(B,<span class="keyword">self</span>).__init__()</span><br><span class="line">print(<span class="keyword">type</span>(<span class="keyword">self</span>))</span><br><span class="line">pass</span><br><span class="line"></span><br><span class="line">import test</span><br><span class="line">test.B()</span><br><span class="line"></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">test</span>.<span class="title">B</span>'&gt; </span></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">test</span>.<span class="title">B</span>'&gt;</span></span><br></pre></td></tr></table></figure><h2 id="class"><a href="#class" class="headerlink" title="__class__:"></a>__class__:</h2><p>和type类似<br><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>(<span class="title">object</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span></span>(<span class="keyword">self</span>):</span><br><span class="line">print(<span class="keyword">type</span>(<span class="keyword">self</span>))</span><br><span class="line">print(<span class="keyword">self</span>.__class__)</span><br><span class="line">pass</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>(<span class="title">A</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span></span>(<span class="keyword">self</span>):</span><br><span class="line"><span class="keyword">super</span>(B,<span class="keyword">self</span>).__init__()</span><br><span class="line">print(<span class="keyword">type</span>(<span class="keyword">self</span>))</span><br><span class="line">print(<span class="keyword">self</span>.__class__)</span><br><span class="line">pass</span><br><span class="line"></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">test</span>.<span class="title">B</span>'&gt;</span></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">test</span>.<span class="title">B</span>'&gt;</span></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">test</span>.<span class="title">B</span>'&gt;</span></span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">test</span>.<span class="title">B</span>'&gt;</span></span><br></pre></td></tr></table></figure></p><h2 id="获取config源码"><a href="#获取config源码" class="headerlink" title="获取config源码"></a>获取config源码</h2><p>打印参数，方便输入参数<br><a href="https://docs.python.org/3/library/inspect.html" target="_blank" rel="noopener">inspect.getsource</a><br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> <span class="keyword">inspect</span> <span class="keyword">import</span> getsource</span><br><span class="line"><span class="keyword">source</span> = getsource(opt.__class__)</span><br><span class="line"><span class="keyword">print</span>(<span class="keyword">source</span>)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基础知识&quot;&gt;&lt;a href=&quot;#基础知识&quot; class=&quot;headerlink&quot; title=&quot;基础知识&quot;&gt;&lt;/a&gt;基础知识&lt;/h1&gt;&lt;p&gt;魔术方法: P23  &lt;/p&gt;
&lt;p&gt;调试: P27&lt;br&gt;&lt;figure class=&quot;highlight elm&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; ipdb&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;title&quot;&gt;ipdb&lt;/span&gt;.set_trace()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;带下划线_的函数会修改Tensor本身，比如x.add_(y)和x.add(y)的区别  &lt;/p&gt;
&lt;h2 id=&quot;Tensor&quot;&gt;&lt;a href=&quot;#Tensor&quot; class=&quot;headerlink&quot; title=&quot;Tensor&quot;&gt;&lt;/a&gt;Tensor&lt;/h2&gt;&lt;p&gt;Numpy与Tensor共享内存&lt;br&gt;b = a.numpy() # Tensor -&amp;gt; Numpy&lt;br&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch-learn chenyun" scheme="http://yoursite.com/tags/pytorch-learn-chenyun/"/>
    
  </entry>
  
  <entry>
    <title>Cmd Markdown</title>
    <link href="http://yoursite.com/2018/08/26/Cmd%20Markdown/"/>
    <id>http://yoursite.com/2018/08/26/Cmd Markdown/</id>
    <published>2018-08-26T09:34:06.000Z</published>
    <updated>2018-09-24T05:54:21.073Z</updated>
    
    <content type="html"><![CDATA[<h1 id="欢迎使用-Cmd-Markdown-编辑阅读器"><a href="#欢迎使用-Cmd-Markdown-编辑阅读器" class="headerlink" title="欢迎使用 Cmd Markdown 编辑阅读器"></a>欢迎使用 Cmd Markdown 编辑阅读器</h1><a id="more"></a><p>我们理解您需要更便捷更高效的工具记录思想，整理笔记、知识，并将其中承载的价值传播给他人，<strong>Cmd Markdown</strong> 是我们给出的答案 —— 我们为记录思想和分享知识提供更专业的工具。 您可以使用 Cmd Markdown：</p><blockquote><ul><li>整理知识，学习笔记</li><li>发布日记，杂文，所见所想</li><li>撰写发布技术文稿（代码支持）</li><li>撰写发布学术论文（LaTeX 公式支持）</li></ul></blockquote><p><img src="https://www.zybuluo.com/static/img/logo.png" alt="cmd-markdown-logo"></p><p>除了您现在看到的这个 Cmd Markdown 在线版本，您还可以前往以下网址下载：</p><h3 id="Windows-Mac-Linux-全平台客户端"><a href="#Windows-Mac-Linux-全平台客户端" class="headerlink" title="Windows/Mac/Linux 全平台客户端"></a><a href="https://www.zybuluo.com/cmd/" target="_blank" rel="noopener">Windows/Mac/Linux 全平台客户端</a></h3><blockquote><p>请保留此份 Cmd Markdown 的欢迎稿兼使用说明，如需撰写新稿件，点击顶部工具栏右侧的 <i class="icon-file"></i> <strong>新文稿</strong> 或者使用快捷键 <code>Ctrl+Alt+N</code>。</p></blockquote><hr><h2 id="什么是-Markdown"><a href="#什么是-Markdown" class="headerlink" title="什么是 Markdown"></a>什么是 Markdown</h2><p>Markdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，<strong>粗体</strong> 或者 <em>斜体</em> 某些文字，更棒的是，它还可以</p><h3 id="1-制作一份待办事宜-Todo-列表"><a href="#1-制作一份待办事宜-Todo-列表" class="headerlink" title="1. 制作一份待办事宜 Todo 列表"></a>1. 制作一份待办事宜 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#13-待办事宜-todo-列表" target="_blank" rel="noopener">Todo 列表</a></h3><ul><li style="list-style: none"><input type="checkbox"> 支持以 PDF 格式导出文稿</li><li style="list-style: none"><input type="checkbox"> 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率</li><li style="list-style: none"><input type="checkbox" checked> 新增 Todo 列表功能</li><li style="list-style: none"><input type="checkbox" checked> 修复 LaTex 公式渲染问题</li><li style="list-style: none"><input type="checkbox" checked> 新增 LaTex 公式编号功能</li></ul><h3 id="2-书写一个质能守恒公式-LaTeX"><a href="#2-书写一个质能守恒公式-LaTeX" class="headerlink" title="2. 书写一个质能守恒公式[^LaTeX]"></a>2. 书写一个质能守恒公式[^LaTeX]</h3><p>$$E=mc^2$$<br>$$ x = {-b \pm \sqrt{b^2-4ac} \over 2a} $$</p><h3 id="3-高亮一段代码-code"><a href="#3-高亮一段代码-code" class="headerlink" title="3. 高亮一段代码[^code]"></a>3. 高亮一段代码[^code]</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@requires_authorization</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SomeClass</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># A comment</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'hello world'</span></span><br></pre></td></tr></table></figure><h3 id="4-高效绘制-流程图"><a href="#4-高效绘制-流程图" class="headerlink" title="4. 高效绘制 流程图"></a>4. 高效绘制 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#7-流程图" target="_blank" rel="noopener">流程图</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: Start</span><br><span class="line">op=&gt;operation: Your Operation</span><br><span class="line">cond=&gt;condition: Yes or No?</span><br><span class="line">e=&gt;end</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br></pre></td></tr></table></figure><h3 id="5-高效绘制-序列图"><a href="#5-高效绘制-序列图" class="headerlink" title="5. 高效绘制 序列图"></a>5. 高效绘制 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#8-序列图" target="_blank" rel="noopener">序列图</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Alice-&gt;Bob: Hello Bob, how are you?</span><br><span class="line">Note right of Bob: Bob thinks</span><br><span class="line">Bob--&gt;Alice: I am good thanks!</span><br></pre></td></tr></table></figure><h3 id="6-高效绘制-甘特图"><a href="#6-高效绘制-甘特图" class="headerlink" title="6. 高效绘制 甘特图"></a>6. 高效绘制 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#9-甘特图" target="_blank" rel="noopener">甘特图</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">title 项目开发流程</span><br><span class="line">section 项目确定</span><br><span class="line">    需求分析       :a1, 2016-06-22, 3d</span><br><span class="line">    可行性报告     :after a1, 5d</span><br><span class="line">    概念验证       : 5d</span><br><span class="line">section 项目实施</span><br><span class="line">    概要设计      :2016-07-05  , 5d</span><br><span class="line">    详细设计      :2016-07-08, 10d</span><br><span class="line">    编码          :2016-07-15, 10d</span><br><span class="line">    测试          :2016-07-22, 5d</span><br><span class="line">section 发布验收</span><br><span class="line">    发布: 2d</span><br><span class="line">    验收: 3d</span><br></pre></td></tr></table></figure><h3 id="7-绘制表格"><a href="#7-绘制表格" class="headerlink" title="7. 绘制表格"></a>7. 绘制表格</h3><table><thead><tr><th>项目</th><th style="text-align:right">价格</th><th style="text-align:center">数量</th></tr></thead><tbody><tr><td>计算机</td><td style="text-align:right">\$1600</td><td style="text-align:center">5</td></tr><tr><td>手机</td><td style="text-align:right">\$12</td><td style="text-align:center">12</td></tr><tr><td>管线</td><td style="text-align:right">\$1</td><td style="text-align:center">234</td></tr></tbody></table><h3 id="8-更详细语法说明"><a href="#8-更详细语法说明" class="headerlink" title="8. 更详细语法说明"></a>8. 更详细语法说明</h3><p>想要查看更详细的语法说明，可以参考我们准备的 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown" target="_blank" rel="noopener">Cmd Markdown 简明语法手册</a>，进阶用户可以参考 <a href="https://www.zybuluo.com/mdeditor?url=https://www.zybuluo.com/static/editor/md-help.markdown#cmd-markdown-高阶语法手册" target="_blank" rel="noopener">Cmd Markdown 高阶语法手册</a> 了解更多高级功能。</p><p>总而言之，不同于其它 <em>所见即所得</em> 的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。<strong>Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。</strong> 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式。</p><hr><h2 id="什么是-Cmd-Markdown"><a href="#什么是-Cmd-Markdown" class="headerlink" title="什么是 Cmd Markdown"></a>什么是 Cmd Markdown</h2><p>您可以使用很多工具书写 Markdown，但是 Cmd Markdown 是这个星球上我们已知的、最好的 Markdown 工具——没有之一 ：）因为深信文字的力量，所以我们和你一样，对流畅书写，分享思想和知识，以及阅读体验有极致的追求，我们把对于这些诉求的回应整合在 Cmd Markdown，并且一次，两次，三次，乃至无数次地提升这个工具的体验，最终将它演化成一个 <strong>编辑/发布/阅读</strong> Markdown 的在线平台——您可以在任何地方，任何系统/设备上管理这里的文字。</p><h3 id="1-实时同步预览"><a href="#1-实时同步预览" class="headerlink" title="1. 实时同步预览"></a>1. 实时同步预览</h3><p>我们将 Cmd Markdown 的主界面一分为二，左边为<strong>编辑区</strong>，右边为<strong>预览区</strong>，在编辑区的操作会实时地渲染到预览区方便查看最终的版面效果，并且如果你在其中一个区拖动滚动条，我们有一个巧妙的算法把另一个区的滚动条同步到等价的位置，超酷！</p><h3 id="2-编辑工具栏"><a href="#2-编辑工具栏" class="headerlink" title="2. 编辑工具栏"></a>2. 编辑工具栏</h3><p>也许您还是一个 Markdown 语法的新手，在您完全熟悉它之前，我们在 <strong>编辑区</strong> 的顶部放置了一个如下图所示的工具栏，您可以使用鼠标在工具栏上调整格式，不过我们仍旧鼓励你使用键盘标记格式，提高书写的流畅度。</p><p><img src="https://www.zybuluo.com/static/img/toolbar-editor.png" alt="tool-editor"></p><h3 id="3-编辑模式"><a href="#3-编辑模式" class="headerlink" title="3. 编辑模式"></a>3. 编辑模式</h3><p>完全心无旁骛的方式编辑文字：点击 <strong>编辑工具栏</strong> 最右侧的拉伸按钮或者按下 <code>Ctrl + M</code>，将 Cmd Markdown 切换到独立的编辑模式，这是一个极度简洁的写作环境，所有可能会引起分心的元素都已经被挪除，超清爽！</p><h3 id="4-实时的云端文稿"><a href="#4-实时的云端文稿" class="headerlink" title="4. 实时的云端文稿"></a>4. 实时的云端文稿</h3><p>为了保障数据安全，Cmd Markdown 会将您每一次击键的内容保存至云端，同时在 <strong>编辑工具栏</strong> 的最右侧提示 <code>已保存</code> 的字样。无需担心浏览器崩溃，机器掉电或者地震，海啸——在编辑的过程中随时关闭浏览器或者机器，下一次回到 Cmd Markdown 的时候继续写作。</p><h3 id="5-离线模式"><a href="#5-离线模式" class="headerlink" title="5. 离线模式"></a>5. 离线模式</h3><p>在网络环境不稳定的情况下记录文字一样很安全！在您写作的时候，如果电脑突然失去网络连接，Cmd Markdown 会智能切换至离线模式，将您后续键入的文字保存在本地，直到网络恢复再将他们传送至云端，即使在网络恢复前关闭浏览器或者电脑，一样没有问题，等到下次开启 Cmd Markdown 的时候，她会提醒您将离线保存的文字传送至云端。简而言之，我们尽最大的努力保障您文字的安全。</p><h3 id="6-管理工具栏"><a href="#6-管理工具栏" class="headerlink" title="6. 管理工具栏"></a>6. 管理工具栏</h3><p>为了便于管理您的文稿，在 <strong>预览区</strong> 的顶部放置了如下所示的 <strong>管理工具栏</strong>：</p><p><img src="https://www.zybuluo.com/static/img/toolbar-manager.jpg" alt="tool-manager"></p><p>通过管理工具栏可以：</p><p><i class="icon-share"></i> 发布：将当前的文稿生成固定链接，在网络上发布，分享<br><i class="icon-file"></i> 新建：开始撰写一篇新的文稿<br><i class="icon-trash"></i> 删除：删除当前的文稿<br><i class="icon-cloud"></i> 导出：将当前的文稿转化为 Markdown 文本或者 Html 格式，并导出到本地<br><i class="icon-reorder"></i> 列表：所有新增和过往的文稿都可以在这里查看、操作<br><i class="icon-pencil"></i> 模式：切换 普通/Vim/Emacs 编辑模式</p><h3 id="7-阅读工具栏"><a href="#7-阅读工具栏" class="headerlink" title="7. 阅读工具栏"></a>7. 阅读工具栏</h3><p><img src="https://www.zybuluo.com/static/img/toolbar-reader.jpg" alt="tool-manager"></p><p>通过 <strong>预览区</strong> 右上角的 <strong>阅读工具栏</strong>，可以查看当前文稿的目录并增强阅读体验。</p><p>工具栏上的五个图标依次为：</p><p><i class="icon-list"></i> 目录：快速导航当前文稿的目录结构以跳转到感兴趣的段落<br><i class="icon-chevron-sign-left"></i> 视图：互换左边编辑区和右边预览区的位置<br><i class="icon-adjust"></i> 主题：内置了黑白两种模式的主题，试试 <strong>黑色主题</strong>，超炫！<br><i class="icon-desktop"></i> 阅读：心无旁骛的阅读模式提供超一流的阅读体验<br><i class="icon-fullscreen"></i> 全屏：简洁，简洁，再简洁，一个完全沉浸式的写作和阅读环境</p><h3 id="8-阅读模式"><a href="#8-阅读模式" class="headerlink" title="8. 阅读模式"></a>8. 阅读模式</h3><p>在 <strong>阅读工具栏</strong> 点击 <i class="icon-desktop"></i> 或者按下 <code>Ctrl+Alt+M</code> 随即进入独立的阅读模式界面，我们在版面渲染上的每一个细节：字体，字号，行间距，前背景色都倾注了大量的时间，努力提升阅读的体验和品质。</p><h3 id="9-标签、分类和搜索"><a href="#9-标签、分类和搜索" class="headerlink" title="9. 标签、分类和搜索"></a>9. 标签、分类和搜索</h3><p>在编辑区任意行首位置输入以下格式的文字可以标签当前文档：</p><p>标签： 未分类</p><p>标签以后的文稿在【文件列表】（Ctrl+Alt+F）里会按照标签分类，用户可以同时使用键盘或者鼠标浏览查看，或者在【文件列表】的搜索文本框内搜索标题关键字过滤文稿，如下图所示：</p><p><img src="https://www.zybuluo.com/static/img/file-list.png" alt="file-list"></p><h3 id="10-文稿发布和分享"><a href="#10-文稿发布和分享" class="headerlink" title="10. 文稿发布和分享"></a>10. 文稿发布和分享</h3><p>在您使用 Cmd Markdown 记录，创作，整理，阅读文稿的同时，我们不仅希望它是一个有力的工具，更希望您的思想和知识通过这个平台，连同优质的阅读体验，将他们分享给有相同志趣的人，进而鼓励更多的人来到这里记录分享他们的思想和知识，尝试点击 <i class="icon-share"></i> (Ctrl+Alt+P) 发布这份文档给好友吧！</p><hr><p>再一次感谢您花费时间阅读这份欢迎稿，点击 <i class="icon-file"></i> (Ctrl+Alt+N) 开始撰写新的文稿吧！祝您在这里记录、阅读、分享愉快！</p><p>作者 <a href="http://weibo.com/ghosert" target="_blank" rel="noopener">@ghosert</a><br>2016 年 07月 07日    </p><p>[^LaTeX]: 支持 <strong>LaTeX</strong> 编辑显示支持，例如：$\sum_{i=1}^n a_i=0$， 访问 <a href="http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference" target="_blank" rel="noopener">MathJax</a> 参考更多使用方法。</p><p>[^code]: 代码高亮功能支持包括 Java, Python, JavaScript 在内的，<strong>四十一</strong>种主流编程语言。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;欢迎使用-Cmd-Markdown-编辑阅读器&quot;&gt;&lt;a href=&quot;#欢迎使用-Cmd-Markdown-编辑阅读器&quot; class=&quot;headerlink&quot; title=&quot;欢迎使用 Cmd Markdown 编辑阅读器&quot;&gt;&lt;/a&gt;欢迎使用 Cmd Markdown 编辑阅读器&lt;/h1&gt;
    
    </summary>
    
      <category term="Markdown" scheme="http://yoursite.com/categories/Markdown/"/>
    
    
      <category term="Markdown" scheme="http://yoursite.com/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>python</title>
    <link href="http://yoursite.com/2018/08/26/python/"/>
    <id>http://yoursite.com/2018/08/26/python/</id>
    <published>2018-08-26T09:34:06.000Z</published>
    <updated>2018-10-01T14:00:03.639Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python的学习过程："><a href="#python的学习过程：" class="headerlink" title="python的学习过程："></a>python的学习过程：</h1><a id="more"></a><ul><li>第一个是看着廖雪峰的网站，里面的内容基础，是关于数据结构等的十分基本的内容，适合小白入门</li><li>第二个是流畅的python<ul><li>这本书比python-codebook还深入，更适合当你实现了一个功能之后，还是想知道其具体怎么实现的时候查询。</li><li>第三个是python-codebook. </li><li>它的组织形式是任务式、问题式的，而且问题也相对而言比较高级，不是算法导论那种以解决某个实际问题，而是在编程上我想实现什么更好的功能那种问题，通过每一个问题，或者说通过每一个你想怎么更优的实现一个方法的思路，来引导如何更好地写代码，实现高级功能。这本书的前提是你已经入门，并且写了一段时间的python代码，在实际写的过程中已经遇到了类似的问题，也勉强实现了，只是苦于没有更好更顺心的方法实现。我现在是个小白，看这本书用了将近两周吧，主要看了第一二三四七八章，里面的代码翔实。其他的也是略微看了看，因为没有实际操作背景，有的时候不懂为什么那样做会更好，可以在以后的编程过程中，遇到这样的情况：这个我能勉强实现，但是感觉不太好，我想实现的更优美。那就应该来看看这本书，说不定这本书的实现能给自己一些思路。不适合为了读而读，因为不是入门。</li><li>接下来可以考虑看看那种直接算法任务型的。刚刚看了看python算法教程，估计要跳着看了，因为里面的关于算法的内容已经熟悉了，可以扫描着看</li></ul></li></ul><h1 id="python的点"><a href="#python的点" class="headerlink" title="python的点"></a>python的点</h1><h2 id="二重列表生成式"><a href="#二重列表生成式" class="headerlink" title="二重列表生成式"></a>二重列表生成式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种</span></span><br><span class="line">[[i+j <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>)] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]]</span><br><span class="line"><span class="comment"># 第二种</span></span><br><span class="line">[i+j <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>) <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按列访问类似列表的结构</span></span><br><span class="line">[a[i][j] <span class="keyword">for</span> j <span class="keyword">in</span> range(len(a[<span class="number">0</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a.size))]</span><br></pre></td></tr></table></figure><p>所以对于二重列表生成式，一般可以认为是对于同层的列表，是从前到后，对于不同层的列表，是从外到内</p><h2 id="li-list-str-和str-‘’-join-li-互为相反"><a href="#li-list-str-和str-‘’-join-li-互为相反" class="headerlink" title="li_ = list(str_)和str_ = ‘’.join(li_)互为相反"></a>li_ = list(str_)和str_ = ‘’.join(li_)互为相反</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一重列表</span></span><br><span class="line">In [<span class="number">1</span>]: str = <span class="string">'我你'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: li = [<span class="string">'我'</span>,<span class="string">'你'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: list(str)</span><br><span class="line">Out[<span class="number">3</span>]: [<span class="string">'我'</span>, <span class="string">'你'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: <span class="string">''</span>.join(li)</span><br><span class="line">Out[<span class="number">4</span>]: <span class="string">'我你'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二重列表</span></span><br><span class="line">In [<span class="number">5</span>]: lli_=[[<span class="string">'我'</span>,<span class="string">'你'</span>],[<span class="string">'北'</span>,<span class="string">'京'</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: str_ = [<span class="string">''</span>.join(li) <span class="keyword">for</span> li <span class="keyword">in</span> lli_]</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: str_ </span><br><span class="line">Out[<span class="number">7</span>]: [<span class="string">'我你'</span>, <span class="string">'北京'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: st_ =<span class="string">'/n'</span>.join([<span class="string">''</span>.join(li) <span class="keyword">for</span> li <span class="keyword">in</span> lli_])</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: st_</span><br><span class="line">Out[<span class="number">9</span>]: <span class="string">'我你/n北京'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#同理，可以推广到多重列表</span></span><br></pre></td></tr></table></figure><h2 id="list删除元素"><a href="#list删除元素" class="headerlink" title="list删除元素"></a>list删除元素</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用pop，根据位置删除</span></span><br><span class="line"><span class="comment"># 存在返回值，与append相对应</span></span><br><span class="line">li_.pop()</span><br><span class="line">a = li_.pop(i)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用remove，根据值删除</span></span><br><span class="line"><span class="comment"># 删除第一个匹配的值</span></span><br><span class="line">aList = [<span class="number">123</span>, <span class="string">'xyz'</span>, <span class="string">'zara'</span>, <span class="string">'abc'</span>, <span class="string">'xyz'</span>];</span><br><span class="line">aList.remove(<span class="string">'xyz'</span>);</span><br><span class="line">aList.remove(aList[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用del,根据位置删除，没有返回值</span></span><br><span class="line"><span class="keyword">del</span>(n[<span class="number">4</span>])</span><br><span class="line"><span class="keyword">del</span> n[<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># str.replace()</span></span><br><span class="line">```python</span><br><span class="line"><span class="string">u'afafafa'</span>.replace(<span class="string">'a'</span>,<span class="string">u'eee'</span>).replace(<span class="string">'f'</span>,<span class="string">u'rr'</span>)</span><br><span class="line"><span class="string">'eeerreeerreeerreee'</span></span><br></pre></td></tr></table></figure><h2 id="python函数的互换"><a href="#python函数的互换" class="headerlink" title="python函数的互换"></a>python函数的互换</h2><p>对于类似的函数，并且有相同输入和输出，只是对于实现的功能有一些不一样<br>暂时无法评价这两种写法的优劣<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种写法</span></span><br><span class="line"><span class="keyword">if</span> opt.acrostic:</span><br><span class="line">    result = gen_acrostic(model, start_words, ix2word, word2ix, prefix_words)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    result = generate(model, start_words, ix2word, word2ix, prefix_words)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种写法</span></span><br><span class="line">gen_poetry = gen_acrostic <span class="keyword">if</span> opt.acrostic <span class="keyword">else</span> generate</span><br><span class="line">result = gen_poetry(model, start_words, ix2word, word2ix, prefix_words)</span><br></pre></td></tr></table></figure></p><h2 id="argparse"><a href="#argparse" class="headerlink" title="argparse"></a>argparse</h2><p>参考链接：<a href="http://lib.csdn.net/article/python/49052" target="_blank" rel="noopener">http://lib.csdn.net/article/python/49052</a><br><a href="https://blog.csdn.net/u010895119/article/details/78960740" target="_blank" rel="noopener">https://blog.csdn.net/u010895119/article/details/78960740</a><br><a href="https://www.jianshu.com/p/a50aead61319" target="_blank" rel="noopener">https://www.jianshu.com/p/a50aead61319</a><br>不是很适合交互式调试 命令行参数<br>分为位置参数和选项参数</p><h3 id="位置参数"><a href="#位置参数" class="headerlink" title="位置参数"></a>位置参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">"say something about this application !!"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'name'</span>, type=int,  help=<span class="string">"i can tell you how to set a name argument"</span>)</span><br><span class="line"></span><br><span class="line">result = parser.parse_args()</span><br><span class="line"></span><br><span class="line">print(result.name)</span><br><span class="line"></span><br><span class="line">$python main.py taylor</span><br><span class="line">taylor</span><br></pre></td></tr></table></figure><h3 id="选项参数"><a href="#选项参数" class="headerlink" title="选项参数"></a>选项参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">"say something about this application !!"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-a"</span>,<span class="string">"--age"</span>, help=<span class="string">"this is an optional argument"</span>)</span><br><span class="line">result = parser.parse_args()</span><br><span class="line">print(result.age)</span><br><span class="line"></span><br><span class="line">$python main.py  --age <span class="number">888</span></span><br><span class="line"><span class="number">888</span></span><br><span class="line">$python main.py  --age=<span class="number">888</span></span><br><span class="line"><span class="number">888</span></span><br></pre></td></tr></table></figure><h3 id="特殊的选项参数"><a href="#特殊的选项参数" class="headerlink" title="特殊的选项参数"></a>特殊的选项参数</h3><p>起着开关的作用<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">parser = argparse.ArgumentParser(<span class="attribute">description</span>=<span class="string">"say something about this application !!"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-a"</span>, <span class="string">"--age"</span>, <span class="attribute">help</span>=<span class="string">"this is an optional argument"</span>, <span class="attribute">action</span>=<span class="string">"store_true"</span>)</span><br><span class="line">result = parser.parse_args()</span><br><span class="line"><span class="builtin-name">print</span>(result.age)</span><br><span class="line"></span><br><span class="line"><span class="variable">$python</span> main.py  -a</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure></p><p>指定选项<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">"say something about this application !!"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-a"</span>, <span class="string">"--age"</span>, help=<span class="string">"this is an optional argument"</span>, type=int, choices=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">result = parser.parse_args()</span><br><span class="line">print(result.age)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure></p><p>nargs<br>nargs=N(N是int类型)，nargs=’*’, nargs=’?’某个参数接受的值，nargs定义了值的个数，加了nargs后，接受的值会变成一个list，’?’代表一个值，’*’代表一个或多个值，举例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">'capital'</span>, default=<span class="string">'hello'</span>, nargs=<span class="number">1</span>, help=<span class="string">'将首字母大写'</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args)</span><br><span class="line">print(args.capital)</span><br></pre></td></tr></table></figure></p><p>计数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">"-v"</span>, <span class="string">"--verbosity"</span>,</span><br><span class="line">       action=<span class="string">"count"</span>, default=<span class="number">0</span>, help=<span class="string">"increase output verbosity"</span>)</span><br></pre></td></tr></table></figure></p><h1 id="奇怪"><a href="#奇怪" class="headerlink" title="奇怪"></a>奇怪</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ipdb&gt; y = <span class="number">10</span></span><br><span class="line">ipdb&gt; [[ <span class="number">1</span> <span class="keyword">for</span> w <span class="keyword">in</span> range(<span class="number">2</span>)] <span class="keyword">for</span> j <span class="keyword">in</span> range(y)]</span><br><span class="line">[[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">ipdb&gt; [[ <span class="number">1</span> <span class="keyword">for</span> w <span class="keyword">in</span> range(y)] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">*** NameError: name <span class="string">'y'</span> <span class="keyword">is</span> <span class="keyword">not</span> defined</span><br></pre></td></tr></table></figure><hr><h2 id="assert"><a href="#assert" class="headerlink" title="assert"></a>assert</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种</span></span><br><span class="line"><span class="keyword">assert</span> <span class="number">3</span> &gt;=<span class="number">5</span>,<span class="string">'2不等于1'</span></span><br><span class="line"></span><br><span class="line">----&gt; 1 assert 3 &gt;=5</span><br><span class="line"></span><br><span class="line">AssertionError:</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种</span></span><br><span class="line"><span class="keyword">assert</span> <span class="number">3</span> &gt;=<span class="number">5</span>,<span class="string">'3不小于等于5'</span></span><br><span class="line">----&gt; 1 assert 3 &gt;=5,'3不小于等于5'</span><br><span class="line"></span><br><span class="line">AssertionError: <span class="number">3</span>不小于等于<span class="number">5</span></span><br></pre></td></tr></table></figure><hr><h2 id="sort和sorted"><a href="#sort和sorted" class="headerlink" title="sort和sorted"></a>sort和sorted</h2><p>sort是对list的操作<br>sorted是对所有可迭代的序列的操作</p><hr><h2 id="requirements-txt"><a href="#requirements-txt" class="headerlink" title="requirements.txt"></a>requirements.txt</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip freeze &gt; requirements.txt <span class="comment"># 生成requirements.txt</span></span><br><span class="line">pip install -r requirements.txt <span class="comment"># 从requirements.txt安装依赖</span></span><br><span class="line"></span><br><span class="line">pip install pipreqs</span><br><span class="line">pipreqs /home/project/location</span><br></pre></td></tr></table></figure><hr><h2 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h2><p>第一步：<br>函数也是一个对象，也可以赋值给变量，也可以通过变量来调用函数。<br><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">In</span> [<span class="number">1</span>]: def now():</span><br><span class="line">   ...:     print(<span class="string">'now 2020202'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">2</span>]: f = now</span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">3</span>]: f()</span><br><span class="line">now <span class="number">2020202</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">4</span>]: now.__name__</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">4</span>]: <span class="string">'now'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">5</span>]: f.__name__</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">5</span>]: <span class="string">'now'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">In</span> [<span class="number">6</span>]: <span class="keyword">type</span>(f)</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">6</span>]: <span class="function"><span class="keyword">function</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">In</span> [7]:</span> <span class="keyword">type</span>(now)</span><br><span class="line"><span class="keyword">Out</span>[<span class="number">7</span>]: <span class="function"><span class="keyword">function</span></span></span><br></pre></td></tr></table></figure></p><p>第二步：<br>简单的装饰器，在函数调用前后，进行一些没有参数的操作，在代码运行期间增加功能<br>两层的装饰器,@log<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">15</span>]: <span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(func)</span>:</span></span><br><span class="line">    ...:     print(<span class="string">'wrapper early'</span>)</span><br><span class="line">    ...:     print(func.__name__)</span><br><span class="line">    ...:     <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">    ...:         print(<span class="string">'fun early&#123;0&#125;'</span>.format(func.__name__))</span><br><span class="line">    ...:         func(*args,**kwargs)</span><br><span class="line">    ...:         print(<span class="string">'fun later'</span>)</span><br><span class="line">    ...:     print(<span class="string">'wrapper later'</span>)</span><br><span class="line">    ...:     <span class="keyword">return</span> wrapper</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">16</span>]: @log</span><br><span class="line">    ...: <span class="function"><span class="keyword">def</span> <span class="title">now</span><span class="params">()</span>:</span></span><br><span class="line">    ...:     print(<span class="string">'now test3'</span>)</span><br><span class="line">    ...:</span><br><span class="line">wrapper early</span><br><span class="line">now</span><br><span class="line">wrapper later</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: now()</span><br><span class="line">fun earlynow</span><br><span class="line">now test3</span><br><span class="line">fun later</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: now.__name__</span><br><span class="line">Out[<span class="number">18</span>]: <span class="string">'wrapper'</span></span><br></pre></td></tr></table></figure></p><p>第三步：<br>复杂的装饰器，在函数调用前后，进行有参数的操作，<br>三层的装饰器，@log()<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">19</span>]: <span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(text)</span>:</span></span><br><span class="line">    ...:     print(<span class="string">'log----decorator'</span>)</span><br><span class="line">    ...:     <span class="function"><span class="keyword">def</span> <span class="title">decorator</span><span class="params">(func)</span>:</span></span><br><span class="line">    ...:         print(<span class="string">'decorator----wrapper'</span>)</span><br><span class="line">    ...:         <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args,**kwargs)</span>:</span></span><br><span class="line">    ...:             print(<span class="string">'wrapper 1'</span>)</span><br><span class="line">    ...:             print(text,func.__name__)</span><br><span class="line">    ...:             print(<span class="string">' wrapper 2'</span>)</span><br><span class="line">    ...:             <span class="keyword">return</span>  func(*args, **kwargs)</span><br><span class="line">    ...:         print(<span class="string">'wrapper----decorator'</span>)</span><br><span class="line">    ...:         <span class="keyword">return</span> wrapper</span><br><span class="line">    ...:     print(<span class="string">'decorator----log'</span>)</span><br><span class="line">    ...:     <span class="keyword">return</span> decorator</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: @log(<span class="string">'hello'</span>)</span><br><span class="line">    ...: <span class="function"><span class="keyword">def</span> <span class="title">now</span><span class="params">()</span>:</span></span><br><span class="line">    ...:     print(<span class="string">'1000'</span>)</span><br><span class="line">    ...:     <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line">log----decorator</span><br><span class="line">decorator----log</span><br><span class="line">decorator----wrapper</span><br><span class="line">wrapper----decorator</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: now()</span><br><span class="line">wrapper <span class="number">1</span></span><br><span class="line">hello now</span><br><span class="line"> wrapper <span class="number">2</span></span><br><span class="line"><span class="number">1000</span></span><br><span class="line">Out[<span class="number">21</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: f = now</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: f.__name__</span><br><span class="line">Out[<span class="number">23</span>]: <span class="string">'wrapper'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: now.__name__</span><br><span class="line">Out[<span class="number">24</span>]: <span class="string">'wrapper'</span></span><br></pre></td></tr></table></figure></p><p>第四步：<br>完整的装饰器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(func)</span>:</span></span><br><span class="line"><span class="meta">    @functools.wraps(func)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args, **kw)</span>:</span></span><br><span class="line">        print(<span class="string">'call %s():'</span> % func.__name__)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kw)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decorator</span><span class="params">(func)</span>:</span></span><br><span class="line"><span class="meta">        @functools.wraps(func)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args, **kw)</span>:</span></span><br><span class="line">            print(<span class="string">'%s %s():'</span> % (text, func.__name__))</span><br><span class="line">            <span class="keyword">return</span> func(*args, **kw)</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br><span class="line"></span><br><span class="line">等价于wrapper.__name__ = func.__name__</span><br></pre></td></tr></table></figure></p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>分为位置参数（可以设置为默认参数），可变参数，关键字参数<br>位置参数很简单，跳过<br>可变参数或者关键字参数可以没有值赋予</p><h3 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h3><p> 第一步：对于不确定个数的参数，使用list或者tuple作为参数传入<br>缺点：在调用的时候必须先组装成list或者tuple<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">7</span>]: <span class="function"><span class="keyword">def</span> <span class="title">calc</span><span class="params">(number)</span>:</span></span><br><span class="line">   ...:     sum = <span class="number">0</span></span><br><span class="line">   ...:     print(type(number))</span><br><span class="line">   ...:     <span class="keyword">for</span> i <span class="keyword">in</span> number:</span><br><span class="line">   ...:         sum+=i</span><br><span class="line">   ...:     <span class="keyword">return</span> sum</span><br><span class="line">   ...:</span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: calc([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">list</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[8]:</span> <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: calc((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">   ...: )</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[9]:</span> <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: calc((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[10]:</span> <span class="number">6</span></span><br></pre></td></tr></table></figure></p><p>第二步：利用可变参数*number，在第一步的基础上修正缺点，使其调用不再需要先组装<br>缺点：输入参数是list和tuple时就会很麻烦，需要先拆解<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">11</span>]: <span class="function"><span class="keyword">def</span> <span class="title">calc</span><span class="params">(*number)</span>:</span></span><br><span class="line">    ...:     sum = <span class="number">0</span></span><br><span class="line">    ...:     print(type(number))</span><br><span class="line">    ...:     <span class="keyword">for</span> i <span class="keyword">in</span> number:</span><br><span class="line">    ...:         sum+=i</span><br><span class="line">    ...:     <span class="keyword">return</span> sum</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: calc(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[12]:</span> <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: calc()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[13]:</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: num = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">15</span>]: calc(num)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class">---------------------------------------------------------------------------</span></span><br><span class="line"><span class="class"><span class="title">TypeError</span>                                 <span class="title">Traceback</span> <span class="params">(most recent call last)</span></span></span><br><span class="line"><span class="class">&lt;<span class="title">ipython</span>-<span class="title">input</span>-15-<span class="title">bb5c0a89404a</span>&gt; <span class="title">in</span> &lt;<span class="title">module</span>&gt;<span class="params">()</span></span></span><br><span class="line"><span class="class">----&gt; 1 calc(num)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&lt;ipython-input-11-34cdd7bd7eaa&gt; in calc(*number)</span></span><br><span class="line"><span class="class">      3     print(type(number))</span></span><br><span class="line"><span class="class">      4     for i in number:</span></span><br><span class="line">----&gt; 5         sum+=i</span><br><span class="line">      <span class="number">6</span>     <span class="keyword">return</span> sum</span><br><span class="line"></span><br><span class="line">TypeError: unsupported operand type(s) <span class="keyword">for</span> +=: <span class="string">'int'</span> <span class="keyword">and</span> <span class="string">'list'</span></span><br></pre></td></tr></table></figure></p><blockquote><p>注意，可变参数在函数内部是作为一个tuple存在的，如果对于tuple进行修改，先变成list</p></blockquote><p>第三步：对第一步的优点和第二步的优点进行整合，使调用时既能直接接收list或者tuple作为输入参数，也能不需要组装成list或者tuple进行输入。<br>也就是在函数定义时注明<em>number,输入直接输入或者</em>list.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">11</span>]: <span class="function"><span class="keyword">def</span> <span class="title">calc</span><span class="params">(*number)</span>:</span></span><br><span class="line">    ...:     sum = <span class="number">0</span></span><br><span class="line">    ...:     print(type(number))</span><br><span class="line">    ...:     <span class="keyword">for</span> i <span class="keyword">in</span> number:</span><br><span class="line">    ...:         sum+=i</span><br><span class="line">    ...:     <span class="keyword">return</span> sum</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"><span class="comment"># 合理调用的几种方式</span></span><br><span class="line">In [<span class="number">14</span>]: num = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">In [<span class="number">16</span>]: calc(*num)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[16]:</span> <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: calc(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[20]:</span> <span class="number">6</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: calc(*(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Out</span>[22]:</span> <span class="number">6</span></span><br></pre></td></tr></table></figure></p><h3 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h3><p>类比可变参数，就很容易地理解dict型参数的输入<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">18</span>]: <span class="function"><span class="keyword">def</span> <span class="title">person</span><span class="params">(name, **kwargs)</span>:</span></span><br><span class="line">    ...:     print(type(kwargs))</span><br><span class="line">    ...:     print(kwargs)</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: person(<span class="string">'fa'</span>,city=<span class="string">'beijing'</span>,age=<span class="string">'44'</span>)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">dict</span>'&gt;</span></span><br><span class="line">&#123;'city': 'beijing', 'age': '44'&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: extra = &#123;<span class="string">'city'</span>: <span class="string">'Beijing'</span>, <span class="string">'job'</span>: <span class="string">'Engineer'</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: person(<span class="string">'hh'</span>,**extra)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">dict</span>'&gt;</span></span><br><span class="line">&#123;'city': 'Beijing', 'job': 'Engineer'&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>对于可变参数或者关键字参树，或者按照正常地类似位置参数或者默认参数的形式传入，或者按照*list或者**dict进行传入。</p></blockquote><h3 id="命名关键字参数"><a href="#命名关键字参数" class="headerlink" title="命名关键字参数"></a>命名关键字参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一种，直接*</span></span><br><span class="line">In [<span class="number">26</span>]: <span class="function"><span class="keyword">def</span> <span class="title">person</span><span class="params">(name, * ,city, job)</span>:</span></span><br><span class="line">    ...:     print(name, city, job)</span><br><span class="line">    ...:</span><br><span class="line"><span class="comment"># 其调用时必须显示输入参数名，city和job，当然，命名关键字参数也可以设置默认值</span></span><br><span class="line">In [<span class="number">27</span>]: person(<span class="string">'11'</span>,city=<span class="string">'beijing'</span>, job=<span class="string">'enginner'</span>)</span><br><span class="line"><span class="number">11</span> beijing enginner</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种  有可变参数的存在</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">person</span><span class="params">(name, age, *args, city, job)</span>:</span></span><br><span class="line">    print(name, age, args, city, job)</span><br></pre></td></tr></table></figure><h3 id="参数组合"><a href="#参数组合" class="headerlink" title="参数组合"></a>参数组合</h3><p>参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f1</span><span class="params">(a, b, c=<span class="number">0</span>, *args, **kw)</span>:</span></span><br><span class="line">    print(<span class="string">'a ='</span>, a, <span class="string">'b ='</span>, b, <span class="string">'c ='</span>, c, <span class="string">'args ='</span>, args, <span class="string">'kw ='</span>, kw)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f2</span><span class="params">(a, b, c=<span class="number">0</span>, *, d, **kw)</span>:</span></span><br><span class="line">    print(<span class="string">'a ='</span>, a, <span class="string">'b ='</span>, b, <span class="string">'c ='</span>, c, <span class="string">'d ='</span>, d, <span class="string">'kw ='</span>, kw)</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(a,b,c=<span class="number">0</span>,*args,d,**kw)</span>:</span></span><br><span class="line">    ...:     print(<span class="string">'a'</span>,a,<span class="string">'b'</span>,b,<span class="string">'c'</span>,c,<span class="string">'args'</span>,args,<span class="string">'d'</span>,d,<span class="string">'kw'</span>,kw)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: f(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,d=<span class="number">5</span>,e=<span class="number">6</span>)</span><br><span class="line">a <span class="number">1</span> b <span class="number">2</span> c <span class="number">3</span> args (<span class="number">4</span>,) d <span class="number">5</span> kw &#123;<span class="string">'e'</span>: <span class="number">6</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 看一个神奇的东西，输入参数用tuple和dict直接代替</span></span><br><span class="line">In [<span class="number">30</span>]: args = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: dic = &#123;<span class="string">'d'</span>:<span class="number">5</span>, <span class="string">'e'</span>:<span class="number">6</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: f(*args,**dic)</span><br><span class="line">a <span class="number">1</span> b <span class="number">2</span> c <span class="number">3</span> args (<span class="number">4</span>,) d <span class="number">5</span> kw &#123;<span class="string">'e'</span>: <span class="number">6</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由此引出一个重要结论</span></span><br><span class="line"><span class="comment"># 所以，对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。</span></span><br><span class="line"><span class="comment"># 这个结论解释了后期定义装饰器的时候，参数的定义直接是(*args, **kw)的形式，而不用去管函数本身的参数的定义是什么样的，而在调用的时候，按照原函数的参数定义调用即可。</span></span><br></pre></td></tr></table></figure></p><hr><h2 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">29</span>]: <span class="function"><span class="keyword">def</span> <span class="title">lazy_sum</span><span class="params">(*args)</span>:</span></span><br><span class="line">    ...:     <span class="function"><span class="keyword">def</span> <span class="title">sum</span><span class="params">()</span>:</span></span><br><span class="line">    ...:         ax = <span class="number">0</span></span><br><span class="line">    ...:         <span class="keyword">for</span> i <span class="keyword">in</span> args:</span><br><span class="line">    ...:             ax = ax+i</span><br><span class="line">    ...:         <span class="keyword">return</span> ax</span><br><span class="line">    ...:     <span class="keyword">return</span> sum</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: f =  lazy_sum(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: f.__name__</span><br><span class="line">Out[<span class="number">31</span>]: <span class="string">'sum'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: f.__file__</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AttributeError                            Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input<span class="number">-32</span><span class="number">-9</span>c8edc3d9e41&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; 1 f.__file__</span><br><span class="line"></span><br><span class="line">AttributeError: <span class="string">'function'</span> object has no attribute <span class="string">'__file__'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: f</span><br><span class="line">Out[<span class="number">33</span>]: &lt;function __main__.lazy_sum.&lt;locals&gt;.sum()&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: f()</span><br><span class="line">Out[<span class="number">34</span>]: <span class="number">10</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: f1 = lazy_sum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: f2 = lazy_sum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: f1==f2</span><br><span class="line">Out[<span class="number">37</span>]: <span class="keyword">False</span></span><br></pre></td></tr></table></figure><p>闭包存在的问题<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回多个函数</span></span><br><span class="line">In [<span class="number">38</span>]: <span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">()</span>:</span></span><br><span class="line">    ...:     fs=[]</span><br><span class="line">    ...:     <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    ...:         <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">()</span>:</span></span><br><span class="line">    ...:             <span class="keyword">return</span> i*i</span><br><span class="line">    ...:         fs.append(f)</span><br><span class="line">    ...:     <span class="keyword">return</span> fs</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: f1,f2,f3,f4 = count()</span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: f1()</span><br><span class="line">Out[<span class="number">40</span>]: <span class="number">9</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: f2()</span><br><span class="line">Out[<span class="number">42</span>]: <span class="number">9</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: f3()</span><br><span class="line">Out[<span class="number">43</span>]: <span class="number">9</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: f4()</span><br><span class="line">Out[<span class="number">44</span>]: <span class="number">9</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: <span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">()</span>:</span></span><br><span class="line">    ...:     <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">()</span>:</span></span><br><span class="line">    ...:         <span class="keyword">return</span> i*i</span><br><span class="line">    ...:     fs=[]</span><br><span class="line">    ...:     <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    ...:         fs.append(f)</span><br><span class="line">    ...:         print(i)</span><br><span class="line">    ...:     <span class="keyword">return</span> fs</span><br><span class="line"></span><br><span class="line">In [<span class="number">64</span>]: f1, f2, f3, f4 = count()</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: f1()</span><br><span class="line">Out[<span class="number">65</span>]: <span class="number">9</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">66</span>]: f2()</span><br><span class="line">Out[<span class="number">66</span>]: <span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回单个函数</span></span><br><span class="line">In [<span class="number">48</span>]: <span class="function"><span class="keyword">def</span> <span class="title">lazy_sum</span><span class="params">(*args)</span>:</span></span><br><span class="line">    ...:     j=<span class="number">0</span></span><br><span class="line">    ...:     <span class="function"><span class="keyword">def</span> <span class="title">sum</span><span class="params">()</span>:</span></span><br><span class="line">    ...:         ax = <span class="number">0</span></span><br><span class="line">    ...:         <span class="keyword">for</span> i <span class="keyword">in</span> args:</span><br><span class="line">    ...:             ax = ax+i+j</span><br><span class="line">    ...:         <span class="keyword">return</span> ax</span><br><span class="line">    ...:     j=<span class="number">100</span></span><br><span class="line">    ...:     <span class="keyword">return</span> sum</span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: f1 = lazy_sum(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: f1()</span><br><span class="line">Out[<span class="number">50</span>]: <span class="number">306</span></span><br></pre></td></tr></table></figure></p><blockquote><p>返回函数不要引用任何循环变量，或者后续会发生变化的变量。应该满足内层函数定义后其所引用的外部变量不发生变化。</p></blockquote><p>针对外部变量发生变化的解决方案<br>就是再用一个函数，令变化的外部变量从隐式参数变成显式参数<br>或者说，对于变化的外部变量，令其执行，不再以变量的形式存在，而是以其值的形式存在。<br>第一种方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(j)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">()</span>:</span></span><br><span class="line">            <span class="keyword">return</span> j*j</span><br><span class="line">        <span class="keyword">return</span> g</span><br><span class="line">    fs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">        fs.append(f(i)) <span class="comment"># f(i)立刻被执行，因此i的当前值被传入f()</span></span><br><span class="line">    <span class="keyword">return</span> fs</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: f1, f2, f3 = count()</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: f1()</span><br><span class="line">Out[<span class="number">53</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: f1</span><br><span class="line">Out[<span class="number">60</span>]: &lt;function __main__.count.&lt;locals&gt;.f.&lt;locals&gt;.g()&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: f2</span><br><span class="line">Out[<span class="number">61</span>]: &lt;function __main__.count.&lt;locals&gt;.f.&lt;locals&gt;.g()&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: f1.__name__</span><br><span class="line">Out[<span class="number">62</span>]: <span class="string">'g'</span></span><br></pre></td></tr></table></figure></p><p>第二种方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">113</span>]: <span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">()</span>:</span></span><br><span class="line">     ...:     fs=[]</span><br><span class="line">     ...:     <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">     ...:         <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(m=i)</span>:</span></span><br><span class="line">     ...:             <span class="keyword">return</span> m*m</span><br><span class="line">     ...:         fs.append(f)</span><br><span class="line">     ...:     <span class="keyword">return</span> fs</span><br><span class="line">     ...:</span><br><span class="line">     ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: count()</span><br><span class="line">Out[<span class="number">114</span>]:</span><br><span class="line">[&lt;function __main__.count.&lt;locals&gt;.f(m=<span class="number">0</span>)&gt;,</span><br><span class="line"> &lt;function __main__.count.&lt;locals&gt;.f(m=<span class="number">1</span>)&gt;]</span><br></pre></td></tr></table></figure></p><p>廖雪峰说可以用lambda函数进行代码缩写，但是没有想通怎么用。</p><h3 id="内部函数内修改外部函数局部变量"><a href="#内部函数内修改外部函数局部变量" class="headerlink" title="内部函数内修改外部函数局部变量"></a>内部函数内修改外部函数局部变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">counterA = createCounter()</span><br><span class="line">print(counterA(), counterA(), counterA(), counterA(), counterA()) <span class="comment"># 1 2 3 4 5</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">一、在内部函数内修改外部函数局部变量的两种方法</span><br><span class="line"><span class="number">1</span>法：把外部变量变成容器或者说可变变量</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createCounter</span><span class="params">()</span>:</span></span><br><span class="line">    a = [<span class="number">0</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">counter</span><span class="params">()</span>:</span></span><br><span class="line">        a[<span class="number">0</span>] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> a[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> counter</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>法：在内部函数里给予外部函数局部变量<span class="keyword">nonlocal</span>声明，让内部函数去其他领域获取这个变量</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createCounter</span><span class="params">()</span>:</span></span><br><span class="line">    a = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">counter</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">nonlocal</span> a</span><br><span class="line">        a += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    <span class="keyword">return</span> counter</span><br><span class="line">二、在内部函数内修改全局变量</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createCounter</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> a</span><br><span class="line">    a = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">counter</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">global</span> a</span><br><span class="line">        a += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    <span class="keyword">return</span> counter</span><br></pre></td></tr></table></figure><hr><h2 id="快速解压或者list-tuple转置"><a href="#快速解压或者list-tuple转置" class="headerlink" title="快速解压或者list+tuple转置"></a>快速解压或者list+tuple转置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">li_ = [(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)]</span><br><span class="line">ll = list(zip(*li_))</span><br><span class="line">[(<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 甚至可以达到按列取值的效果</span></span><br><span class="line">l1, l2, l3 = list(zip(*li_))</span><br><span class="line">l1</span><br><span class="line">(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">l2</span><br><span class="line">(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">l3</span><br><span class="line">(<span class="number">3</span>, <span class="number">6</span>)</span><br></pre></td></tr></table></figure><hr><h2 id="求一个序列中，与固定值之间的最大值，这个最大值不能超过序列的最大值和固定值"><a href="#求一个序列中，与固定值之间的最大值，这个最大值不能超过序列的最大值和固定值" class="headerlink" title="求一个序列中，与固定值之间的最大值，这个最大值不能超过序列的最大值和固定值"></a>求一个序列中，与固定值之间的最大值，这个最大值不能超过序列的最大值和固定值</h2><p>或者说求两个序列的最小最大值<br>或者说在这个序列中，如果没有比固定值大的数，则取这个序列的最大值作为最大值，如果有，则取固定值作为最大值<br>或者说对这个序列进行截断<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ll = [min(c, max_len) <span class="keyword">for</span> c <span class="keyword">in</span> l]</span><br><span class="line">max_query = max(ll)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">max_l = max(l)</span><br><span class="line">max_query = min(max_l, max_len)</span><br></pre></td></tr></table></figure></p><hr><h2 id="dict"><a href="#dict" class="headerlink" title="dict"></a>dict</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">d = dict(aa = a, bb = b)</span><br><span class="line">&#123;<span class="string">'aa'</span>: <span class="number">1</span>, <span class="string">'bb'</span>: <span class="number">2</span>&#125;</span><br><span class="line">dd = &#123;<span class="string">'aa'</span>:a, <span class="string">'bb'</span>:<span class="number">2</span>&#125;</span><br><span class="line">dd</span><br><span class="line">&#123;<span class="string">'aa'</span>: <span class="number">1</span>, <span class="string">'bb'</span>: <span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="注释文档"><a href="#注释文档" class="headerlink" title="注释文档"></a>注释文档</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">文档快速生成注释的方法介绍,首先我们要用到__all__属性</span></span><br><span class="line"><span class="string">在Py中使用为导出__all__中的所有类、函数、变量成员等</span></span><br><span class="line"><span class="string">在模块使用__all__属性可避免相互引用时命名冲突</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">__all__ = [<span class="string">'Login'</span>, <span class="string">'check'</span>, <span class="string">'Shop'</span>, <span class="string">'upDateIt'</span>, <span class="string">'findIt'</span>, <span class="string">'deleteIt'</span>]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Login</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    测试注释一可以写上此类的作用说明等</span></span><br><span class="line"><span class="string">    例如此方法用来写登录</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        初始化你要的参数说明</span></span><br><span class="line"><span class="string">        那么登录可能要用到</span></span><br><span class="line"><span class="string">        用户名username</span></span><br><span class="line"><span class="string">        密码password</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        协商你要实现的功能说明</span></span><br><span class="line"><span class="string">        功能也有很多例如验证</span></span><br><span class="line"><span class="string">        判断语句，验证码之类的</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Shop</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    商品类所包含的属性及方法</span></span><br><span class="line"><span class="string">    update改/更新</span></span><br><span class="line"><span class="string">    find查找</span></span><br><span class="line"><span class="string">    delete删除</span></span><br><span class="line"><span class="string">    create添加</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        初始化商品的价格、日期、分类等</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">upDateIt</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        用来更新商品信息</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findIt</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        查找商品信息</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteIt</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        删除过期下架商品信息</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">createIt</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        创建新商品及上架信息</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">import</span> test</span><br><span class="line">    print(help(test))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">$ python test.py</span><br><span class="line">Help on module test:</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">    test</span><br><span class="line"></span><br><span class="line">DESCRIPTION</span><br><span class="line">    文档快速生成注释的方法介绍,首先我们要用到__all__属性</span><br><span class="line">    在Py中使用为导出__all__中的所有类、函数、变量成员等</span><br><span class="line">    在模块使用__all__属性可避免相互引用时命名冲突</span><br><span class="line"></span><br><span class="line">CLASSES</span><br><span class="line">    builtins.object</span><br><span class="line">        Login</span><br><span class="line">        Shop</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Login</span><span class="params">(builtins.object)</span></span></span><br><span class="line"><span class="class">     |  测试注释一可以写上此类的作用说明等</span></span><br><span class="line"><span class="class">     |  例如此方法用来写登录</span></span><br><span class="line"><span class="class">     |</span></span><br><span class="line"><span class="class">     |  <span class="title">Methods</span> <span class="title">defined</span> <span class="title">here</span>:</span></span><br><span class="line">     |</span><br><span class="line">     |  __init__(self)</span><br><span class="line">     |      初始化你要的参数说明</span><br><span class="line">     |      那么登录可能要用到</span><br><span class="line">     |      用户名username</span><br><span class="line">     |      密码password</span><br><span class="line">     |</span><br><span class="line">     |  check(self)</span><br><span class="line">     |      协商你要实现的功能说明</span><br><span class="line">     |      功能也有很多例如验证</span><br><span class="line">     |      判断语句，验证码之类的</span><br><span class="line">     |</span><br><span class="line">     |  ----------------------------------------------------------------------</span><br><span class="line">     |  Data descriptors defined here:</span><br><span class="line">     |</span><br><span class="line">     |  __dict__</span><br><span class="line">     |      dictionary <span class="keyword">for</span> instance variables (<span class="keyword">if</span> defined)</span><br><span class="line">     |</span><br><span class="line">     |  __weakref__</span><br><span class="line">     |      list of weak references to the object (<span class="keyword">if</span> defined)</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Shop</span><span class="params">(builtins.object)</span></span></span><br><span class="line"><span class="class">     |  商品类所包含的属性及方法</span></span><br><span class="line"><span class="class">     |  <span class="title">update</span>改/更新</span></span><br><span class="line"><span class="class">     |  <span class="title">find</span>查找</span></span><br><span class="line"><span class="class">     |  <span class="title">delete</span>删除</span></span><br><span class="line"><span class="class">     |  <span class="title">create</span>添加</span></span><br><span class="line"><span class="class">     |</span></span><br><span class="line"><span class="class">     |  <span class="title">Methods</span> <span class="title">defined</span> <span class="title">here</span>:</span></span><br><span class="line">     |</span><br><span class="line">     |  __init__(self)</span><br><span class="line">     |      初始化商品的价格、日期、分类等</span><br><span class="line">     |</span><br><span class="line">     |  createIt(self)</span><br><span class="line">     |      创建新商品及上架信息</span><br><span class="line">     |</span><br><span class="line">     |  deleteIt(self)</span><br><span class="line">     |      删除过期下架商品信息</span><br><span class="line">     |</span><br><span class="line">     |  findIt(self)</span><br><span class="line">     |      查找商品信息</span><br><span class="line">     |</span><br><span class="line">     |  upDateIt(self)</span><br><span class="line">     |      用来更新商品信息</span><br><span class="line">     |</span><br><span class="line">     |  ----------------------------------------------------------------------</span><br><span class="line">     |  Data descriptors defined here:</span><br><span class="line">     |</span><br><span class="line">     |  __dict__</span><br><span class="line">     |      dictionary <span class="keyword">for</span> instance variables (<span class="keyword">if</span> defined)</span><br><span class="line">     |</span><br><span class="line">     |  __weakref__</span><br><span class="line">     |      list of weak references to the object (<span class="keyword">if</span> defined)</span><br><span class="line"></span><br><span class="line">DATA</span><br><span class="line">    __all__ = [<span class="string">'Login'</span>, <span class="string">'check'</span>, <span class="string">'Shop'</span>, <span class="string">'upDateIt'</span>, <span class="string">'findIt'</span>, <span class="string">'deleteIt'</span>]</span><br><span class="line"></span><br><span class="line">FILE</span><br><span class="line">    h:\桌面\test.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">None</span></span><br></pre></td></tr></table></figure><p>用help或者.<strong>doc</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(math.sin.__doc__)</span><br></pre></td></tr></table></figure></p><hr><h2 id="all"><a href="#all" class="headerlink" title="all"></a><strong>all</strong></h2><p>只对from xx import *有作用<br>参考链接<a href="https://stackoverflow.com/questions/44834/can-someone-explain-all-in-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/44834/can-someone-explain-all-in-python</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># foo.py</span></span><br><span class="line">__all__ = [<span class="string">'bar'</span>, <span class="string">'baz'</span>]</span><br><span class="line"> </span><br><span class="line">waz = <span class="number">5</span></span><br><span class="line">bar = <span class="number">10</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">baz</span><span class="params">()</span>:</span> <span class="keyword">return</span> <span class="string">'baz'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># run-foo.py</span></span><br><span class="line"><span class="keyword">from</span> foo <span class="keyword">import</span> *</span><br><span class="line"> </span><br><span class="line">print(bar) <span class="comment"># 正常</span></span><br><span class="line">print(baz) <span class="comment"># 正常</span></span><br><span class="line">print(waz) <span class="comment"># 显示错误</span></span><br></pre></td></tr></table></figure></p><hr><h2 id="from-future-import-absolute-import"><a href="#from-future-import-absolute-import" class="headerlink" title="from future import absolute_import"></a>from <strong>future</strong> import absolute_import</h2><p>从python2.1开始以后, 当一个新的语言特性首次出现在发行版中时候, 如果该新特性与以前旧版本python不兼容, 则该特性将会被默认禁用. 如果想启用这个新特性, 则必须使用 “from <strong>future</strong>import *” 语句进行导入.<br><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"># https:<span class="comment">//blog.csdn.net/caiqiiqi/article/details/51050800</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"># https:<span class="comment">//blog.csdn.net/feixingfei/article/details/7081446</span></span><br></pre></td></tr></table></figure></p><hr><h2 id="保持原有维度的取元素-narrow-或者切片"><a href="#保持原有维度的取元素-narrow-或者切片" class="headerlink" title="保持原有维度的取元素 narrow 或者切片"></a>保持原有维度的取元素 narrow 或者切片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tt = t.Tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]])</span><br><span class="line">ttt = tt.narrow(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">ttt</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>]])</span><br><span class="line"></span><br><span class="line">tt[<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>]])</span><br></pre></td></tr></table></figure><hr><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p><a href="https://www.bbsmax.com/A/gAJGaGeZdZ/" target="_blank" rel="noopener">https://www.bbsmax.com/A/gAJGaGeZdZ/</a></p><hr><h2 id="生成器函数-迭代器-迭代对象"><a href="#生成器函数-迭代器-迭代对象" class="headerlink" title="生成器函数 迭代器 迭代对象"></a>生成器函数 迭代器 迭代对象</h2><p>对于生成器函数，可以理解成列表，yield的值就是列表中的元素，用next()或者for in来调用<br>迭代器 Iterator: 可以用于next的，惰性计算<br>迭代对象 Iteratable: 可以用于for的 list, tuple, 生成器<br>迭代对象可以使用iter变成迭代器<br>迭代对象范围更广</p><hr><h2 id="对于0"><a href="#对于0" class="headerlink" title="对于0"></a>对于0</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> a ==<span class="number">0</span>:</span><br><span class="line">    <span class="keyword">True</span></span><br><span class="line">等价于</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> a:</span><br><span class="line">并且</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> a!=<span class="number">0</span></span><br><span class="line">等价于</span><br><span class="line"><span class="keyword">if</span> a</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;python的学习过程：&quot;&gt;&lt;a href=&quot;#python的学习过程：&quot; class=&quot;headerlink&quot; title=&quot;python的学习过程：&quot;&gt;&lt;/a&gt;python的学习过程：&lt;/h1&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>MdEditor</title>
    <link href="http://yoursite.com/2018/08/22/MdEditor/"/>
    <id>http://yoursite.com/2018/08/22/MdEditor/</id>
    <published>2018-08-22T08:22:31.000Z</published>
    <updated>2018-08-22T08:58:57.983Z</updated>
    
    <content type="html"><![CDATA[<h1 id="欢迎使用-Markdown在线编辑器-MdEditor"><a href="#欢迎使用-Markdown在线编辑器-MdEditor" class="headerlink" title="欢迎使用 Markdown在线编辑器 MdEditor"></a>欢迎使用 Markdown在线编辑器 MdEditor</h1><p><strong>Markdown是一种轻量级的「标记语言」</strong></p><p><img src="http://www.mdeditor.com/images/logos/markdown.png" alt="markdown" title="markdown"><br><a id="more"></a></p><p>Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面，Markdown文件的后缀名便是“.md”</p><h2 id="MdEditor是一个在线编辑Markdown文档的编辑器"><a href="#MdEditor是一个在线编辑Markdown文档的编辑器" class="headerlink" title="MdEditor是一个在线编辑Markdown文档的编辑器"></a>MdEditor是一个在线编辑Markdown文档的编辑器</h2><p><em>MdEditor扩展了Markdown的功能（如表格、脚注、内嵌HTML等等），以使让Markdown转换成更多的格式，和更丰富的展示效果，这些功能原初的Markdown尚不具备。</em></p><blockquote><p>Markdown增强版中比较有名的有Markdown Extra、MultiMarkdown、 Maruku等。这些衍生版本要么基于工具，如<del>Pandoc</del>，Pandao；要么基于网站，如GitHub和Wikipedia，在语法上基本兼容，但在一些语法和渲染效果上有改动。</p></blockquote><p>MdEditor源于Pandao的JavaScript开源项目，开源地址<a href="https://github.com/pandao/editor.md" title="Editor.md" target="_blank" rel="noopener">Editor.md</a>，并在MIT开源协议的许可范围内进行了优化，以适应广大用户群体的需求。向优秀的markdown开源编辑器原作者Pandao致敬。</p><p><img src="https://pandao.github.io/editor.md/images/logos/editormd-logo-180x180.png" alt="Pandao editor.md" title="Pandao editor.md"></p><h2 id="MdEditor的功能列表演示"><a href="#MdEditor的功能列表演示" class="headerlink" title="MdEditor的功能列表演示"></a>MdEditor的功能列表演示</h2><h1 id="标题H1"><a href="#标题H1" class="headerlink" title="标题H1"></a>标题H1</h1><h2 id="标题H2"><a href="#标题H2" class="headerlink" title="标题H2"></a>标题H2</h2><h3 id="标题H3"><a href="#标题H3" class="headerlink" title="标题H3"></a>标题H3</h3><h4 id="标题H4"><a href="#标题H4" class="headerlink" title="标题H4"></a>标题H4</h4><h5 id="标题H5"><a href="#标题H5" class="headerlink" title="标题H5"></a>标题H5</h5><h6 id="标题H5-1"><a href="#标题H5-1" class="headerlink" title="标题H5"></a>标题H5</h6><h3 id="字符效果和横线等"><a href="#字符效果和横线等" class="headerlink" title="字符效果和横线等"></a>字符效果和横线等</h3><hr><p><del>删除线</del> <s>删除线（开启识别HTML标签时）</s></p><p><em>斜体字</em>      <em>斜体字</em></p><p><strong>粗体</strong>  <strong>粗体</strong></p><p><strong><em>粗斜体</em></strong> <strong><em>粗斜体</em></strong></p><p>上标：X<sub>2</sub>，下标：O<sup>2</sup></p><p><strong>缩写(同HTML的abbr标签)</strong></p><blockquote><p>即更长的单词或短语的缩写形式，前提是开启识别HTML标签时，已默认开启</p></blockquote><p>The <abbr title="Hyper Text Markup Language">HTML</abbr> specification is maintained by the <abbr title="World Wide Web Consortium">W3C</abbr>.</p><h3 id="引用-Blockquotes"><a href="#引用-Blockquotes" class="headerlink" title="引用 Blockquotes"></a>引用 Blockquotes</h3><blockquote><p>引用文本 Blockquotes</p></blockquote><p>引用的行内混合 Blockquotes</p><blockquote><p>引用：如果想要插入空白换行<code>即&lt;br /&gt;标签</code>，在插入处先键入两个以上的空格然后回车即可，<a href="http://www.mdeditor.com/" target="_blank" rel="noopener">普通链接</a>。</p></blockquote><h3 id="锚点与链接-Links"><a href="#锚点与链接-Links" class="headerlink" title="锚点与链接 Links"></a>锚点与链接 Links</h3><p><a href="http://www.mdeditor.com/" target="_blank" rel="noopener">普通链接</a><br><a href="http://www.mdeditor.com/" title="普通链接带标题" target="_blank" rel="noopener">普通链接带标题</a><br>直接链接：<a href="http://www.mdeditor.com" target="_blank" rel="noopener">http://www.mdeditor.com</a><br>[锚点链接][anchor-id]<br>[anchor-id]: <a href="http://www.mdeditor.com/" target="_blank" rel="noopener">http://www.mdeditor.com/</a><br><a href="mailto:test.test@gmail.com" target="_blank" rel="noopener">mailto:test.test@gmail.com</a><br>GFM a-tail link @pandao<br>邮箱地址自动链接 <a href="mailto:test.test@gmail.com" target="_blank" rel="noopener">test.test@gmail.com</a>  <a href="mailto:www@vip.qq.com" target="_blank" rel="noopener">www@vip.qq.com</a></p><blockquote><p>@pandao</p></blockquote><h3 id="多语言代码高亮-Codes"><a href="#多语言代码高亮-Codes" class="headerlink" title="多语言代码高亮 Codes"></a>多语言代码高亮 Codes</h3><h4 id="行内代码-Inline-code"><a href="#行内代码-Inline-code" class="headerlink" title="行内代码 Inline code"></a>行内代码 Inline code</h4><p>执行命令：<code>npm install marked</code></p><h4 id="缩进风格"><a href="#缩进风格" class="headerlink" title="缩进风格"></a>缩进风格</h4><p>即缩进四个空格，也做为实现类似 <code>&lt;pre&gt;</code> 预格式化文本 ( Preformatted Text ) 的功能。</p><pre><code>&lt;?php    echo &quot;Hello world!&quot;;?&gt;</code></pre><p>预格式化文本：</p><pre><code>| First Header  | Second Header || ------------- | ------------- || Content Cell  | Content Cell  || Content Cell  | Content Cell  |</code></pre><h4 id="JS代码"><a href="#JS代码" class="headerlink" title="JS代码"></a>JS代码</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">test</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"Hello world!"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="HTML-代码-HTML-codes"><a href="#HTML-代码-HTML-codes" class="headerlink" title="HTML 代码 HTML codes"></a>HTML 代码 HTML codes</h4><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mate</span> <span class="attr">charest</span>=<span class="string">"utf-8"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"keywords"</span> <span class="attr">content</span>=<span class="string">"Editor.md, Markdown, Editor"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Hello world!<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">style</span> <span class="attr">type</span>=<span class="string">"text/css"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">            body&#123;font-size:14px;color:#444;font-family: "Microsoft Yahei", Tahoma, "Hiragino Sans GB", Arial;background:#fff;&#125;</span></span><br><span class="line"><span class="undefined">            ul&#123;list-style: none;&#125;</span></span><br><span class="line"><span class="undefined">            img&#123;border:none;vertical-align: middle;&#125;</span></span><br><span class="line"><span class="undefined">        </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span> <span class="attr">class</span>=<span class="string">"text-xxl"</span>&gt;</span>Hello world!<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"text-green"</span>&gt;</span>Plain text<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="图片-Images"><a href="#图片-Images" class="headerlink" title="图片 Images"></a>图片 Images</h3><p>图片加链接 (Image + Link)：</p><p><a href="http://www.mdeditor.com/images/logos/markdown.png" title="markdown" target="_blank" rel="noopener"><img src="http://www.mdeditor.com/images/logos/markdown.png" alt=""></a></p><blockquote><p>Follow your heart.</p></blockquote><hr><h3 id="列表-Lists"><a href="#列表-Lists" class="headerlink" title="列表 Lists"></a>列表 Lists</h3><h4 id="无序列表（减号）Unordered-Lists"><a href="#无序列表（减号）Unordered-Lists" class="headerlink" title="无序列表（减号）Unordered Lists (-)"></a>无序列表（减号）Unordered Lists (-)</h4><ul><li>列表一</li><li>列表二</li><li>列表三</li></ul><h4 id="无序列表（星号）Unordered-Lists"><a href="#无序列表（星号）Unordered-Lists" class="headerlink" title="无序列表（星号）Unordered Lists (*)"></a>无序列表（星号）Unordered Lists (*)</h4><ul><li>列表一</li><li>列表二</li><li>列表三</li></ul><h4 id="无序列表（加号和嵌套）Unordered-Lists"><a href="#无序列表（加号和嵌套）Unordered-Lists" class="headerlink" title="无序列表（加号和嵌套）Unordered Lists (+)"></a>无序列表（加号和嵌套）Unordered Lists (+)</h4><ul><li>列表一</li><li>列表二<ul><li>列表二-1</li><li>列表二-2</li><li>列表二-3</li></ul></li><li>列表三<ul><li>列表一</li><li>列表二</li><li>列表三</li></ul></li></ul><h4 id="有序列表-Ordered-Lists"><a href="#有序列表-Ordered-Lists" class="headerlink" title="有序列表 Ordered Lists (-)"></a>有序列表 Ordered Lists (-)</h4><ol><li>第一行</li><li>第二行</li><li>第三行</li></ol><h4 id="GFM-task-list"><a href="#GFM-task-list" class="headerlink" title="GFM task list"></a>GFM task list</h4><ul><li style="list-style: none"><input type="checkbox" checked> GFM task list 1</li><li style="list-style: none"><input type="checkbox" checked> GFM task list 2</li><li style="list-style: none"><input type="checkbox"> GFM task list 3<ul><li style="list-style: none"><input type="checkbox"> GFM task list 3-1</li><li style="list-style: none"><input type="checkbox"> GFM task list 3-2</li><li style="list-style: none"><input type="checkbox"> GFM task list 3-3</li></ul></li><li style="list-style: none"><input type="checkbox"> GFM task list 4<ul><li style="list-style: none"><input type="checkbox"> GFM task list 4-1</li><li style="list-style: none"><input type="checkbox"> GFM task list 4-2</li></ul></li></ul><hr><h3 id="绘制表格-Tables"><a href="#绘制表格-Tables" class="headerlink" title="绘制表格 Tables"></a>绘制表格 Tables</h3><table><thead><tr><th>项目</th><th style="text-align:right">价格</th><th style="text-align:center">数量</th></tr></thead><tbody><tr><td>计算机</td><td style="text-align:right">$1600</td><td style="text-align:center">5</td></tr><tr><td>手机</td><td style="text-align:right">$12</td><td style="text-align:center">12</td></tr><tr><td>管线</td><td style="text-align:right">$1</td><td style="text-align:center">234</td></tr></tbody></table><table><thead><tr><th>First Header</th><th>Second Header</th></tr></thead><tbody><tr><td>Content Cell</td><td>Content Cell</td></tr><tr><td>Content Cell</td><td>Content Cell</td></tr></tbody></table><table><thead><tr><th>First Header</th><th>Second Header</th></tr></thead><tbody><tr><td>Content Cell</td><td>Content Cell</td></tr><tr><td>Content Cell</td><td>Content Cell</td></tr></tbody></table><table><thead><tr><th>Function name</th><th>Description</th></tr></thead><tbody><tr><td><code>help()</code></td><td>Display the help window.</td></tr><tr><td><code>destroy()</code></td><td><strong>Destroy your computer!</strong></td></tr></tbody></table><table><thead><tr><th style="text-align:left">Left-Aligned</th><th style="text-align:center">Center Aligned</th><th style="text-align:right">Right Aligned</th></tr></thead><tbody><tr><td style="text-align:left">col 3 is</td><td style="text-align:center">some wordy text</td><td style="text-align:right">$1600</td></tr><tr><td style="text-align:left">col 2 is</td><td style="text-align:center">centered</td><td style="text-align:right">$12</td></tr><tr><td style="text-align:left">zebra stripes</td><td style="text-align:center">are neat</td><td style="text-align:right">$1</td></tr></tbody></table><table><thead><tr><th>Item</th><th style="text-align:right">Value</th></tr></thead><tbody><tr><td>Computer</td><td style="text-align:right">$1600</td></tr><tr><td>Phone</td><td style="text-align:right">$12</td></tr><tr><td>Pipe</td><td style="text-align:right">$1</td></tr></tbody></table><hr><h4 id="特殊符号-HTML-Entities-Codes"><a href="#特殊符号-HTML-Entities-Codes" class="headerlink" title="特殊符号 HTML Entities Codes"></a>特殊符号 HTML Entities Codes</h4><p>&copy; &amp;  &uml; &trade; &iexcl; &pound;<br>&amp; &lt; &gt; &yen; &euro; &reg; &plusmn; &para; &sect; &brvbar; &macr; &laquo; &middot;</p><p>X&sup2; Y&sup3; &frac34; &frac14;  &times;  &divide;   &raquo;</p><p>18&ordm;C  &quot;  &apos;</p><p>[========]</p><h3 id="Emoji表情-smiley"><a href="#Emoji表情-smiley" class="headerlink" title="Emoji表情 :smiley:"></a>Emoji表情 :smiley:</h3><blockquote><p>Blockquotes :star:</p></blockquote><h4 id="GFM-task-lists-amp-Emoji-amp-fontAwesome-icon-emoji-amp-editormd-logo-emoji-editormd-logo-5x"><a href="#GFM-task-lists-amp-Emoji-amp-fontAwesome-icon-emoji-amp-editormd-logo-emoji-editormd-logo-5x" class="headerlink" title="GFM task lists &amp; Emoji &amp; fontAwesome icon emoji &amp; editormd logo emoji :editormd-logo-5x:"></a>GFM task lists &amp; Emoji &amp; fontAwesome icon emoji &amp; editormd logo emoji :editormd-logo-5x:</h4><ul><li style="list-style: none"><input type="checkbox" checked> :smiley: @mentions, :smiley: #refs, <a href="">links</a>, <strong>formatting</strong>, and <del>tags</del> supported :editormd-logo:;</li><li style="list-style: none"><input type="checkbox" checked> list syntax required (any unordered or ordered list supported) :editormd-logo-3x:;</li><li style="list-style: none"><input type="checkbox" checked> [ ] :smiley: this is a complete item :smiley:;</li><li style="list-style: none"><input type="checkbox"> []this is an incomplete item <a href="#">test link</a> :fa-star: @pandao;</li><li style="list-style: none"><input type="checkbox"> [ ]this is an incomplete item :fa-star: :fa-gear:;<ul><li style="list-style: none"><input type="checkbox"> :smiley: this is an incomplete item <a href="#">test link</a> :fa-star: :fa-gear:;</li><li style="list-style: none"><input type="checkbox"> :smiley: this is  :fa-star: :fa-gear: an incomplete item <a href="#">test link</a>;</li></ul></li></ul><h4 id="反斜杠-Escape"><a href="#反斜杠-Escape" class="headerlink" title="反斜杠 Escape"></a>反斜杠 Escape</h4><p>*literal asterisks*</p><p>[========]</p><h3 id="科学公式-TeX-KaTeX"><a href="#科学公式-TeX-KaTeX" class="headerlink" title="科学公式 TeX(KaTeX)"></a>科学公式 TeX(KaTeX)</h3><p>$$E=mc^2$$</p><p>行内的公式$$E=mc^2$$行内的公式，行内的$$E=mc^2$$公式。</p><p>$$x &gt; y$$</p><p>$$(\sqrt{3x-1}+(1+x)^2)$$</p><p>$$\sin(\alpha)^{\theta}=\sum_{i=0}^{n}(x^i + \cos(f))$$</p><p>多行公式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\displaystyle</span><br><span class="line">\left( \sum\_&#123;k=1&#125;^n a\_k b\_k \right)^2</span><br><span class="line">\leq</span><br><span class="line">\left( \sum\_&#123;k=1&#125;^n a\_k^2 \right)</span><br><span class="line">\left( \sum\_&#123;k=1&#125;^n b\_k^2 \right)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">\displaystyle</span><br><span class="line">    \frac&#123;1&#125;&#123;</span><br><span class="line">        \Bigl(\sqrt&#123;\phi \sqrt&#123;5&#125;&#125;-\phi\Bigr) e^&#123;</span><br><span class="line">        \frac25 \pi&#125;&#125; = 1+\frac&#123;e^&#123;-2\pi&#125;&#125; &#123;1+\frac&#123;e^&#123;-4\pi&#125;&#125; &#123;</span><br><span class="line">        1+\frac&#123;e^&#123;-6\pi&#125;&#125;</span><br><span class="line">        &#123;1+\frac&#123;e^&#123;-8\pi&#125;&#125;</span><br><span class="line">         &#123;1+\cdots&#125; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f(x) = \int_&#123;-\infty&#125;^\infty</span><br><span class="line">    \hat f(\xi)\,e^&#123;2 \pi i \xi x&#125;</span><br><span class="line">    \,d\xi</span><br></pre></td></tr></table></figure><h3 id="分页符-Page-break"><a href="#分页符-Page-break" class="headerlink" title="分页符 Page break"></a>分页符 Page break</h3><blockquote><p>Print Test: Ctrl + P</p></blockquote><p>[========]</p><h3 id="绘制流程图-Flowchart"><a href="#绘制流程图-Flowchart" class="headerlink" title="绘制流程图 Flowchart"></a>绘制流程图 Flowchart</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: 用户登陆</span><br><span class="line">op=&gt;operation: 登陆操作</span><br><span class="line">cond=&gt;condition: 登陆成功 Yes or No?</span><br><span class="line">e=&gt;end: 进入后台</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no)-&gt;op</span><br></pre></td></tr></table></figure><p>[========]</p><h3 id="绘制序列图-Sequence-Diagram"><a href="#绘制序列图-Sequence-Diagram" class="headerlink" title="绘制序列图 Sequence Diagram"></a>绘制序列图 Sequence Diagram</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Andrew-&gt;China: Says Hello</span><br><span class="line">Note right of China: China thinks\nabout it</span><br><span class="line">China--&gt;Andrew: How are you?</span><br><span class="line">Andrew-&gt;&gt;China: I am good thanks!</span><br></pre></td></tr></table></figure><h3 id="End"><a href="#End" class="headerlink" title="End"></a>End</h3>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;欢迎使用-Markdown在线编辑器-MdEditor&quot;&gt;&lt;a href=&quot;#欢迎使用-Markdown在线编辑器-MdEditor&quot; class=&quot;headerlink&quot; title=&quot;欢迎使用 Markdown在线编辑器 MdEditor&quot;&gt;&lt;/a&gt;欢迎使用 Markdown在线编辑器 MdEditor&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Markdown是一种轻量级的「标记语言」&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.mdeditor.com/images/logos/markdown.png&quot; alt=&quot;markdown&quot; title=&quot;markdown&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>hexo</title>
    <link href="http://yoursite.com/2018/08/17/hexo/"/>
    <id>http://yoursite.com/2018/08/17/hexo/</id>
    <published>2018-08-17T13:00:33.000Z</published>
    <updated>2018-09-24T05:53:53.240Z</updated>
    
    <content type="html"><![CDATA[<p>##常用命令(cmd)<br>hexo n “postName”<br>hexo clean<br>hexo g 本地生成<br>hexo d 同步到github<br>hexo d -g<br>hexo new page aboutme<br>hexo s 本地服务器预览<br>hexo s -p 4100 换端口<br><a id="more"></a></p><h2 id="搭建Github-hexo-博客的过程"><a href="#搭建Github-hexo-博客的过程" class="headerlink" title="搭建Github+hexo 博客的过程"></a>搭建Github+hexo 博客的过程</h2><p>参考链接如下<br><a href="https://www.cnblogs.com/fengxiongZz/p/7707219.html" target="_blank" rel="noopener">使用Hexo+Github一步步搭建属于自己的博客（基础）</a><br><a href="https://www.cnblogs.com/fengxiongZz/p/7707568.html" target="_blank" rel="noopener">使用Hexo+Github一步步搭建属于自己的博客（进阶）</a><br><a href="http://blog.haoji.me/build-blog-website-by-hexo-github.html?from=xa" target="_blank" rel="noopener">1</a><br><a href="https://www.cnblogs.com/fengxiongZz/p/7707568.html" target="_blank" rel="noopener">2</a><br><a href="https://www.jianshu.com/p/84a8384be1ae" target="_blank" rel="noopener">3</a><br><a href="http://tengj.top/2016/02/22/hexo1/" target="_blank" rel="noopener">4</a><br>$ npm install -g hexo-cli<br>安装Node.js →安装Hexo → 安装主题 →  本地测试运行 → 注册给github与coding并创建pages仓库 → 部署<br>安装Git                                        →<br><a href="https://blog.csdn.net/heshuaicsdn/article/details/78923476" target="_blank" rel="noopener">node.js的解释是高并发</a><br>npm是模块的包管理器,与node.js一起安装的。<br>npm install hexo -g 全局安装<a href="https://www.runoob.com/nodejs/nodejs-npm.html" target="_blank" rel="noopener"></a><br>hexo是基于node.js的静态博客，所以我们才需要安装node.js<br>Git是为了让其他人也可以看到你的博客，把本地的内容提交到github上面去<br>常用命令<a href="https://blog.csdn.net/qq_26975307/article/details/62447489" target="_blank" rel="noopener"></a><br>hexo g 生成 generate<br>hexo s 启动服务器预览 server<br>hexo d 部署 deploy<br>hexo clean 清除缓存<br>hexo server -p 4100<br>hexo generate –deploy 完成后部署<br>hexo deploy –generate 完成后部<br>hexo new “postName”</p><p>node_modules 依赖包<br>public 生成的页面<br>scaffolds 模板文件夹 post draft page<br>source 用户资源的地方</p><p><a href="https://www.jianshu.com/p/3a8dba06856a" target="_blank" rel="noopener">hexo解释</a><br><a href="https://blog.csdn.net/kingice1014/article/details/52924523" target="_blank" rel="noopener">hexo中_config.yml</a><br><a href="https://www.jianshu.com/p/56d99a3049a5" target="_blank" rel="noopener">markdown写博客</a><br><a href="https://blog.csdn.net/o_mario_o/article/details/80347863" target="_blank" rel="noopener">hexo中的配置信息</a><br><a href="https://www.jianshu.com/p/84a8384be1ae" target="_blank" rel="noopener">域名绑定</a><br><a href="https://www.jianshu.com/p/7ab21c7f0674" target="_blank" rel="noopener">hexo渲染MathJax数学公式</a><br>markdownpad渲染数学公式只能F6浏览器预览，并且不能实时预览，所以考虑换个markdown编辑器<br>cmd markdown对本地文件支持不友好，并且不能加载本地图片<br><a href="https://hyxxsfwy.github.io/2016/01/15/Hexo-Markdown-%E7%AE%80%E6%98%8E%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C/" target="_blank" rel="noopener">Hexo Markdown 简明语法手册</a><br><a href="https://github.com/LouisBarranqueiro/hexo-footnotes" target="_blank" rel="noopener">hexo的脚注问题</a><br>只能实现数字的脚注</p><hr><p>2018-09-12</p><h2 id="实现评论功能"><a href="#实现评论功能" class="headerlink" title="实现评论功能"></a>实现评论功能</h2><p>此次评论功能使用disqus，理由：同学推荐<br>参考链接：<br><a href="https://www.jianshu.com/p/2671b28b79e5" target="_blank" rel="noopener">Hexo折腾记之科学使用Disqus与Next的集成</a><br><a href="https://blog.fooleap.org/use-disqus-correctly.html" target="_blank" rel="noopener">科学使用 Disqus</a><br><a href="https://github.com/fooleap/disqus-php-api" target="_blank" rel="noopener">Disqus PHP API</a><br><a href="http://smk17.cn/posts/104/" target="_blank" rel="noopener">基于disqus-php-api在Hexo博客中使用Disqus</a><br><a href="https://ycwalker.com/2017/06/01/diqus-proxy-config/" target="_blank" rel="noopener">Disqus-Proxy 配置说明</a><br><a href="https://blog.csdn.net/u010053344/article/details/50701191" target="_blank" rel="noopener">Github 搭建 hexo （四）——更换主题，disqus，RSS</a></p><h2 id="添加rss功能"><a href="#添加rss功能" class="headerlink" title="添加rss功能"></a>添加rss功能</h2><p>不知道是干嘛的，好像是为了实现订阅的。暂时不是很清楚。<br>参考链接：<br><a href="https://blog.csdn.net/tx874828503/article/details/51577815" target="_blank" rel="noopener">最简便的方法搭建Hexo+Github博客,基于Next主题</a></p><h2 id="添加site-map功能"><a href="#添加site-map功能" class="headerlink" title="添加site-map功能"></a>添加site-map功能</h2><p>参考链接<br>不知道是干嘛的<br><a href="https://blog.csdn.net/u010053344/article/details/50706790" target="_blank" rel="noopener">Github 搭建 hexo （五）- 站点地图（sitemap.xml）</a><br>站点地图还挺高级，以后再说。</p><h2 id="百度自动推送"><a href="#百度自动推送" class="headerlink" title="百度自动推送"></a>百度自动推送</h2><p>参考链接<br><a href="https://blog.csdn.net/hosea1008/article/details/53384382" target="_blank" rel="noopener">Hexo+Next主题博客提交百度谷歌收录</a></p><h2 id="添加公益404界面"><a href="#添加公益404界面" class="headerlink" title="添加公益404界面"></a>添加公益404界面</h2><p>参考链接<br><a href="https://blog.csdn.net/liu1340308350/article/details/81744824" target="_blank" rel="noopener">hexo添加404公益界面</a><br><a href="https://blog.csdn.net/tx874828503/article/details/51577815" target="_blank" rel="noopener">最简便的方法搭建Hexo+Github博客,基于Next主题</a></p><h2 id="添加搜索"><a href="#添加搜索" class="headerlink" title="添加搜索"></a>添加搜索</h2><p>参考链接<br><a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener">hexo-genarator-search</a></p><h2 id="高级教程"><a href="#高级教程" class="headerlink" title="高级教程"></a>高级教程</h2><p>以后再说<br><a href="https://blog.csdn.net/sunshine940326/article/details/52552283" target="_blank" rel="noopener">利用Gitpage+hexo开发自己的博客</a><br><a href="https://blog.csdn.net/linshuhe1/article/details/52424573" target="_blank" rel="noopener">Hexo个人免费博客(三) next主题、评论、阅读量统计和站内搜索</a><br><a href="https://hexo.io/plugins/" target="_blank" rel="noopener">官网插件</a></p><hr><p>title: Hello World<br>toc: true </p><hr><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><!--more--><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;##常用命令(cmd)&lt;br&gt;hexo n “postName”&lt;br&gt;hexo clean&lt;br&gt;hexo g 本地生成&lt;br&gt;hexo d 同步到github&lt;br&gt;hexo d -g&lt;br&gt;hexo new page aboutme&lt;br&gt;hexo s 本地服务器预览&lt;br&gt;hexo s -p 4100 换端口&lt;br&gt;
    
    </summary>
    
      <category term="搭建博客" scheme="http://yoursite.com/categories/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
      <category term="github" scheme="http://yoursite.com/tags/github/"/>
    
      <category term="npm" scheme="http://yoursite.com/tags/npm/"/>
    
      <category term="基础" scheme="http://yoursite.com/tags/%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
